# Overview
Apache Spark is an open-source, distributed processing system used for big data workloads.

Spark is setup as a cluster based service which allows users to submit workloads to it through various language bindings. Users can submit code snippets to the cluster using Scala, Python, and R.

# 1. History
Originally developed at the University of California, Berkeley's AMPLab in 2009 under a BSD license, the Spark codebase was later donated to the Apache Software Foundation in 2013 under the Apache 2.0 license. There have been several major iterations released with the most recent version being 3.1.

# 2. Relevant Notebooks
The following notebooks will get you up and running with Apache Spark:

- [Install Apache Spark Prerequisites](Install%20Apache%20Spark%20Prerequisites.ipynb)
- [Spark Pi - The Hello World Example For Apache spark](Spark%20Pi%20-%20The%20Hello%20World%20Example%20For%20Apache%20spark.ipynb)
- [Running Apache Spark Locally](Running%20Apache%20Spark%20Locally.ipynb)
- [Running Apache Spark On Kubernetes](Running%20Apache%20Spark%20On%20Kubernetes.ipynb)