{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57f4757-e367-4dbd-a4e0-b987be81ea17",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "While Spark is a distributed compute cluster is does provide a nuce feature: we can run the code locally so that we can sebug issues etc.\n",
    "\n",
    "In this notebook we will run a locak spark cluster for the purposes of sebugging in a simpler local environment.\n",
    "\n",
    "It assumes you have already read the following notebooks:\n",
    "- [Install Apache Spark Prerequisites](Install%20Apache%20Spark%20Prerequisites.ipynb)\n",
    "- [Spark Pi - The Hello World Example For Apache spark](Spark%20Pi%20-%20The%20Hello%20World%20Example%20For%20Apache%20spark.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa963e-2319-423c-9d0b-6baae300d60e",
   "metadata": {},
   "source": [
    "# 1. Add Spark To The Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61e857b-90bc-4588-b95f-4b72ee384438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa8ce69-458b-4e16-8e4b-9550886c9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\spark\\\\spark-3.1.1-bin-hadoop2.7\\\\python', 'C:\\\\spark\\\\spark-3.1.1-bin-hadoop2.7\\\\python\\\\lib\\\\py4j-0.10.9-src.zip', 'c:\\\\program files\\\\python36\\\\python36.zip', 'c:\\\\program files\\\\python36\\\\DLLs', 'c:\\\\program files\\\\python36\\\\lib', 'c:\\\\program files\\\\python36', '', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages\\\\win32', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages\\\\Pythonwin', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Administrator\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400246cd-edf6-417b-a467-74d5ccad0006",
   "metadata": {},
   "source": [
    "# 2. Create The SparkConf Object\n",
    "The SparkConf object is a configuration object. It configures the SparkContext object and allows us to create and connect to our local cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6732fef1-3682-4b21-9766-cf12af9f3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839ee595-4901-4aff-9589-e6bd59841a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x6944358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkConf = pyspark.SparkConf()\n",
    "sparkConf.setAppName(\"spark-jupyter-win\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da235ac2-2386-4895-a3eb-5037f440beee",
   "metadata": {},
   "source": [
    "# 3. Create the SparkContext\n",
    "The SparkContext is the object that allows us to interface with apache spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8118dda-1bb0-419e-9a07-fd9c5ecd65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646c344-4183-478d-b227-071d0d1f27d6",
   "metadata": {},
   "source": [
    "# 4. Sumbit The Hello, World! Example Spark Job\n",
    "For an explanation of what the code is doing or how it works, see [Spark Pi - The Hello World Example For Apache spark](Spark%20Pi%20-%20The%20Hello%20World%20Example%20For%20Apache%20spark.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4853ff89-4098-43bf-bb3f-73880ced96a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1484\n"
     ]
    }
   ],
   "source": [
    "# Define a function to generate a pair or random numbers and determine whether they corespond to a point within a circle\n",
    "import random\n",
    "\n",
    "def monte_carlo_trial(var):\n",
    "    # Generate random variables for x and y\n",
    "    x, y = random.random(), random.random()\n",
    "    # Calculate whether or not the point is inside the circle\n",
    "    inside_circle =  x*x + y*y < 1\n",
    "    # Return the value\n",
    "    return inside_circle\n",
    "\n",
    "# Set the number of trials for the monte carlo simulation\n",
    "number_of_trials = 10000\n",
    "\n",
    "# Use the SparkContext to apply the monte carlo trials in parrallel and count the positive results\n",
    "count = sc.parallelize(range(0, number_of_trials)).filter(monte_carlo_trial).count()\n",
    "\n",
    "# Compute the value of pi based on the information from the monte carlo simulation\n",
    "pi = 4 * count / number_of_trials\n",
    "\n",
    "# Print the value of pi\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e493ab-ff1f-4bce-92eb-8b46751f7e74",
   "metadata": {},
   "source": [
    "# 5. Cleanup The SparkContext\n",
    "We will stop the local cluster and cleanup our memory objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1fa300-be03-4abf-9ad5-8a80e4185c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
