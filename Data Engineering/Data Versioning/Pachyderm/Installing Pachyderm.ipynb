{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e96703e-ad57-421d-85a9-89d7980eba5c",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook we will explore the options for installing pachyderm locally (i.e. in a self-hosted format). This means no commercial requirements like a cloud provider or any manages service or applicance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12da697-ee6c-4ca9-a350-9c16e7053eba",
   "metadata": {},
   "source": [
    "Currently the latest stable version is [2.5.5](https://github.com/pachyderm/pachyderm/releases/tag/v2.5.5) which was released 4/27/2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f1e2b-af4e-420b-94ff-e0981a069c9d",
   "metadata": {},
   "source": [
    "# Installation Options\n",
    "\n",
    "Looking through the documentation we see several options for installing pachyderm: locally or in the cloud. We then see that these two opions break down further. The table below tries to enumerate the options presented or implied in the documentation.\n",
    "\n",
    "- [Local Installation](https://docs.pachyderm.com/2.3.x/getting-started/local-installation/)\n",
    "    - [Docker Desktop](https://docs.pachyderm.com/latest/getting-started/local-deploy/docker/) - A commercial application that allows running containers as well as a single node kubernetes cluster\n",
    "    - [Minikube](https://docs.pachyderm.com/latest/getting-started/local-deploy/minikube/) - An open source tool that allows running a single node kubernetes cluster locally\n",
    "- [On-premisis Installation](https://docs.pachyderm.com/latest/deploy-manage/deploy/on-premises/)\n",
    "    - kubernetes cluster\n",
    "- Cloud Installation\n",
    "    - AWS\n",
    "    - Azure\n",
    "    - GCP\n",
    "\n",
    "In this guide, I will be installing to a self-hosted kubernetes cluster. Additionally, this will NOT be a production deployment. Instead it will be a bare bones spin-up to evaluate the pachyderm features. If I like the solution I will update the instructions for a proper production worthy install."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba9267-3dee-43c9-b698-30f60cb3ca1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c02380-2fa9-41f6-94a7-f07a17c3d6cb",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Install Helm (full kuberentes only)\n",
    "\n",
    "We can think of helm as a package and deployment manager for kubernetes. Helm automates the creation, packaging, configuration, and deployment of Kubernetes applications. It does this through a packaging structure that combines your configuration files into a single reusable format that can be understood and managed by the utility.\n",
    "\n",
    "### Helm Compatibility\n",
    "\n",
    "In order to install helm, we need to figure out which version is comptible with the version of our kubernetes cluster. The helm documentation lists the [compatibility matrix](https://helm.sh/docs/topics/version_skew/) as seen below:\n",
    "\n",
    "\n",
    "|Helm Version|Supported Kubernetes Versions|\n",
    "|------------|-----------------------------|\n",
    "|3.11.x |1.26.x - 1.23.x|\n",
    "|3.10.x|1.25.x - 1.22.x|\n",
    "|3.9.x|1.24.x - 1.21.x|\n",
    "|3.8.x|1.23.x - 1.20.x|\n",
    "|3.7.x|1.22.x - 1.19.x|\n",
    "|3.6.x|1.21.x - 1.18.x|\n",
    "|3.5.x|1.20.x - 1.17.x|\n",
    "|3.4.x|1.19.x - 1.16.x|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd136bc-84d8-4e50-b869-7cfa8f218e0a",
   "metadata": {},
   "source": [
    "In my case my case my kubernetes cluster was running version 1.21.14:\n",
    "```\n",
    "[root@os004k8-master001 ~]# kubectl version\n",
    "Client Version: version.Info{Major:\"1\", Minor:\"21\", GitVersion:\"v1.21.9\", GitCommit:\"b631974d68ac5045e076c86a5c66fba6f128dc72\", GitTreeState:\"clean\", BuildDate:\"2022-01-19T17:51:12Z\", GoVersion:\"go1.16.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n",
    "Server Version: version.Info{Major:\"1\", Minor:\"21\", GitVersion:\"v1.21.14\", GitCommit:\"0f77da5bd4809927e15d1658fb4aa8f13ad890a5\", GitTreeState:\"clean\", BuildDate:\"2022-06-15T14:11:36Z\", GoVersion:\"go1.16.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n",
    "\n",
    "```\n",
    "\n",
    "So this means I can run helm 3.6 to 3.9. I will go with 3.9 as it's the newest version which has had the most burn in time with my version of k8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d9468-0627-4a7e-82dd-b21d2dd61c88",
   "metadata": {},
   "source": [
    "### Download Binaries\n",
    "The official installation instructions can be found [here](https://helm.sh/docs/intro/install/). Every version of helm is distributed as a binary built for x64 arhchitectures. The binaries can be doenloaded from the [github releases page](https://github.com/helm/helm/releases).\n",
    "\n",
    "In my case, [3.9.4](https://github.com/helm/helm/releases/tag/v3.9.4) is the latest version available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eddcc6e-375f-4020-b718-38864c5f8f1c",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# curl -O https://get.helm.sh/helm-v3.9.4-linux-amd64.tar.gz\n",
    "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    "                                 Dload  Upload   Total   Spent    Left  Speed\n",
    "100 13.3M  100 13.3M    0     0  20.1M      0 --:--:-- --:--:-- --:--:-- 20.1M\n",
    "\n",
    "[root@os004k8-master001 ~]# tar -zxvf helm-v3.9.4-linux-amd64.tar.gz\n",
    "linux-amd64/\n",
    "linux-amd64/helm\n",
    "linux-amd64/LICENSE\n",
    "linux-amd64/README.md\n",
    "\n",
    "[root@os004k8-master001 ~]# linux-amd64/helm version\n",
    "WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config\n",
    "WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config\n",
    "version.BuildInfo{Version:\"v3.9.4\", GitCommit:\"dbc6d8e20fe1d58d50e6ed30f09a04a77e4c68db\", GitTreeState:\"clean\", GoVersion:\"go1.17.13\"}\n",
    "\n",
    "[root@os004k8-master001 ~]# cp linux-amd64/helm /usr/bin/\n",
    "[root@os004k8-master001 ~]# helm version\n",
    "WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config\n",
    "WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config\n",
    "version.BuildInfo{Version:\"v3.9.4\", GitCommit:\"dbc6d8e20fe1d58d50e6ed30f09a04a77e4c68db\", GitTreeState:\"clean\", GoVersion:\"go1.17.13\"}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4704ec-2d25-4a37-9f07-ea0f8287bf8b",
   "metadata": {},
   "source": [
    "### Connect helm to kubernetes cluster\n",
    "In order to allow helm to install packages on kuernetes, it needs to be able to access information about the cluster. This is typically done via the kube config file. A plain text file that contains the configurations and secrets necessary for a cli to connect and authenticate against a kubernetes cluster. For example, the kubectl and kubeadm programs use this file.\n",
    "\n",
    "Helm will default to using whatever your current Kubernetes context is, as specified in the $HOME/. kube/config file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43f2c1-a5d1-4616-96d5-74ae9f2c7f5a",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Setup Load Balancer\n",
    "\n",
    "The purpose of a Load Balancer is to configure the networking so people outside the cluster can reliably connect to services hosted inside the cluster. In kubernetes this is done through a [Service](https://kubernetes.io/docs/concepts/services-networking/service/). There are [several types of services](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types) provided by kubernetes: ClusterIP, NodePort, LoadBalancer, ExternalName. We will be using a [LoadBalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer) for our purposes. \n",
    "\n",
    "Reading through the documentation we infer that the LoadBalancer implimentation varies with each cloud provider. From experience I can say that the LoadBalancer can be thought of as a plugin. Each cloud provider hosts their own flavor of kubernetes which integrates, through a load balancer plugin, with their back end infrastructure. For example, AWS offers the [AWS Load Balancer Controller add-on](https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html). \n",
    "\n",
    "As my kubernetes cluster is running \"on-prem\" or \"bare-metal\" I cannot leverage any of these cloud native LB options. Instead I must look for a 3rd party solution that will provde the features I need. Enter MetalLB.\n",
    "\n",
    "**Note** If a LoadBalancer Service is deployed on a bare-metal kubernetes cluster withouth a LoadBallancer being installed in the system, the services will start, but they will not be allocated an externally facing IP address. For example, in the case of Pachyderm, we would see something like this:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get service pachyderm-proxy\n",
    "NAME              TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n",
    "pachyderm-proxy   LoadBalancer   10.107.34.238   <pending>     80:31201/TCP   20m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ccdd4f-663b-4ac2-ab30-69688c263f74",
   "metadata": {},
   "source": [
    "### MetalLB Overview\n",
    "As the name suggests, MetalLB is a load-balancer implementation for bare metal Kubernetes clusters. It uses standard routing protocols and can be run on any OSS implimentation.\n",
    "\n",
    "The current version is v0.13.9 which is labeled as a beta despite the offering being used and reccomended for production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8cd02-e40b-44fc-81e0-5d7c24862324",
   "metadata": {},
   "source": [
    "#### Why?\n",
    "Kubernetes does not offer an implementation of network load balancers (Services of type LoadBalancer) for bare-metal clusters. The implementations of network load balancers that Kubernetes does ship with are all glue code that calls out to various IaaS platforms (GCP, AWS, Azure…). If you’re not running on a supported IaaS platform (GCP, AWS, Azure…), LoadBalancers will remain in the “pending” state indefinitely when created.\n",
    "\n",
    "Bare-metal cluster operators are left with two lesser tools to bring user traffic into their clusters, “NodePort” and “externalIPs” services. Both of these options have significant downsides for production use, which makes bare-metal clusters second-class citizens in the Kubernetes ecosystem.\n",
    "\n",
    "MetalLB aims to redress this imbalance by offering a network load balancer implementation that integrates with standard network equipment, so that external services on bare-metal clusters also “just work” as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38c609-5833-43c4-a434-e49e8fa206ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Requirements\n",
    "\n",
    "MetalLB requires the following to function:\n",
    "\n",
    "- A Kubernetes cluster, running Kubernetes 1.13.0 or later, that does not already have network load-balancing functionality.\n",
    "- A cluster network configuration that can coexist with MetalLB. The following network addons are [supported](https://metallb.universe.tf/installation/network-addons/):\n",
    "\n",
    "|Network addon|Compatible|\n",
    "|-------------|----------|\n",
    "|Antrea|Yes (Tested on version 1.4 and 1.5)|\n",
    "|Calico|Mostly (see known issues)|\n",
    "|Canal|Yes|\n",
    "|Cilium|Yes|\n",
    "|Flannel|Yes|\n",
    "|Kube-ovn|Yes|\n",
    "|Kube-router|Mostly (see known issues)|\n",
    "|Weave Net|Mostly (see known issues)|\n",
    "\n",
    "- Some IPv4 addresses for MetalLB to hand out.\n",
    "- When using the BGP operating mode, you will need one or more routers capable of speaking BGP.\n",
    "- When using the L2 operating mode, traffic on port 7946 (TCP & UDP, other port can be configured) must be allowed between nodes, as required by memberlist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa827d-7bbb-4c71-8e56-ef43ebf2500d",
   "metadata": {},
   "source": [
    "### MetalLB Installation Overview\n",
    "\n",
    "The basic process required to setup MetalLB is to install the solution and then configure it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af77d92c-f7fc-405e-8a85-efcb005a90ae",
   "metadata": {},
   "source": [
    "#### Installation Options\n",
    "\n",
    "According to the [documentation](https://metallb.universe.tf/installation/), there are three supported ways to install MetalLB: \n",
    "- using plain Kubernetes manifests\n",
    "- using Kustomize\n",
    "- using Helm\n",
    "\n",
    "**Note**: The installation comes in two flavors: Regular and FRR; FRRouting (FRR) is a set of open source internet routing protocols, including the Border Gateway Protocol (BGP).\n",
    "\n",
    "The installation will deploy MetalLB under the `metallb-system` namespace. The high-level components that make up the MetalLB solution are:\n",
    "- The `metallb-system/controller` deployment. This is the cluster-wide controller that handles IP address assignments.\n",
    "- The `metallb-system/speaker` daemonset. This is the component that speaks the protocol(s) of your choice to make the services reachable.\n",
    "- Service accounts for the controller and speaker, along with the RBAC permissions that the components need to function.\n",
    "\n",
    "While looking at the kubernetes manifest I saw declarations for the following types of kubernetes resources:\n",
    "- Namespace\n",
    "- CustomResourceDefinition\n",
    "- ServiceAccount\n",
    "- Role\n",
    "- ClusterRole\n",
    "- RoleBinding\n",
    "- ClusterRoleBinding\n",
    "- Secret\n",
    "- Service\n",
    "- Deployment\n",
    "- DaemonSet\n",
    "- ValidatingWebhookConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f6d5f-99f1-4d85-8e08-194618c0d46b",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "\n",
    "Once deployed, MetalLB remains idle until configured. [Configuration](https://metallb.universe.tf/configuration/) of the MetalLB solution occurs through the depoyment of resources into the MetalLB namesapce (metallb-system). These resources articulate and impliment the various load balancer configurations that a user requires.\n",
    "\n",
    "Typically, these resources are ultimatly Custom Resources (CRs) which are defined as part of the project.\n",
    "\n",
    "For more information on the configuration options see the [official documentation](https://metallb.universe.tf/configuration/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982778c2-061c-4c8b-9b5c-a86602a7316e",
   "metadata": {},
   "source": [
    "##### Custom Resources\n",
    "\n",
    "**Custom Resources** (CRs) are extensions of the Kubernetes API. A resource is an endpoint in the Kubernetes API that stores a collection of API objects of a certain kind; for example, the built-in pods resource contains a collection of Pod objects.\n",
    "\n",
    "A custom resource is an extension of the Kubernetes API that is not necessarily available in a default Kubernetes installation. It represents a customization of a particular Kubernetes installation. However, many core Kubernetes functions are now built using custom resources, making Kubernetes more modular.\n",
    "\n",
    "For more information see the [official documentation](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/).\n",
    "\n",
    "\n",
    "A **Custom Resource Definition** (CRD) file defines your custom resource. The definition enables Kubernetes to handle the entire lifecycle of the custome resource. The Kubernetes API serves and handles the storage of your custom resource.\n",
    "\n",
    "For more information see the [official documentation](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions).\n",
    "\n",
    "An **Operator** is a software extensions to Kubernetes that manages or \"operates\" custom resources and their components. The operator is what plugs into the kubernetes API / CLI and makes the magic happen by watching a CR type and taking application-specific actions to make the current state match the desired state in that resource. We can interract with the operator to edit the configurations or change the state (eg. stop or delete) a resource.\n",
    "\n",
    "For more information see the [official documentation](https://kubernetes.io/docs/concepts/extend-kubernetes/operator) or the (RedHat Documentation](https://www.redhat.com/en/topics/containers/what-is-a-kubernetes-operator)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d4e1a-a9e8-4775-b183-bdd8076bbb2e",
   "metadata": {},
   "source": [
    "##### Key Concepts: Address Allocation and External Announcement\n",
    "\n",
    "MetalLB relies on [two main features](https://metallb.universe.tf/concepts/) which work together to provide it's load balancer functionality: address allocation, and external announcement.\n",
    "\n",
    "**Address Allocation**\n",
    "\n",
    "When a load balancer is created, it needs an IP Address in order to communicate with other machines on the network and thus provide load balancing. Traditionally there are two patterns which a load balancer uses to obtain an IP address: static and automatic via DHCP. Through the static pattern, a host \"hard codes\" it's IP information. Through DHCP a host can instead reach out to a centralized server to obtain its IP information.\n",
    "\n",
    "Currently MetalLB only supports assigning static IPs or allocating IPs from static pools of IPs. There is an [open enhancement request](https://github.com/metallb/metallb/issues/157) to support dhcp but it is not close to being complete.\n",
    "\n",
    "**External Announcement**\n",
    "\n",
    "After MetalLB has assigned an external IP address to a service, it needs to make the network beyond the cluster aware that the IP “lives” in the cluster. MetalLB uses standard networking or routing protocols to achieve this, depending on which mode is used: ARP, NDP, or BGP.\n",
    "\n",
    "The specific configuration depends on the protocol(s) you want to use to announce service IPs. More information can be found [here](https://metallb.universe.tf/configuration/#announce-the-service-ips)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bf72e-057c-4998-ad4d-98405c0a51c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c44f37-9886-49cc-bba6-d104e43283a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6122b8-5977-4d5b-bb06-0086411ab5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777dcc5-360b-4678-bd4f-f20552b18541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3156f-939d-4977-8b92-86af9e2b0117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0a3ab-e9bd-440e-9b32-035dbf347df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7734ee1-2a2e-4e91-92bd-1780a31c47ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7108e9-c651-4ea1-841e-80e270bf3e8f",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bca3fc-1753-459c-b465-f33225520053",
   "metadata": {},
   "source": [
    "#### Check kube-proxy Config Map For IPVS Settings\n",
    "\n",
    "If you’re using kube-proxy in IPVS mode, since Kubernetes v1.14.2 you have to enable strict ARP mode.\n",
    "\n",
    "Note, you don’t need this if you’re using kube-router as service-proxy because it is enabling strict ARP by default.\n",
    "\n",
    "We can check if we are using IPVS as follows:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get configmap -n kube-system kube-proxy\n",
    "NAME         DATA   AGE\n",
    "kube-proxy   2      2d16h\n",
    "\n",
    "[root@os004k8-master001 pachyderm]# kubectl get configmap -n kube-system kube-proxy -o yaml\n",
    "apiVersion: v1\n",
    "data:\n",
    "  config.conf: |-\n",
    "    apiVersion: kubeproxy.config.k8s.io/v1alpha1\n",
    "    bindAddress: 0.0.0.0\n",
    "    bindAddressHardFail: false\n",
    "    clientConnection:\n",
    "      acceptContentTypes: \"\"\n",
    "      burst: 0\n",
    "      contentType: \"\"\n",
    "      kubeconfig: /var/lib/kube-proxy/kubeconfig.conf\n",
    "      qps: 0\n",
    "    clusterCIDR: 192.168.0.0/16\n",
    "    configSyncPeriod: 0s\n",
    "    conntrack:\n",
    "      maxPerCore: null\n",
    "      min: null\n",
    "      tcpCloseWaitTimeout: null\n",
    "      tcpEstablishedTimeout: null\n",
    "    detectLocalMode: \"\"\n",
    "    enableProfiling: false\n",
    "    healthzBindAddress: \"\"\n",
    "    hostnameOverride: \"\"\n",
    "    iptables:\n",
    "      masqueradeAll: false\n",
    "      masqueradeBit: null\n",
    "      minSyncPeriod: 0s\n",
    "      syncPeriod: 0s\n",
    "    ipvs:\n",
    "      excludeCIDRs: null\n",
    "      minSyncPeriod: 0s\n",
    "      scheduler: \"\"\n",
    "      strictARP: false\n",
    "      syncPeriod: 0s\n",
    "      tcpFinTimeout: 0s\n",
    "      tcpTimeout: 0s\n",
    "      udpTimeout: 0s\n",
    "    kind: KubeProxyConfiguration\n",
    "    metricsBindAddress: \"\"\n",
    "    mode: \"\"\n",
    "    nodePortAddresses: null\n",
    "    oomScoreAdj: null\n",
    "    portRange: \"\"\n",
    "    showHiddenMetricsForVersion: \"\"\n",
    "    udpIdleTimeout: 0s\n",
    "    winkernel:\n",
    "      enableDSR: false\n",
    "      networkName: \"\"\n",
    "      sourceVip: \"\"\n",
    "  kubeconfig.conf: |-\n",
    "    apiVersion: v1\n",
    "    kind: Config\n",
    "    clusters:\n",
    "    - cluster:\n",
    "        certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n",
    "        server: https://15.4.7.11:6443\n",
    "      name: default\n",
    "    contexts:\n",
    "    - context:\n",
    "        cluster: default\n",
    "        namespace: default\n",
    "        user: default\n",
    "      name: default\n",
    "    current-context: default\n",
    "    users:\n",
    "    - name: default\n",
    "      user:\n",
    "        tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  annotations:\n",
    "    kubeadm.kubernetes.io/component-config.hash: sha256:725d9006cdf16469bef2e8434e5225a49b721dd71843dfd2431b55bad0eb3701\n",
    "  creationTimestamp: \"2023-04-30T22:58:20Z\"\n",
    "  labels:\n",
    "    app: kube-proxy\n",
    "  name: kube-proxy\n",
    "  namespace: kube-system\n",
    "  resourceVersion: \"300\"\n",
    "  uid: e93d3967-bf4e-42bc-b5c9-f0c546ad2276\n",
    "  \n",
    "[root@os004k8-master001 pachyderm]# kubectl get configmap -n kube-system kube-proxy -o yaml | grep mode -C 3\n",
    "      udpTimeout: 0s\n",
    "    kind: KubeProxyConfiguration\n",
    "    metricsBindAddress: \"\"\n",
    "    mode: \"\"\n",
    "    nodePortAddresses: null\n",
    "    oomScoreAdj: null\n",
    "    portRange: \"\"\n",
    "\n",
    "```\n",
    "\n",
    "We can see that no mode is set (i.e. we are not using ipvs). Thus we do not need to do anything further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2172be-cff4-4be1-a98d-45250e99b1f5",
   "metadata": {},
   "source": [
    "#### Download The MetalLB Manifest\n",
    "I have decided to go with installation from the manifes.\n",
    "\n",
    "As mentioned earlier, there are two versions of MetalLB that can be deployed. The standard version and the FRR version. As I do not need any of the functionality of the FRR mode, I will do a standard deployment.\n",
    "\n",
    "We can use curl to download a local copy of the manifest.\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# curl -O https://raw.githubusercontent.com/metallb/metallb/v0.13.9/config/manifests/metallb-native.yaml\n",
    "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    "                                 Dload  Upload   Total   Spent    Left  Speed\n",
    "100 75270  100 75270    0     0   244k      0 --:--:-- --:--:-- --:--:--  245k\n",
    "```\n",
    "\n",
    "We will see that this manifest is very large and has declarations for the following types of kubernetes resources:\n",
    "- Namespace\n",
    "- CustomResourceDefinition\n",
    "- ServiceAccount\n",
    "- Role\n",
    "- ClusterRole\n",
    "- RoleBinding\n",
    "- ClusterRoleBinding\n",
    "- Secret\n",
    "- Service\n",
    "- Deployment\n",
    "- DaemonSet\n",
    "- ValidatingWebhookConfiguration\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# cat metallb-native.yaml\n",
    "apiVersion: v1\n",
    "kind: Namespace\n",
    "metadata:\n",
    "  labels:\n",
    "    pod-security.kubernetes.io/audit: privileged\n",
    "    pod-security.kubernetes.io/enforce: privileged\n",
    "    pod-security.kubernetes.io/warn: privileged\n",
    "  name: metallb-system\n",
    "---\n",
    "apiVersion: apiextensions.k8s.io/v1\n",
    "kind: CustomResourceDefinition\n",
    "metadata:\n",
    "  annotations:\n",
    "    controller-gen.kubebuilder.io/version: v0.11.1\n",
    "  name: addresspools.metallb.io\n",
    "spec:\n",
    "  conversion:\n",
    "    strategy: Webhook\n",
    "    webhook:\n",
    "      clientConfig:\n",
    "        caBundle: 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\n",
    "        service:\n",
    "          name: webhook-service\n",
    "          namespace: metallb-system\n",
    "          path: /convert\n",
    "      conversionReviewVersions:\n",
    "      - v1alpha1\n",
    "      - v1beta1\n",
    "  group: metallb.io\n",
    "  names:\n",
    "    kind: AddressPool\n",
    "    listKind: AddressPoolList\n",
    "    plural: addresspools\n",
    "    singular: addresspool\n",
    "  scope: Namespaced\n",
    "  versions:\n",
    "  - deprecated: true\n",
    "    deprecationWarning: metallb.io v1alpha1 AddressPool is deprecated\n",
    "    name: v1alpha1\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: AddressPool is the Schema for the addresspools API.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: AddressPoolSpec defines the desired state of AddressPool.\n",
    "            properties:\n",
    "              addresses:\n",
    "                description: A list of IP address ranges over which MetalLB has authority.\n",
    "                  You can list multiple ranges in a single pool, they will all share\n",
    "                  the same settings. Each range can be either a CIDR prefix, or an\n",
    "                  explicit start-end range of IPs.\n",
    "                items:\n",
    "                  type: string\n",
    "                type: array\n",
    "              autoAssign:\n",
    "                default: true\n",
    "                description: AutoAssign flag used to prevent MetallB from automatic\n",
    "                  allocation for a pool.\n",
    "                type: boolean\n",
    "              bgpAdvertisements:\n",
    "                description: When an IP is allocated from this pool, how should it\n",
    "                  be translated into BGP announcements?\n",
    "                items:\n",
    "                  properties:\n",
    "                    aggregationLength:\n",
    "                      default: 32\n",
    "                      description: The aggregation-length advertisement option lets\n",
    "                        you “roll up” the /32s into a larger prefix.\n",
    "                      format: int32\n",
    "                      minimum: 1\n",
    "                      type: integer\n",
    "                    aggregationLengthV6:\n",
    "                      default: 128\n",
    "                      description: Optional, defaults to 128 (i.e. no aggregation)\n",
    "                        if not specified.\n",
    "                      format: int32\n",
    "                      type: integer\n",
    "                    communities:\n",
    "                      description: BGP communities\n",
    "                      items:\n",
    "                        type: string\n",
    "                      type: array\n",
    "                    localPref:\n",
    "                      description: BGP LOCAL_PREF attribute which is used by BGP best\n",
    "                        path algorithm, Path with higher localpref is preferred over\n",
    "                        one with lower localpref.\n",
    "                      format: int32\n",
    "                      type: integer\n",
    "                  type: object\n",
    "                type: array\n",
    "              protocol:\n",
    "                description: Protocol can be used to select how the announcement is\n",
    "                  done.\n",
    "                enum:\n",
    "                - layer2\n",
    "                - bgp\n",
    "                type: string\n",
    "            required:\n",
    "            - addresses\n",
    "            - protocol\n",
    "            type: object\n",
    "          status:\n",
    "            description: AddressPoolStatus defines the observed state of AddressPool.\n",
    "            type: object\n",
    "        required:\n",
    "        - spec\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: false\n",
    "    subresources:\n",
    "      status: {}\n",
    "  - deprecated: true\n",
    "    deprecationWarning: metallb.io v1beta1 AddressPool is deprecated, consider using\n",
    "      IPAddressPool\n",
    "    name: v1beta1\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: AddressPool represents a pool of IP addresses that can be allocated\n",
    "          to LoadBalancer services. AddressPool is deprecated and being replaced by\n",
    "          IPAddressPool.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: AddressPoolSpec defines the desired state of AddressPool.\n",
    "            properties:\n",
    "              addresses:\n",
    "                description: A list of IP address ranges over which MetalLB has authority.\n",
    "                  You can list multiple ranges in a single pool, they will all share\n",
    "                  the same settings. Each range can be either a CIDR prefix, or an\n",
    "                  explicit start-end range of IPs.\n",
    "                items:\n",
    "                  type: string\n",
    "                type: array\n",
    "              autoAssign:\n",
    "                default: true\n",
    "                description: AutoAssign flag used to prevent MetallB from automatic\n",
    "                  allocation for a pool.\n",
    "                type: boolean\n",
    "              bgpAdvertisements:\n",
    "                description: Drives how an IP allocated from this pool should translated\n",
    "                  into BGP announcements.\n",
    "                items:\n",
    "                  properties:\n",
    "                    aggregationLength:\n",
    "                      default: 32\n",
    "                      description: The aggregation-length advertisement option lets\n",
    "                        you “roll up” the /32s into a larger prefix.\n",
    "                      format: int32\n",
    "                      minimum: 1\n",
    "                      type: integer\n",
    "                    aggregationLengthV6:\n",
    "                      default: 128\n",
    "                      description: Optional, defaults to 128 (i.e. no aggregation)\n",
    "                        if not specified.\n",
    "                      format: int32\n",
    "                      type: integer\n",
    "                    communities:\n",
    "                      description: BGP communities to be associated with the given\n",
    "                        advertisement.\n",
    "                      items:\n",
    "                        type: string\n",
    "                      type: array\n",
    "                    localPref:\n",
    "                      description: BGP LOCAL_PREF attribute which is used by BGP best\n",
    "                        path algorithm, Path with higher localpref is preferred over\n",
    "                        one with lower localpref.\n",
    "                      format: int32\n",
    "                      type: integer\n",
    "                  type: object\n",
    "                type: array\n",
    "              protocol:\n",
    "                description: Protocol can be used to select how the announcement is\n",
    "                  done.\n",
    "                enum:\n",
    "                - layer2\n",
    "                - bgp\n",
    "                type: string\n",
    "            required:\n",
    "            - addresses\n",
    "            - protocol\n",
    "            type: object\n",
    "          status:\n",
    "            description: AddressPoolStatus defines the observed state of AddressPool.\n",
    "            type: object\n",
    "        required:\n",
    "        - spec\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: true\n",
    "    subresources:\n",
    "      status: {}\n",
    "---\n",
    "apiVersion: apiextensions.k8s.io/v1\n",
    "kind: CustomResourceDefinition\n",
    "metadata:\n",
    "  annotations:\n",
    "    controller-gen.kubebuilder.io/version: v0.11.1\n",
    "  creationTimestamp: null\n",
    "  name: bfdprofiles.metallb.io\n",
    "spec:\n",
    "  group: metallb.io\n",
    "  names:\n",
    "    kind: BFDProfile\n",
    "    listKind: BFDProfileList\n",
    "    plural: bfdprofiles\n",
    "    singular: bfdprofile\n",
    "  scope: Namespaced\n",
    "  versions:\n",
    "  - additionalPrinterColumns:\n",
    "    - jsonPath: .spec.passiveMode\n",
    "      name: Passive Mode\n",
    "      type: boolean\n",
    "    - jsonPath: .spec.transmitInterval\n",
    "      name: Transmit Interval\n",
    "      type: integer\n",
    "    - jsonPath: .spec.receiveInterval\n",
    "      name: Receive Interval\n",
    "      type: integer\n",
    "    - jsonPath: .spec.detectMultiplier\n",
    "      name: Multiplier\n",
    "      type: integer\n",
    "    name: v1beta1\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: BFDProfile represents the settings of the bfd session that can\n",
    "          be optionally associated with a BGP session.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: BFDProfileSpec defines the desired state of BFDProfile.\n",
    "            properties:\n",
    "              detectMultiplier:\n",
    "                description: Configures the detection multiplier to determine packet\n",
    "                  loss. The remote transmission interval will be multiplied by this\n",
    "                  value to determine the connection loss detection timer.\n",
    "                format: int32\n",
    "                maximum: 255\n",
    "                minimum: 2\n",
    "                type: integer\n",
    "              echoInterval:\n",
    "                description: Configures the minimal echo receive transmission interval\n",
    "                  that this system is capable of handling in milliseconds. Defaults\n",
    "                  to 50ms\n",
    "                format: int32\n",
    "                maximum: 60000\n",
    "                minimum: 10\n",
    "                type: integer\n",
    "              echoMode:\n",
    "                description: Enables or disables the echo transmission mode. This\n",
    "                  mode is disabled by default, and not supported on multi hops setups.\n",
    "                type: boolean\n",
    "              minimumTtl:\n",
    "                description: 'For multi hop sessions only: configure the minimum expected\n",
    "                  TTL for an incoming BFD control packet.'\n",
    "                format: int32\n",
    "                maximum: 254\n",
    "                minimum: 1\n",
    "                type: integer\n",
    "              passiveMode:\n",
    "                description: 'Mark session as passive: a passive session will not\n",
    "                  attempt to start the connection and will wait for control packets\n",
    "                  from peer before it begins replying.'\n",
    "                type: boolean\n",
    "              receiveInterval:\n",
    "                description: The minimum interval that this system is capable of receiving\n",
    "                  control packets in milliseconds. Defaults to 300ms.\n",
    "                format: int32\n",
    "                maximum: 60000\n",
    "                minimum: 10\n",
    "                type: integer\n",
    "              transmitInterval:\n",
    "                description: The minimum transmission interval (less jitter) that\n",
    "                  this system wants to use to send BFD control packets in milliseconds.\n",
    "                  Defaults to 300ms\n",
    "                format: int32\n",
    "                maximum: 60000\n",
    "                minimum: 10\n",
    "                type: integer\n",
    "            type: object\n",
    "          status:\n",
    "            description: BFDProfileStatus defines the observed state of BFDProfile.\n",
    "            type: object\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: true\n",
    "    subresources:\n",
    "      status: {}\n",
    "---\n",
    "apiVersion: apiextensions.k8s.io/v1\n",
    "kind: CustomResourceDefinition\n",
    "metadata:\n",
    "  annotations:\n",
    "    controller-gen.kubebuilder.io/version: v0.11.1\n",
    "  creationTimestamp: null\n",
    "  name: bgpadvertisements.metallb.io\n",
    "spec:\n",
    "  group: metallb.io\n",
    "  names:\n",
    "    kind: BGPAdvertisement\n",
    "    listKind: BGPAdvertisementList\n",
    "    plural: bgpadvertisements\n",
    "    singular: bgpadvertisement\n",
    "  scope: Namespaced\n",
    "  versions:\n",
    "  - additionalPrinterColumns:\n",
    "    - jsonPath: .spec.ipAddressPools\n",
    "      name: IPAddressPools\n",
    "      type: string\n",
    "    - jsonPath: .spec.ipAddressPoolSelectors\n",
    "      name: IPAddressPool Selectors\n",
    "      type: string\n",
    "    - jsonPath: .spec.peers\n",
    "      name: Peers\n",
    "      type: string\n",
    "    - jsonPath: .spec.nodeSelectors\n",
    "      name: Node Selectors\n",
    "      priority: 10\n",
    "      type: string\n",
    "    name: v1beta1\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: BGPAdvertisement allows to advertise the IPs coming from the\n",
    "          selected IPAddressPools via BGP, setting the parameters of the BGP Advertisement.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: BGPAdvertisementSpec defines the desired state of BGPAdvertisement.\n",
    "            properties:\n",
    "              aggregationLength:\n",
    "                default: 32\n",
    "                description: The aggregation-length advertisement option lets you\n",
    "                  “roll up” the /32s into a larger prefix. Defaults to 32. Works for\n",
    "                  IPv4 addresses.\n",
    "                format: int32\n",
    "                minimum: 1\n",
    "                type: integer\n",
    "              aggregationLengthV6:\n",
    "                default: 128\n",
    "                description: The aggregation-length advertisement option lets you\n",
    "                  “roll up” the /128s into a larger prefix. Defaults to 128. Works\n",
    "                  for IPv6 addresses.\n",
    "                format: int32\n",
    "                type: integer\n",
    "              communities:\n",
    "                description: The BGP communities to be associated with the announcement.\n",
    "                  Each item can be a community of the form 1234:1234 or the name of\n",
    "                  an alias defined in the Community CRD.\n",
    "                items:\n",
    "                  type: string\n",
    "                type: array\n",
    "              ipAddressPoolSelectors:\n",
    "                description: A selector for the IPAddressPools which would get advertised\n",
    "                  via this advertisement. If no IPAddressPool is selected by this\n",
    "                  or by the list, the advertisement is applied to all the IPAddressPools.\n",
    "                items:\n",
    "                  description: A label selector is a label query over a set of resources.\n",
    "                    The result of matchLabels and matchExpressions are ANDed. An empty\n",
    "                    label selector matches all objects. A null label selector matches\n",
    "                    no objects.\n",
    "                  properties:\n",
    "                    matchExpressions:\n",
    "                      description: matchExpressions is a list of label selector requirements.\n",
    "                        The requirements are ANDed.\n",
    "                      items:\n",
    "                        description: A label selector requirement is a selector that\n",
    "                          contains values, a key, and an operator that relates the\n",
    "                          key and values.\n",
    "                        properties:\n",
    "                          key:\n",
    "                            description: key is the label key that the selector applies\n",
    "                              to.\n",
    "                            type: string\n",
    "                          operator:\n",
    "                            description: operator represents a key's relationship\n",
    "                              to a set of values. Valid operators are In, NotIn, Exists\n",
    "                              and DoesNotExist.\n",
    "                            type: string\n",
    "                          values:\n",
    "                            description: values is an array of string values. If the\n",
    "                              operator is In or NotIn, the values array must be non-empty.\n",
    "                              If the operator is Exists or DoesNotExist, the values\n",
    "                              array must be empty. This array is replaced during a\n",
    "                              strategic merge patch.\n",
    "                            items:\n",
    "                              type: string\n",
    "                            type: array\n",
    "                        required:\n",
    "                        - key\n",
    "                        - operator\n",
    "                        type: object\n",
    "                      type: array\n",
    "                    matchLabels:\n",
    "                      additionalProperties:\n",
    "                        type: string\n",
    "                      description: matchLabels is a map of {key,value} pairs. A single\n",
    "                        {key,value} in the matchLabels map is equivalent to an element\n",
    "                        of matchExpressions, whose key field is \"key\", the operator\n",
    "                        is \"In\", and the values array contains only \"value\". The requirements\n",
    "                        are ANDed.\n",
    "                      type: object\n",
    "                  type: object\n",
    "                  x-kubernetes-map-type: atomic\n",
    "                type: array\n",
    "              ipAddressPools:\n",
    "                description: The list of IPAddressPools to advertise via this advertisement,\n",
    "                  selected by name.\n",
    "                items:\n",
    "                  type: string\n",
    "                type: array\n",
    "              localPref:\n",
    "                description: The BGP LOCAL_PREF attribute which is used by BGP best\n",
    "                  path algorithm, Path with higher localpref is preferred over one\n",
    "                  with lower localpref.\n",
    "                format: int32\n",
    "                type: integer\n",
    "              nodeSelectors:\n",
    "                description: NodeSelectors allows to limit the nodes to announce as\n",
    "                  next hops for the LoadBalancer IP. When empty, all the nodes having  are\n",
    "                  announced as next hops.\n",
    "                items:\n",
    "                  description: A label selector is a label query over a set of resources.\n",
    "                    The result of matchLabels and matchExpressions are ANDed. An empty\n",
    "                    label selector matches all objects. A null label selector matches\n",
    "                    no objects.\n",
    "                  properties:\n",
    "                    matchExpressions:\n",
    "                      description: matchExpressions is a list of label selector requirements.\n",
    "                        The requirements are ANDed.\n",
    "                      items:\n",
    "                        description: A label selector requirement is a selector that\n",
    "                          contains values, a key, and an operator that relates the\n",
    "                          key and values.\n",
    "                        properties:\n",
    "                          key:\n",
    "                            description: key is the label key that the selector applies\n",
    "                              to.\n",
    "                            type: string\n",
    "                          operator:\n",
    "                            description: operator represents a key's relationship\n",
    "                              to a set of values. Valid operators are In, NotIn, Exists\n",
    "                              and DoesNotExist.\n",
    "                            type: string\n",
    "                          values:\n",
    "                            description: values is an array of string values. If the\n",
    "                              operator is In or NotIn, the values array must be non-empty.\n",
    "                              If the operator is Exists or DoesNotExist, the values\n",
    "                              array must be empty. This array is replaced during a\n",
    "                              strategic merge patch.\n",
    "                            items:\n",
    "                              type: string\n",
    "                            type: array\n",
    "                        required:\n",
    "                        - key\n",
    "                        - operator\n",
    "                        type: object\n",
    "                      type: array\n",
    "                    matchLabels:\n",
    "                      additionalProperties:\n",
    "                        type: string\n",
    "                      description: matchLabels is a map of {key,value} pairs. A single\n",
    "                        {key,value} in the matchLabels map is equivalent to an element\n",
    "                        of matchExpressions, whose key field is \"key\", the operator\n",
    "                        is \"In\", and the values array contains only \"value\". The requirements\n",
    "                        are ANDed.\n",
    "                      type: object\n",
    "                  type: object\n",
    "                  x-kubernetes-map-type: atomic\n",
    "                type: array\n",
    "              peers:\n",
    "                description: Peers limits the bgppeer to advertise the ips of the\n",
    "                  selected pools to. When empty, the loadbalancer IP is announced\n",
    "                  to all the BGPPeers configured.\n",
    "                items:\n",
    "                  type: string\n",
    "                type: array\n",
    "            type: object\n",
    "          status:\n",
    "            description: BGPAdvertisementStatus defines the observed state of BGPAdvertisement.\n",
    "            type: object\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: true\n",
    "    subresources:\n",
    "      status: {}\n",
    "---\n",
    "apiVersion: apiextensions.k8s.io/v1\n",
    "kind: CustomResourceDefinition\n",
    "metadata:\n",
    "  annotations:\n",
    "    controller-gen.kubebuilder.io/version: v0.11.1\n",
    "  name: bgppeers.metallb.io\n",
    "spec:\n",
    "  conversion:\n",
    "    strategy: Webhook\n",
    "    webhook:\n",
    "      clientConfig:\n",
    "        caBundle: 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\n",
    "        service:\n",
    "          name: webhook-service\n",
    "          namespace: metallb-system\n",
    "          path: /convert\n",
    "      conversionReviewVersions:\n",
    "      - v1beta1\n",
    "      - v1beta2\n",
    "  group: metallb.io\n",
    "  names:\n",
    "    kind: BGPPeer\n",
    "    listKind: BGPPeerList\n",
    "    plural: bgppeers\n",
    "    singular: bgppeer\n",
    "  scope: Namespaced\n",
    "  versions:\n",
    "  - additionalPrinterColumns:\n",
    "    - jsonPath: .spec.peerAddress\n",
    "      name: Address\n",
    "      type: string\n",
    "    - jsonPath: .spec.peerASN\n",
    "      name: ASN\n",
    "      type: string\n",
    "    - jsonPath: .spec.bfdProfile\n",
    "      name: BFD Profile\n",
    "      type: string\n",
    "    - jsonPath: .spec.ebgpMultiHop\n",
    "      name: Multi Hops\n",
    "      type: string\n",
    "    name: v1beta1\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: BGPPeer is the Schema for the peers API.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: BGPPeerSpec defines the desired state of Peer.\n",
    "            properties:\n",
    "              bfdProfile:\n",
    "                type: string\n",
    "              ebgpMultiHop:\n",
    "                description: EBGP peer is multi-hops away\n",
    "                type: boolean\n",
    "              holdTime:\n",
    "                description: Requested BGP hold time, per RFC4271.\n",
    "                type: string\n",
    "              keepaliveTime:\n",
    "                description: Requested BGP keepalive time, per RFC4271.\n",
    "                type: string\n",
    "              myASN:\n",
    "                description: AS number to use for the local end of the session.\n",
    "                format: int32\n",
    "                maximum: 4294967295\n",
    "                minimum: 0\n",
    "                type: integer\n",
    "              nodeSelectors:\n",
    "                description: Only connect to this peer on nodes that match one of\n",
    "                  these selectors.\n",
    "                items:\n",
    "                  properties:\n",
    "                    matchExpressions:\n",
    "                      items:\n",
    "                        properties:\n",
    "                          key:\n",
    "                            type: string\n",
    "                          operator:\n",
    "                            type: string\n",
    "                          values:\n",
    "                            items:\n",
    "                              type: string\n",
    "                            minItems: 1\n",
    "                            type: array\n",
    "                        required:\n",
    "                        - key\n",
    "                        - operator\n",
    "                        - values\n",
    "                        type: object\n",
    "                      type: array\n",
    "                    matchLabels:\n",
    "                      additionalProperties:\n",
    "                        type: string\n",
    "                      type: object\n",
    "                  type: object\n",
    "                type: array\n",
    "              password:\n",
    "                description: Authentication password for routers enforcing TCP MD5\n",
    "                  authenticated sessions\n",
    "                type: string\n",
    "              peerASN:\n",
    "                description: AS number to expect from the remote end of the session.\n",
    "                format: int32\n",
    "                maximum: 4294967295\n",
    "                minimum: 0\n",
    "                type: integer\n",
    "              peerAddress:\n",
    "                description: Address to dial when establishing the session.\n",
    "                type: string\n",
    "              peerPort:\n",
    "                description: Port to dial when establishing the session.\n",
    "                maximum: 16384\n",
    "                minimum: 0\n",
    "                type: integer\n",
    "              routerID:\n",
    "                description: BGP router ID to advertise to the peer\n",
    "                type: string\n",
    "              sourceAddress:\n",
    "                description: Source address to use when establishing the session.\n",
    "                type: string\n",
    "            required:\n",
    "            - myASN\n",
    "            - peerASN\n",
    "            - peerAddress\n",
    "            type: object\n",
    "          status:\n",
    "            description: BGPPeerStatus defines the observed state of Peer.\n",
    "            type: object\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: false\n",
    "    subresources:\n",
    "      status: {}\n",
    "  - additionalPrinterColumns:\n",
    "    - jsonPath: .spec.peerAddress\n",
    "      name: Address\n",
    "      type: string\n",
    "    - jsonPath: .spec.peerASN\n",
    "      name: ASN\n",
    "      type: string\n",
    "    - jsonPath: .spec.bfdProfile\n",
    "      name: BFD Profile\n",
    "      type: string\n",
    "    - jsonPath: .spec.ebgpMultiHop\n",
    "      name: Multi Hops\n",
    "      type: string\n",
    "    name: v1beta2\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: BGPPeer is the Schema for the peers API.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: BGPPeerSpec defines the desired state of Peer.\n",
    "            properties:\n",
    "              bfdProfile:\n",
    "                description: The name of the BFD Profile to be used for the BFD session\n",
    "                  associated to the BGP session. If not set, the BFD session won't\n",
    "                  be set up.\n",
    "                type: string\n",
    "              ebgpMultiHop:\n",
    "                description: To set if the BGPPeer is multi-hops away. Needed for\n",
    "                  FRR mode only.\n",
    "                type: boolean\n",
    "              holdTime:\n",
    "                description: Requested BGP hold time, per RFC4271.\n",
    "                type: string\n",
    "              keepaliveTime:\n",
    "                description: Requested BGP keepalive time, per RFC4271.\n",
    "                type: string\n",
    "              myASN:\n",
    "                description: AS number to use for the local end of the session.\n",
    "                format: int32\n",
    "                maximum: 4294967295\n",
    "                minimum: 0\n",
    "                type: integer\n",
    "              nodeSelectors:\n",
    "                description: Only connect to this peer on nodes that match one of\n",
    "                  these selectors.\n",
    "                items:\n",
    "                  description: A label selector is a label query over a set of resources.\n",
    "                    The result of matchLabels and matchExpressions are ANDed. An empty\n",
    "                    label selector matches all objects. A null label selector matches\n",
    "                    no objects.\n",
    "                  properties:\n",
    "                    matchExpressions:\n",
    "                      description: matchExpressions is a list of label selector requirements.\n",
    "                        The requirements are ANDed.\n",
    "                      items:\n",
    "                        description: A label selector requirement is a selector that\n",
    "                          contains values, a key, and an operator that relates the\n",
    "                          key and values.\n",
    "                        properties:\n",
    "                          key:\n",
    "                            description: key is the label key that the selector applies\n",
    "                              to.\n",
    "                            type: string\n",
    "                          operator:\n",
    "                            description: operator represents a key's relationship\n",
    "                              to a set of values. Valid operators are In, NotIn, Exists\n",
    "                              and DoesNotExist.\n",
    "                            type: string\n",
    "                          values:\n",
    "                            description: values is an array of string values. If the\n",
    "                              operator is In or NotIn, the values array must be non-empty.\n",
    "                              If the operator is Exists or DoesNotExist, the values\n",
    "                              array must be empty. This array is replaced during a\n",
    "                              strategic merge patch.\n",
    "                            items:\n",
    "                              type: string\n",
    "                            type: array\n",
    "                        required:\n",
    "                        - key\n",
    "                        - operator\n",
    "                        type: object\n",
    "                      type: array\n",
    "                    matchLabels:\n",
    "                      additionalProperties:\n",
    "                        type: string\n",
    "                      description: matchLabels is a map of {key,value} pairs. A single\n",
    "                        {key,value} in the matchLabels map is equivalent to an element\n",
    "                        of matchExpressions, whose key field is \"key\", the operator\n",
    "                        is \"In\", and the values array contains only \"value\". The requirements\n",
    "                        are ANDed.\n",
    "                      type: object\n",
    "                  type: object\n",
    "                  x-kubernetes-map-type: atomic\n",
    "                type: array\n",
    "              password:\n",
    "                description: Authentication password for routers enforcing TCP MD5\n",
    "                  authenticated sessions\n",
    "                type: string\n",
    "              passwordSecret:\n",
    "                description: passwordSecret is name of the authentication secret for\n",
    "                  BGP Peer. the secret must be of type \"kubernetes.io/basic-auth\",\n",
    "                  and created in the same namespace as the MetalLB deployment. The\n",
    "                  password is stored in the secret as the key \"password\".\n",
    "                properties:\n",
    "                  name:\n",
    "                    description: name is unique within a namespace to reference a\n",
    "                      secret resource.\n",
    "                    type: string\n",
    "                  namespace:\n",
    "                    description: namespace defines the space within which the secret\n",
    "                      name must be unique.\n",
    "                    type: string\n",
    "                type: object\n",
    "                x-kubernetes-map-type: atomic\n",
    "              peerASN:\n",
    "                description: AS number to expect from the remote end of the session.\n",
    "                format: int32\n",
    "                maximum: 4294967295\n",
    "                minimum: 0\n",
    "                type: integer\n",
    "              peerAddress:\n",
    "                description: Address to dial when establishing the session.\n",
    "                type: string\n",
    "              peerPort:\n",
    "                default: 179\n",
    "                description: Port to dial when establishing the session.\n",
    "                maximum: 16384\n",
    "                minimum: 0\n",
    "                type: integer\n",
    "              routerID:\n",
    "                description: BGP router ID to advertise to the peer\n",
    "                type: string\n",
    "              sourceAddress:\n",
    "                description: Source address to use when establishing the session.\n",
    "                type: string\n",
    "              vrf:\n",
    "                description: To set if we want to peer with the BGPPeer using an interface\n",
    "                  belonging to a host vrf\n",
    "                type: string\n",
    "            required:\n",
    "            - myASN\n",
    "            - peerASN\n",
    "            - peerAddress\n",
    "            type: object\n",
    "          status:\n",
    "            description: BGPPeerStatus defines the observed state of Peer.\n",
    "            type: object\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: true\n",
    "    subresources:\n",
    "      status: {}\n",
    "---\n",
    "apiVersion: apiextensions.k8s.io/v1\n",
    "kind: CustomResourceDefinition\n",
    "metadata:\n",
    "  annotations:\n",
    "    controller-gen.kubebuilder.io/version: v0.11.1\n",
    "  creationTimestamp: null\n",
    "  name: communities.metallb.io\n",
    "spec:\n",
    "  group: metallb.io\n",
    "  names:\n",
    "    kind: Community\n",
    "    listKind: CommunityList\n",
    "    plural: communities\n",
    "    singular: community\n",
    "  scope: Namespaced\n",
    "  versions:\n",
    "  - name: v1beta1\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: Community is a collection of aliases for communities. Users can\n",
    "          define named aliases to be used in the BGPPeer CRD.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: CommunitySpec defines the desired state of Community.\n",
    "            properties:\n",
    "              communities:\n",
    "                items:\n",
    "                  properties:\n",
    "                    name:\n",
    "                      description: The name of the alias for the community.\n",
    "                      type: string\n",
    "                    value:\n",
    "                      description: The BGP community value corresponding to the given\n",
    "                        name.\n",
    "                      type: string\n",
    "                  type: object\n",
    "                type: array\n",
    "            type: object\n",
    "          status:\n",
    "            description: CommunityStatus defines the observed state of Community.\n",
    "            type: object\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: true\n",
    "    subresources:\n",
    "      status: {}\n",
    "---\n",
    "apiVersion: apiextensions.k8s.io/v1\n",
    "kind: CustomResourceDefinition\n",
    "metadata:\n",
    "  annotations:\n",
    "    controller-gen.kubebuilder.io/version: v0.11.1\n",
    "  creationTimestamp: null\n",
    "  name: ipaddresspools.metallb.io\n",
    "spec:\n",
    "  group: metallb.io\n",
    "  names:\n",
    "    kind: IPAddressPool\n",
    "    listKind: IPAddressPoolList\n",
    "    plural: ipaddresspools\n",
    "    singular: ipaddresspool\n",
    "  scope: Namespaced\n",
    "  versions:\n",
    "  - additionalPrinterColumns:\n",
    "    - jsonPath: .spec.autoAssign\n",
    "      name: Auto Assign\n",
    "      type: boolean\n",
    "    - jsonPath: .spec.avoidBuggyIPs\n",
    "      name: Avoid Buggy IPs\n",
    "      type: boolean\n",
    "    - jsonPath: .spec.addresses\n",
    "      name: Addresses\n",
    "      type: string\n",
    "    name: v1beta1\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: IPAddressPool represents a pool of IP addresses that can be allocated\n",
    "          to LoadBalancer services.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: IPAddressPoolSpec defines the desired state of IPAddressPool.\n",
    "            properties:\n",
    "              addresses:\n",
    "                description: A list of IP address ranges over which MetalLB has authority.\n",
    "                  You can list multiple ranges in a single pool, they will all share\n",
    "                  the same settings. Each range can be either a CIDR prefix, or an\n",
    "                  explicit start-end range of IPs.\n",
    "                items:\n",
    "                  type: string\n",
    "                type: array\n",
    "              autoAssign:\n",
    "                default: true\n",
    "                description: AutoAssign flag used to prevent MetallB from automatic\n",
    "                  allocation for a pool.\n",
    "                type: boolean\n",
    "              avoidBuggyIPs:\n",
    "                default: false\n",
    "                description: AvoidBuggyIPs prevents addresses ending with .0 and .255\n",
    "                  to be used by a pool.\n",
    "                type: boolean\n",
    "              serviceAllocation:\n",
    "                description: AllocateTo makes ip pool allocation to specific namespace\n",
    "                  and/or service. The controller will use the pool with lowest value\n",
    "                  of priority in case of multiple matches. A pool with no priority\n",
    "                  set will be used only if the pools with priority can't be used.\n",
    "                  If multiple matching IPAddressPools are available it will check\n",
    "                  for the availability of IPs sorting the matching IPAddressPools\n",
    "                  by priority, starting from the highest to the lowest. If multiple\n",
    "                  IPAddressPools have the same priority, choice will be random.\n",
    "                properties:\n",
    "                  namespaceSelectors:\n",
    "                    description: NamespaceSelectors list of label selectors to select\n",
    "                      namespace(s) for ip pool, an alternative to using namespace\n",
    "                      list.\n",
    "                    items:\n",
    "                      description: A label selector is a label query over a set of\n",
    "                        resources. The result of matchLabels and matchExpressions\n",
    "                        are ANDed. An empty label selector matches all objects. A\n",
    "                        null label selector matches no objects.\n",
    "                      properties:\n",
    "                        matchExpressions:\n",
    "                          description: matchExpressions is a list of label selector\n",
    "                            requirements. The requirements are ANDed.\n",
    "                          items:\n",
    "                            description: A label selector requirement is a selector\n",
    "                              that contains values, a key, and an operator that relates\n",
    "                              the key and values.\n",
    "                            properties:\n",
    "                              key:\n",
    "                                description: key is the label key that the selector\n",
    "                                  applies to.\n",
    "                                type: string\n",
    "                              operator:\n",
    "                                description: operator represents a key's relationship\n",
    "                                  to a set of values. Valid operators are In, NotIn,\n",
    "                                  Exists and DoesNotExist.\n",
    "                                type: string\n",
    "                              values:\n",
    "                                description: values is an array of string values.\n",
    "                                  If the operator is In or NotIn, the values array\n",
    "                                  must be non-empty. If the operator is Exists or\n",
    "                                  DoesNotExist, the values array must be empty. This\n",
    "                                  array is replaced during a strategic merge patch.\n",
    "                                items:\n",
    "                                  type: string\n",
    "                                type: array\n",
    "                            required:\n",
    "                            - key\n",
    "                            - operator\n",
    "                            type: object\n",
    "                          type: array\n",
    "                        matchLabels:\n",
    "                          additionalProperties:\n",
    "                            type: string\n",
    "                          description: matchLabels is a map of {key,value} pairs.\n",
    "                            A single {key,value} in the matchLabels map is equivalent\n",
    "                            to an element of matchExpressions, whose key field is\n",
    "                            \"key\", the operator is \"In\", and the values array contains\n",
    "                            only \"value\". The requirements are ANDed.\n",
    "                          type: object\n",
    "                      type: object\n",
    "                      x-kubernetes-map-type: atomic\n",
    "                    type: array\n",
    "                  namespaces:\n",
    "                    description: Namespaces list of namespace(s) on which ip pool\n",
    "                      can be attached.\n",
    "                    items:\n",
    "                      type: string\n",
    "                    type: array\n",
    "                  priority:\n",
    "                    description: Priority priority given for ip pool while ip allocation\n",
    "                      on a service.\n",
    "                    type: integer\n",
    "                  serviceSelectors:\n",
    "                    description: ServiceSelectors list of label selector to select\n",
    "                      service(s) for which ip pool can be used for ip allocation.\n",
    "                    items:\n",
    "                      description: A label selector is a label query over a set of\n",
    "                        resources. The result of matchLabels and matchExpressions\n",
    "                        are ANDed. An empty label selector matches all objects. A\n",
    "                        null label selector matches no objects.\n",
    "                      properties:\n",
    "                        matchExpressions:\n",
    "                          description: matchExpressions is a list of label selector\n",
    "                            requirements. The requirements are ANDed.\n",
    "                          items:\n",
    "                            description: A label selector requirement is a selector\n",
    "                              that contains values, a key, and an operator that relates\n",
    "                              the key and values.\n",
    "                            properties:\n",
    "                              key:\n",
    "                                description: key is the label key that the selector\n",
    "                                  applies to.\n",
    "                                type: string\n",
    "                              operator:\n",
    "                                description: operator represents a key's relationship\n",
    "                                  to a set of values. Valid operators are In, NotIn,\n",
    "                                  Exists and DoesNotExist.\n",
    "                                type: string\n",
    "                              values:\n",
    "                                description: values is an array of string values.\n",
    "                                  If the operator is In or NotIn, the values array\n",
    "                                  must be non-empty. If the operator is Exists or\n",
    "                                  DoesNotExist, the values array must be empty. This\n",
    "                                  array is replaced during a strategic merge patch.\n",
    "                                items:\n",
    "                                  type: string\n",
    "                                type: array\n",
    "                            required:\n",
    "                            - key\n",
    "                            - operator\n",
    "                            type: object\n",
    "                          type: array\n",
    "                        matchLabels:\n",
    "                          additionalProperties:\n",
    "                            type: string\n",
    "                          description: matchLabels is a map of {key,value} pairs.\n",
    "                            A single {key,value} in the matchLabels map is equivalent\n",
    "                            to an element of matchExpressions, whose key field is\n",
    "                            \"key\", the operator is \"In\", and the values array contains\n",
    "                            only \"value\". The requirements are ANDed.\n",
    "                          type: object\n",
    "                      type: object\n",
    "                      x-kubernetes-map-type: atomic\n",
    "                    type: array\n",
    "                type: object\n",
    "            required:\n",
    "            - addresses\n",
    "            type: object\n",
    "          status:\n",
    "            description: IPAddressPoolStatus defines the observed state of IPAddressPool.\n",
    "            type: object\n",
    "        required:\n",
    "        - spec\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: true\n",
    "    subresources:\n",
    "      status: {}\n",
    "---\n",
    "apiVersion: apiextensions.k8s.io/v1\n",
    "kind: CustomResourceDefinition\n",
    "metadata:\n",
    "  annotations:\n",
    "    controller-gen.kubebuilder.io/version: v0.11.1\n",
    "  creationTimestamp: null\n",
    "  name: l2advertisements.metallb.io\n",
    "spec:\n",
    "  group: metallb.io\n",
    "  names:\n",
    "    kind: L2Advertisement\n",
    "    listKind: L2AdvertisementList\n",
    "    plural: l2advertisements\n",
    "    singular: l2advertisement\n",
    "  scope: Namespaced\n",
    "  versions:\n",
    "  - additionalPrinterColumns:\n",
    "    - jsonPath: .spec.ipAddressPools\n",
    "      name: IPAddressPools\n",
    "      type: string\n",
    "    - jsonPath: .spec.ipAddressPoolSelectors\n",
    "      name: IPAddressPool Selectors\n",
    "      type: string\n",
    "    - jsonPath: .spec.interfaces\n",
    "      name: Interfaces\n",
    "      type: string\n",
    "    - jsonPath: .spec.nodeSelectors\n",
    "      name: Node Selectors\n",
    "      priority: 10\n",
    "      type: string\n",
    "    name: v1beta1\n",
    "    schema:\n",
    "      openAPIV3Schema:\n",
    "        description: L2Advertisement allows to advertise the LoadBalancer IPs provided\n",
    "          by the selected pools via L2.\n",
    "        properties:\n",
    "          apiVersion:\n",
    "            description: 'APIVersion defines the versioned schema of this representation\n",
    "              of an object. Servers should convert recognized schemas to the latest\n",
    "              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'\n",
    "            type: string\n",
    "          kind:\n",
    "            description: 'Kind is a string value representing the REST resource this\n",
    "              object represents. Servers may infer this from the endpoint the client\n",
    "              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'\n",
    "            type: string\n",
    "          metadata:\n",
    "            type: object\n",
    "          spec:\n",
    "            description: L2AdvertisementSpec defines the desired state of L2Advertisement.\n",
    "            properties:\n",
    "              interfaces:\n",
    "                description: A list of interfaces to announce from. The LB IP will\n",
    "                  be announced only from these interfaces. If the field is not set,\n",
    "                  we advertise from all the interfaces on the host.\n",
    "                items:\n",
    "                  type: string\n",
    "                type: array\n",
    "              ipAddressPoolSelectors:\n",
    "                description: A selector for the IPAddressPools which would get advertised\n",
    "                  via this advertisement. If no IPAddressPool is selected by this\n",
    "                  or by the list, the advertisement is applied to all the IPAddressPools.\n",
    "                items:\n",
    "                  description: A label selector is a label query over a set of resources.\n",
    "                    The result of matchLabels and matchExpressions are ANDed. An empty\n",
    "                    label selector matches all objects. A null label selector matches\n",
    "                    no objects.\n",
    "                  properties:\n",
    "                    matchExpressions:\n",
    "                      description: matchExpressions is a list of label selector requirements.\n",
    "                        The requirements are ANDed.\n",
    "                      items:\n",
    "                        description: A label selector requirement is a selector that\n",
    "                          contains values, a key, and an operator that relates the\n",
    "                          key and values.\n",
    "                        properties:\n",
    "                          key:\n",
    "                            description: key is the label key that the selector applies\n",
    "                              to.\n",
    "                            type: string\n",
    "                          operator:\n",
    "                            description: operator represents a key's relationship\n",
    "                              to a set of values. Valid operators are In, NotIn, Exists\n",
    "                              and DoesNotExist.\n",
    "                            type: string\n",
    "                          values:\n",
    "                            description: values is an array of string values. If the\n",
    "                              operator is In or NotIn, the values array must be non-empty.\n",
    "                              If the operator is Exists or DoesNotExist, the values\n",
    "                              array must be empty. This array is replaced during a\n",
    "                              strategic merge patch.\n",
    "                            items:\n",
    "                              type: string\n",
    "                            type: array\n",
    "                        required:\n",
    "                        - key\n",
    "                        - operator\n",
    "                        type: object\n",
    "                      type: array\n",
    "                    matchLabels:\n",
    "                      additionalProperties:\n",
    "                        type: string\n",
    "                      description: matchLabels is a map of {key,value} pairs. A single\n",
    "                        {key,value} in the matchLabels map is equivalent to an element\n",
    "                        of matchExpressions, whose key field is \"key\", the operator\n",
    "                        is \"In\", and the values array contains only \"value\". The requirements\n",
    "                        are ANDed.\n",
    "                      type: object\n",
    "                  type: object\n",
    "                  x-kubernetes-map-type: atomic\n",
    "                type: array\n",
    "              ipAddressPools:\n",
    "                description: The list of IPAddressPools to advertise via this advertisement,\n",
    "                  selected by name.\n",
    "                items:\n",
    "                  type: string\n",
    "                type: array\n",
    "              nodeSelectors:\n",
    "                description: NodeSelectors allows to limit the nodes to announce as\n",
    "                  next hops for the LoadBalancer IP. When empty, all the nodes having  are\n",
    "                  announced as next hops.\n",
    "                items:\n",
    "                  description: A label selector is a label query over a set of resources.\n",
    "                    The result of matchLabels and matchExpressions are ANDed. An empty\n",
    "                    label selector matches all objects. A null label selector matches\n",
    "                    no objects.\n",
    "                  properties:\n",
    "                    matchExpressions:\n",
    "                      description: matchExpressions is a list of label selector requirements.\n",
    "                        The requirements are ANDed.\n",
    "                      items:\n",
    "                        description: A label selector requirement is a selector that\n",
    "                          contains values, a key, and an operator that relates the\n",
    "                          key and values.\n",
    "                        properties:\n",
    "                          key:\n",
    "                            description: key is the label key that the selector applies\n",
    "                              to.\n",
    "                            type: string\n",
    "                          operator:\n",
    "                            description: operator represents a key's relationship\n",
    "                              to a set of values. Valid operators are In, NotIn, Exists\n",
    "                              and DoesNotExist.\n",
    "                            type: string\n",
    "                          values:\n",
    "                            description: values is an array of string values. If the\n",
    "                              operator is In or NotIn, the values array must be non-empty.\n",
    "                              If the operator is Exists or DoesNotExist, the values\n",
    "                              array must be empty. This array is replaced during a\n",
    "                              strategic merge patch.\n",
    "                            items:\n",
    "                              type: string\n",
    "                            type: array\n",
    "                        required:\n",
    "                        - key\n",
    "                        - operator\n",
    "                        type: object\n",
    "                      type: array\n",
    "                    matchLabels:\n",
    "                      additionalProperties:\n",
    "                        type: string\n",
    "                      description: matchLabels is a map of {key,value} pairs. A single\n",
    "                        {key,value} in the matchLabels map is equivalent to an element\n",
    "                        of matchExpressions, whose key field is \"key\", the operator\n",
    "                        is \"In\", and the values array contains only \"value\". The requirements\n",
    "                        are ANDed.\n",
    "                      type: object\n",
    "                  type: object\n",
    "                  x-kubernetes-map-type: atomic\n",
    "                type: array\n",
    "            type: object\n",
    "          status:\n",
    "            description: L2AdvertisementStatus defines the observed state of L2Advertisement.\n",
    "            type: object\n",
    "        type: object\n",
    "    served: true\n",
    "    storage: true\n",
    "    subresources:\n",
    "      status: {}\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: controller\n",
    "  namespace: metallb-system\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: speaker\n",
    "  namespace: metallb-system\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: Role\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: controller\n",
    "  namespace: metallb-system\n",
    "rules:\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resources:\n",
    "  - secrets\n",
    "  verbs:\n",
    "  - create\n",
    "  - delete\n",
    "  - get\n",
    "  - list\n",
    "  - patch\n",
    "  - update\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resourceNames:\n",
    "  - memberlist\n",
    "  resources:\n",
    "  - secrets\n",
    "  verbs:\n",
    "  - list\n",
    "- apiGroups:\n",
    "  - apps\n",
    "  resourceNames:\n",
    "  - controller\n",
    "  resources:\n",
    "  - deployments\n",
    "  verbs:\n",
    "  - get\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - bgppeers\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - addresspools\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - bfdprofiles\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - ipaddresspools\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - bgpadvertisements\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - l2advertisements\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - communities\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: Role\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: pod-lister\n",
    "  namespace: metallb-system\n",
    "rules:\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resources:\n",
    "  - pods\n",
    "  verbs:\n",
    "  - list\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resources:\n",
    "  - secrets\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - addresspools\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - bfdprofiles\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - bgppeers\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - l2advertisements\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - bgpadvertisements\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - ipaddresspools\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - metallb.io\n",
    "  resources:\n",
    "  - communities\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRole\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: metallb-system:controller\n",
    "rules:\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resources:\n",
    "  - services\n",
    "  - namespaces\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resources:\n",
    "  - services/status\n",
    "  verbs:\n",
    "  - update\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resources:\n",
    "  - events\n",
    "  verbs:\n",
    "  - create\n",
    "  - patch\n",
    "- apiGroups:\n",
    "  - policy\n",
    "  resourceNames:\n",
    "  - controller\n",
    "  resources:\n",
    "  - podsecuritypolicies\n",
    "  verbs:\n",
    "  - use\n",
    "- apiGroups:\n",
    "  - admissionregistration.k8s.io\n",
    "  resourceNames:\n",
    "  - metallb-webhook-configuration\n",
    "  resources:\n",
    "  - validatingwebhookconfigurations\n",
    "  - mutatingwebhookconfigurations\n",
    "  verbs:\n",
    "  - create\n",
    "  - delete\n",
    "  - get\n",
    "  - list\n",
    "  - patch\n",
    "  - update\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - admissionregistration.k8s.io\n",
    "  resources:\n",
    "  - validatingwebhookconfigurations\n",
    "  - mutatingwebhookconfigurations\n",
    "  verbs:\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - apiextensions.k8s.io\n",
    "  resourceNames:\n",
    "  - addresspools.metallb.io\n",
    "  - bfdprofiles.metallb.io\n",
    "  - bgpadvertisements.metallb.io\n",
    "  - bgppeers.metallb.io\n",
    "  - ipaddresspools.metallb.io\n",
    "  - l2advertisements.metallb.io\n",
    "  - communities.metallb.io\n",
    "  resources:\n",
    "  - customresourcedefinitions\n",
    "  verbs:\n",
    "  - create\n",
    "  - delete\n",
    "  - get\n",
    "  - list\n",
    "  - patch\n",
    "  - update\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - apiextensions.k8s.io\n",
    "  resources:\n",
    "  - customresourcedefinitions\n",
    "  verbs:\n",
    "  - list\n",
    "  - watch\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRole\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: metallb-system:speaker\n",
    "rules:\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resources:\n",
    "  - services\n",
    "  - endpoints\n",
    "  - nodes\n",
    "  - namespaces\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - discovery.k8s.io\n",
    "  resources:\n",
    "  - endpointslices\n",
    "  verbs:\n",
    "  - get\n",
    "  - list\n",
    "  - watch\n",
    "- apiGroups:\n",
    "  - \"\"\n",
    "  resources:\n",
    "  - events\n",
    "  verbs:\n",
    "  - create\n",
    "  - patch\n",
    "- apiGroups:\n",
    "  - policy\n",
    "  resourceNames:\n",
    "  - speaker\n",
    "  resources:\n",
    "  - podsecuritypolicies\n",
    "  verbs:\n",
    "  - use\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: RoleBinding\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: controller\n",
    "  namespace: metallb-system\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: Role\n",
    "  name: controller\n",
    "subjects:\n",
    "- kind: ServiceAccount\n",
    "  name: controller\n",
    "  namespace: metallb-system\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: RoleBinding\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: pod-lister\n",
    "  namespace: metallb-system\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: Role\n",
    "  name: pod-lister\n",
    "subjects:\n",
    "- kind: ServiceAccount\n",
    "  name: speaker\n",
    "  namespace: metallb-system\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRoleBinding\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: metallb-system:controller\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: ClusterRole\n",
    "  name: metallb-system:controller\n",
    "subjects:\n",
    "- kind: ServiceAccount\n",
    "  name: controller\n",
    "  namespace: metallb-system\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRoleBinding\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "  name: metallb-system:speaker\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: ClusterRole\n",
    "  name: metallb-system:speaker\n",
    "subjects:\n",
    "- kind: ServiceAccount\n",
    "  name: speaker\n",
    "  namespace: metallb-system\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: webhook-server-cert\n",
    "  namespace: metallb-system\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: webhook-service\n",
    "  namespace: metallb-system\n",
    "spec:\n",
    "  ports:\n",
    "  - port: 443\n",
    "    targetPort: 9443\n",
    "  selector:\n",
    "    component: controller\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "    component: controller\n",
    "  name: controller\n",
    "  namespace: metallb-system\n",
    "spec:\n",
    "  revisionHistoryLimit: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: metallb\n",
    "      component: controller\n",
    "  template:\n",
    "    metadata:\n",
    "      annotations:\n",
    "        prometheus.io/port: \"7472\"\n",
    "        prometheus.io/scrape: \"true\"\n",
    "      labels:\n",
    "        app: metallb\n",
    "        component: controller\n",
    "    spec:\n",
    "      containers:\n",
    "      - args:\n",
    "        - --port=7472\n",
    "        - --log-level=info\n",
    "        env:\n",
    "        - name: METALLB_ML_SECRET_NAME\n",
    "          value: memberlist\n",
    "        - name: METALLB_DEPLOYMENT\n",
    "          value: controller\n",
    "        image: quay.io/metallb/controller:v0.13.9\n",
    "        livenessProbe:\n",
    "          failureThreshold: 3\n",
    "          httpGet:\n",
    "            path: /metrics\n",
    "            port: monitoring\n",
    "          initialDelaySeconds: 10\n",
    "          periodSeconds: 10\n",
    "          successThreshold: 1\n",
    "          timeoutSeconds: 1\n",
    "        name: controller\n",
    "        ports:\n",
    "        - containerPort: 7472\n",
    "          name: monitoring\n",
    "        - containerPort: 9443\n",
    "          name: webhook-server\n",
    "          protocol: TCP\n",
    "        readinessProbe:\n",
    "          failureThreshold: 3\n",
    "          httpGet:\n",
    "            path: /metrics\n",
    "            port: monitoring\n",
    "          initialDelaySeconds: 10\n",
    "          periodSeconds: 10\n",
    "          successThreshold: 1\n",
    "          timeoutSeconds: 1\n",
    "        securityContext:\n",
    "          allowPrivilegeEscalation: false\n",
    "          capabilities:\n",
    "            drop:\n",
    "            - all\n",
    "          readOnlyRootFilesystem: true\n",
    "        volumeMounts:\n",
    "        - mountPath: /tmp/k8s-webhook-server/serving-certs\n",
    "          name: cert\n",
    "          readOnly: true\n",
    "      nodeSelector:\n",
    "        kubernetes.io/os: linux\n",
    "      securityContext:\n",
    "        fsGroup: 65534\n",
    "        runAsNonRoot: true\n",
    "        runAsUser: 65534\n",
    "      serviceAccountName: controller\n",
    "      terminationGracePeriodSeconds: 0\n",
    "      volumes:\n",
    "      - name: cert\n",
    "        secret:\n",
    "          defaultMode: 420\n",
    "          secretName: webhook-server-cert\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: DaemonSet\n",
    "metadata:\n",
    "  labels:\n",
    "    app: metallb\n",
    "    component: speaker\n",
    "  name: speaker\n",
    "  namespace: metallb-system\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: metallb\n",
    "      component: speaker\n",
    "  template:\n",
    "    metadata:\n",
    "      annotations:\n",
    "        prometheus.io/port: \"7472\"\n",
    "        prometheus.io/scrape: \"true\"\n",
    "      labels:\n",
    "        app: metallb\n",
    "        component: speaker\n",
    "    spec:\n",
    "      containers:\n",
    "      - args:\n",
    "        - --port=7472\n",
    "        - --log-level=info\n",
    "        env:\n",
    "        - name: METALLB_NODE_NAME\n",
    "          valueFrom:\n",
    "            fieldRef:\n",
    "              fieldPath: spec.nodeName\n",
    "        - name: METALLB_HOST\n",
    "          valueFrom:\n",
    "            fieldRef:\n",
    "              fieldPath: status.hostIP\n",
    "        - name: METALLB_ML_BIND_ADDR\n",
    "          valueFrom:\n",
    "            fieldRef:\n",
    "              fieldPath: status.podIP\n",
    "        - name: METALLB_ML_LABELS\n",
    "          value: app=metallb,component=speaker\n",
    "        - name: METALLB_ML_SECRET_KEY_PATH\n",
    "          value: /etc/ml_secret_key\n",
    "        image: quay.io/metallb/speaker:v0.13.9\n",
    "        livenessProbe:\n",
    "          failureThreshold: 3\n",
    "          httpGet:\n",
    "            path: /metrics\n",
    "            port: monitoring\n",
    "          initialDelaySeconds: 10\n",
    "          periodSeconds: 10\n",
    "          successThreshold: 1\n",
    "          timeoutSeconds: 1\n",
    "        name: speaker\n",
    "        ports:\n",
    "        - containerPort: 7472\n",
    "          name: monitoring\n",
    "        - containerPort: 7946\n",
    "          name: memberlist-tcp\n",
    "        - containerPort: 7946\n",
    "          name: memberlist-udp\n",
    "          protocol: UDP\n",
    "        readinessProbe:\n",
    "          failureThreshold: 3\n",
    "          httpGet:\n",
    "            path: /metrics\n",
    "            port: monitoring\n",
    "          initialDelaySeconds: 10\n",
    "          periodSeconds: 10\n",
    "          successThreshold: 1\n",
    "          timeoutSeconds: 1\n",
    "        securityContext:\n",
    "          allowPrivilegeEscalation: false\n",
    "          capabilities:\n",
    "            add:\n",
    "            - NET_RAW\n",
    "            drop:\n",
    "            - ALL\n",
    "          readOnlyRootFilesystem: true\n",
    "        volumeMounts:\n",
    "        - mountPath: /etc/ml_secret_key\n",
    "          name: memberlist\n",
    "          readOnly: true\n",
    "      hostNetwork: true\n",
    "      nodeSelector:\n",
    "        kubernetes.io/os: linux\n",
    "      serviceAccountName: speaker\n",
    "      terminationGracePeriodSeconds: 2\n",
    "      tolerations:\n",
    "      - effect: NoSchedule\n",
    "        key: node-role.kubernetes.io/master\n",
    "        operator: Exists\n",
    "      - effect: NoSchedule\n",
    "        key: node-role.kubernetes.io/control-plane\n",
    "        operator: Exists\n",
    "      volumes:\n",
    "      - name: memberlist\n",
    "        secret:\n",
    "          defaultMode: 420\n",
    "          secretName: memberlist\n",
    "---\n",
    "apiVersion: admissionregistration.k8s.io/v1\n",
    "kind: ValidatingWebhookConfiguration\n",
    "metadata:\n",
    "  creationTimestamp: null\n",
    "  name: metallb-webhook-configuration\n",
    "webhooks:\n",
    "- admissionReviewVersions:\n",
    "  - v1\n",
    "  clientConfig:\n",
    "    service:\n",
    "      name: webhook-service\n",
    "      namespace: metallb-system\n",
    "      path: /validate-metallb-io-v1beta2-bgppeer\n",
    "  failurePolicy: Fail\n",
    "  name: bgppeersvalidationwebhook.metallb.io\n",
    "  rules:\n",
    "  - apiGroups:\n",
    "    - metallb.io\n",
    "    apiVersions:\n",
    "    - v1beta2\n",
    "    operations:\n",
    "    - CREATE\n",
    "    - UPDATE\n",
    "    resources:\n",
    "    - bgppeers\n",
    "  sideEffects: None\n",
    "- admissionReviewVersions:\n",
    "  - v1\n",
    "  clientConfig:\n",
    "    service:\n",
    "      name: webhook-service\n",
    "      namespace: metallb-system\n",
    "      path: /validate-metallb-io-v1beta1-addresspool\n",
    "  failurePolicy: Fail\n",
    "  name: addresspoolvalidationwebhook.metallb.io\n",
    "  rules:\n",
    "  - apiGroups:\n",
    "    - metallb.io\n",
    "    apiVersions:\n",
    "    - v1beta1\n",
    "    operations:\n",
    "    - CREATE\n",
    "    - UPDATE\n",
    "    resources:\n",
    "    - addresspools\n",
    "  sideEffects: None\n",
    "- admissionReviewVersions:\n",
    "  - v1\n",
    "  clientConfig:\n",
    "    service:\n",
    "      name: webhook-service\n",
    "      namespace: metallb-system\n",
    "      path: /validate-metallb-io-v1beta1-bfdprofile\n",
    "  failurePolicy: Fail\n",
    "  name: bfdprofilevalidationwebhook.metallb.io\n",
    "  rules:\n",
    "  - apiGroups:\n",
    "    - metallb.io\n",
    "    apiVersions:\n",
    "    - v1beta1\n",
    "    operations:\n",
    "    - CREATE\n",
    "    - DELETE\n",
    "    resources:\n",
    "    - bfdprofiles\n",
    "  sideEffects: None\n",
    "- admissionReviewVersions:\n",
    "  - v1\n",
    "  clientConfig:\n",
    "    service:\n",
    "      name: webhook-service\n",
    "      namespace: metallb-system\n",
    "      path: /validate-metallb-io-v1beta1-bgpadvertisement\n",
    "  failurePolicy: Fail\n",
    "  name: bgpadvertisementvalidationwebhook.metallb.io\n",
    "  rules:\n",
    "  - apiGroups:\n",
    "    - metallb.io\n",
    "    apiVersions:\n",
    "    - v1beta1\n",
    "    operations:\n",
    "    - CREATE\n",
    "    - UPDATE\n",
    "    resources:\n",
    "    - bgpadvertisements\n",
    "  sideEffects: None\n",
    "- admissionReviewVersions:\n",
    "  - v1\n",
    "  clientConfig:\n",
    "    service:\n",
    "      name: webhook-service\n",
    "      namespace: metallb-system\n",
    "      path: /validate-metallb-io-v1beta1-community\n",
    "  failurePolicy: Fail\n",
    "  name: communityvalidationwebhook.metallb.io\n",
    "  rules:\n",
    "  - apiGroups:\n",
    "    - metallb.io\n",
    "    apiVersions:\n",
    "    - v1beta1\n",
    "    operations:\n",
    "    - CREATE\n",
    "    - UPDATE\n",
    "    resources:\n",
    "    - communities\n",
    "  sideEffects: None\n",
    "- admissionReviewVersions:\n",
    "  - v1\n",
    "  clientConfig:\n",
    "    service:\n",
    "      name: webhook-service\n",
    "      namespace: metallb-system\n",
    "      path: /validate-metallb-io-v1beta1-ipaddresspool\n",
    "  failurePolicy: Fail\n",
    "  name: ipaddresspoolvalidationwebhook.metallb.io\n",
    "  rules:\n",
    "  - apiGroups:\n",
    "    - metallb.io\n",
    "    apiVersions:\n",
    "    - v1beta1\n",
    "    operations:\n",
    "    - CREATE\n",
    "    - UPDATE\n",
    "    resources:\n",
    "    - ipaddresspools\n",
    "  sideEffects: None\n",
    "- admissionReviewVersions:\n",
    "  - v1\n",
    "  clientConfig:\n",
    "    service:\n",
    "      name: webhook-service\n",
    "      namespace: metallb-system\n",
    "      path: /validate-metallb-io-v1beta1-l2advertisement\n",
    "  failurePolicy: Fail\n",
    "  name: l2advertisementvalidationwebhook.metallb.io\n",
    "  rules:\n",
    "  - apiGroups:\n",
    "    - metallb.io\n",
    "    apiVersions:\n",
    "    - v1beta1\n",
    "    operations:\n",
    "    - CREATE\n",
    "    - UPDATE\n",
    "    resources:\n",
    "    - l2advertisements\n",
    "  sideEffects: None\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a0e6b8-a7b3-4bf0-9c03-12fc254b3a4d",
   "metadata": {},
   "source": [
    "#### Apply Manifest\n",
    "\n",
    "We can kick off the deployment by applying the kubernetes manifest.\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl apply -f metallb-native.yaml\n",
    "namespace/metallb-system created\n",
    "customresourcedefinition.apiextensions.k8s.io/addresspools.metallb.io created\n",
    "customresourcedefinition.apiextensions.k8s.io/bfdprofiles.metallb.io created\n",
    "customresourcedefinition.apiextensions.k8s.io/bgpadvertisements.metallb.io created\n",
    "customresourcedefinition.apiextensions.k8s.io/bgppeers.metallb.io created\n",
    "customresourcedefinition.apiextensions.k8s.io/communities.metallb.io created\n",
    "customresourcedefinition.apiextensions.k8s.io/ipaddresspools.metallb.io created\n",
    "customresourcedefinition.apiextensions.k8s.io/l2advertisements.metallb.io created\n",
    "serviceaccount/controller created\n",
    "serviceaccount/speaker created\n",
    "role.rbac.authorization.k8s.io/controller created\n",
    "role.rbac.authorization.k8s.io/pod-lister created\n",
    "clusterrole.rbac.authorization.k8s.io/metallb-system:controller created\n",
    "clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created\n",
    "rolebinding.rbac.authorization.k8s.io/controller created\n",
    "rolebinding.rbac.authorization.k8s.io/pod-lister created\n",
    "clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created\n",
    "clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created\n",
    "secret/webhook-server-cert created\n",
    "service/webhook-service created\n",
    "deployment.apps/controller created\n",
    "daemonset.apps/speaker created\n",
    "validatingwebhookconfiguration.admissionregistration.k8s.io/metallb-webhook-configuration created\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a495b-f2db-4e4b-ba87-e8482dc5c334",
   "metadata": {},
   "source": [
    "Afterards we can have a look at the system to see what is created\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get all -A\n",
    "```\n",
    "\n",
    "Ideally everything should be running and there should be no errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306ebd5-2d9b-46cd-80e3-7984c5216946",
   "metadata": {},
   "source": [
    "#### A Note On The Operator\n",
    "\n",
    "The MetalLB Operator is available on OperatorHub at operatorhub.io/operator/metallb-operator. It eases the deployment and life-cycle of MetalLB in a cluster and allows configuring MetalLB via CRDs.\n",
    "\n",
    "The documentation mentions steps for using the operator in the case of using FRR Mode, When upgrading, or when deploying MetalLB in an environemnt where multiple different types of load balancers are being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec61249-3b48-450d-9a97-941ece2dcffb",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Now that the instllation is complete, it's time to configure the solution to load balance my application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d95a0b6-4444-4f59-8550-f6ec56005b0d",
   "metadata": {},
   "source": [
    "#### IP Allocation\n",
    "The first step is to define an IPAddressPool that we will allocate for the load balancer to manage. In my case I will pick an arbitrary range from my 15.0.0.0/8 subnet and elect 15.4.25.1 - 15.4.25.5.\n",
    "\n",
    "```\n",
    "apiVersion: metallb.io/v1beta1\n",
    "kind: IPAddressPool\n",
    "metadata:\n",
    "  name: first-pool\n",
    "  namespace: metallb-system\n",
    "spec:\n",
    "  addresses:\n",
    "  - 15.4.25.1-15.4.25.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ea1b2-1332-4ebb-b3da-1020abddf7fc",
   "metadata": {},
   "source": [
    "#### Announce The Service IPs\n",
    "\n",
    "##### Layer 2\n",
    "Once the IPs are assigned to a service, they must be announced. As mentioned earlier there are several options for this particular configuraiton. I will elect to use Layer 2 Advertisement as it is the simplest option and does not require any protocol-specific configuration (as it's layer 2 in the OSI model and site below the layer 3 or layer 7 which typically host the protocols being load balanced).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9ba02-e47b-47f1-83c8-f4f79b36bf24",
   "metadata": {},
   "source": [
    "##### Layer2 info\n",
    "\n",
    "https://metallb.universe.tf/concepts/layer2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ccce5-b61e-4357-8e13-dd21e6a116b8",
   "metadata": {},
   "source": [
    "##### Layer 2 Limitations\n",
    "\n",
    "Layer 2 mode has two main limitations you should be aware of: single-node bottlenecking, and potentially slow failover.\n",
    "\n",
    "As explained above, in layer2 mode a single leader-elected node receives all traffic for a service IP. This means that your service’s ingress bandwidth is limited to the bandwidth of a single node. This is a fundamental limitation of using ARP and NDP to steer traffic.\n",
    "\n",
    "In the current implementation, failover between nodes depends on cooperation from the clients. When a failover occurs, MetalLB sends a number of gratuitous layer 2 packets (a bit of a misnomer - it should really be called “unsolicited layer 2 packets”) to notify clients that the MAC address associated with the service IP has changed.\n",
    "\n",
    "Most operating systems handle “gratuitous” packets correctly, and update their neighbor caches promptly. In that case, failover happens within a few seconds. However, some systems either don’t implement gratuitous handling at all, or have buggy implementations that delay the cache update.\n",
    "\n",
    "All modern versions of major OSes (Windows, Mac, Linux) implement layer 2 failover correctly, so the only situation where issues may happen is with older or less common OSes.\n",
    "\n",
    "https://metallb.universe.tf/concepts/layer2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966d646-03ca-4838-a031-e4f8f64aaf96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d768d9-6952-4820-b2fa-8abf11f665e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66d16d93-c38b-45f1-8831-7668f0e26405",
   "metadata": {},
   "source": [
    "\n",
    "To make this configuration we need to define a L2Advertisement resource and associate it with the IPAddressPool resource defined previously.\n",
    "\n",
    "```\n",
    "apiVersion: metallb.io/v1beta1\n",
    "kind: L2Advertisement\n",
    "metadata:\n",
    "  name: example\n",
    "  namespace: metallb-system\n",
    "spec:\n",
    "  ipAddressPools:\n",
    "    - first-pool\n",
    "```\n",
    "\n",
    "**Note**: Setting no IPAddressPool selector in an L2Advertisement instance is interpreted as that instance being associated to all the IPAddressPools available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad875d-8a6c-4000-aa3c-0f173a043b65",
   "metadata": {},
   "source": [
    "#### Configuration Validation\n",
    "MetalLB ships validation webhooks that check the validity of the CRs applied.\n",
    "\n",
    "However, due to the fact that the global MetalLB configuration is composed by different pieces, not all of the invalid configurations are blocked by those webhooks. Because of that, if a non valid MetalLB configuration is applied, MetalLB discards it and keeps using the last valid configuration.\n",
    "\n",
    "In future releases MetalLB will expose misconfigurations as part of Kubernetes resources, but currently the only way to understand why the configuration was not loaded is by checking the controller’s logs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e79a23-ddfd-4b26-bc2d-dce14471c2cf",
   "metadata": {},
   "source": [
    "We apply the configuration\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# cat metallb-configuration.yaml\n",
    "apiVersion: metallb.io/v1beta1\n",
    "kind: IPAddressPool\n",
    "metadata:\n",
    "  name: first-pool\n",
    "  namespace: metallb-system\n",
    "spec:\n",
    "  addresses:\n",
    "  - 15.4.25.1-15.4.25.5\n",
    "\n",
    "apiVersion: metallb.io/v1beta1\n",
    "kind: L2Advertisement\n",
    "metadata:\n",
    "  name: example\n",
    "  namespace: metallb-system\n",
    "spec:\n",
    "  ipAddressPools:\n",
    "    - first-pool\n",
    "\n",
    "[root@os004k8-master001 pachyderm]# kubectl apply -f metallb-configuration.yaml\n",
    "ipaddresspool.metallb.io/first-pool created\n",
    "l2advertisement.metallb.io/example created\n",
    "```\n",
    "\n",
    "We should see that two new resources are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd6f7f3-fc0f-4536-a2e1-54b1e94b6502",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Check Pods Are Running\n",
    "We can check the status of the applied resources. Note that these are custom resource definisions so the process of getting their status is a bit different that that of normal resources.\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get customresourcedefinitions\n",
    "NAME                           CREATED AT\n",
    "addresspools.metallb.io        2023-05-03T15:27:08Z\n",
    "bfdprofiles.metallb.io         2023-05-03T15:27:08Z\n",
    "bgpadvertisements.metallb.io   2023-05-03T15:27:08Z\n",
    "bgppeers.metallb.io            2023-05-03T15:27:08Z\n",
    "communities.metallb.io         2023-05-03T15:27:08Z\n",
    "ipaddresspools.metallb.io      2023-05-03T15:27:08Z\n",
    "l2advertisements.metallb.io    2023-05-03T15:27:08Z\n",
    "[root@os004k8-master001 pachyderm]# kubectl get ipaddresspools.metallb.io -A\n",
    "NAMESPACE        NAME         AUTO ASSIGN   AVOID BUGGY IPS   ADDRESSES\n",
    "metallb-system   first-pool   true          false             [\"15.4.25.1-15.4.25.5\"]\n",
    "[root@os004k8-master001 pachyderm]# kubectl get l2advertisements.metallb.io -A\n",
    "NAMESPACE        NAME      IPADDRESSPOOLS   IPADDRESSPOOL SELECTORS   INTERFACES\n",
    "metallb-system   example   [\"first-pool\"]\n",
    "```\n",
    "\n",
    "These appear to be in proper order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0bd80-6793-45f3-b8f9-483f60a0430e",
   "metadata": {},
   "source": [
    "# Install Pachyderm On Kubernetes Cluster\n",
    "\n",
    "Regardless of which installation method we have chosen, the steps should be reletively similar as we are essentially deployign an application to kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea1517-b2e5-41b7-935c-30859ce0c799",
   "metadata": {},
   "source": [
    "## Install pachctl\n",
    "The pachctl is a command-line tool that you can use to interact with a Pachyderm cluster in your terminal. It is provided as a precompiled binary available from the [github releases page](https://github.com/pachyderm/pachyderm/releases/tag/v2.5.5).\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# curl -L -O https://github.com/pachyderm/pachyderm/releases/download/v2.5.5/pachctl_2.5.5_linux_amd64.tar.gz\n",
    "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    "                                 Dload  Upload   Total   Spent    Left  Speed\n",
    "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
    "100 37.1M  100 37.1M    0     0  33.6M      0  0:00:01  0:00:01 --:--:-- 82.4M\n",
    "\n",
    "[root@os004k8-master001 ~]# tar -xzvf pachctl_2.5.5_linux_amd64.tar.gz\n",
    "pachctl_2.5.5_linux_amd64/pachctl\n",
    "\n",
    "[root@os004k8-master001 ~]# cp pachctl_2.5.5_linux_amd64/pachctl /usr/bin/\n",
    "\n",
    "[root@os004k8-master001 ~]# pachctl version\n",
    "COMPONENT           VERSION\n",
    "pachctl             2.5.5\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Note**:The official installation instructions can be found [here](https://docs.pachyderm.com/2.3.x/getting-started/local-installation/#install-pachctl)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddaeabb-12fb-4493-80f2-f642559ab620",
   "metadata": {},
   "source": [
    "## Configure Helm To Install Pachyderm Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c392367-cfe1-4e2c-b115-5c9eb0a8533b",
   "metadata": {},
   "source": [
    "### Add Helm Chart Repository\n",
    "\n",
    "The heml package format is referred to as a chart. Similar to regular OS packages, helm charts are provided by repositories. The package manager (helmp) is configured to point to repositories to allow users to download and install packages from those repositories. Artifact Hub is a public repository providing open source helm charts.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6caf90c-65f1-45c0-9389-461228be3ac1",
   "metadata": {},
   "source": [
    "We want to add the repo for the pachyderm repo so we can install the app on our cluster.\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# helm repo add pachyderm https://helm.pachyderm.com\n",
    "WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config\n",
    "WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config\n",
    "\"pachyderm\" has been added to your repositories\n",
    "\n",
    "[root@os004k8-master001 ~]# helm repo update\n",
    "WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config\n",
    "WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config\n",
    "Hang tight while we grab the latest from your chart repositories...\n",
    "...Successfully got an update from the \"pachyderm\" chart repository\n",
    "Update Complete. ⎈Happy Helming!⎈\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21244e9b-f753-4857-a100-b374c1cefad9",
   "metadata": {},
   "source": [
    "### Inspect Helm Chart\n",
    "We can ask helm for a definition of the pachyderm chart\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# helm show chart pachyderm/pachyderm\n",
    "WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config\n",
    "WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config\n",
    "annotations:\n",
    "  artifacthub.io/license: Apache-2.0\n",
    "  artifacthub.io/links: |\n",
    "    - name: \"Pachyderm\"\n",
    "      url: https://www.pachyderm.com/\n",
    "    - name: \"Pachyderm repo\"\n",
    "      url: https://github.com/pachyderm/pachyderm\n",
    "    - name: \"Chart repo\"\n",
    "      url: https://github.com/pachyderm/helmchart\n",
    "  artifacthub.io/prerelease: \"false\"\n",
    "apiVersion: v2\n",
    "appVersion: 2.5.5\n",
    "dependencies:\n",
    "- condition: postgresql.enabled\n",
    "  name: postgresql\n",
    "  repository: file://./dependencies/postgresql\n",
    "  version: 10.8.0\n",
    "- condition: pachd.lokiDeploy\n",
    "  name: loki-stack\n",
    "  repository: https://grafana.github.io/helm-charts\n",
    "  version: 2.8.1\n",
    "description: Explainable, repeatable, scalable data science\n",
    "home: https://www.pachyderm.com/\n",
    "icon: https://www.pachyderm.com/wp-content/themes/pachyderm/assets/img/favicons/favicon-32x32.png\n",
    "keywords:\n",
    "- data science\n",
    "kubeVersion: '>= 1.16.0-0'\n",
    "name: pachyderm\n",
    "sources:\n",
    "- https://github.com/pachyderm/pachyderm\n",
    "- https://github.com/pachyderm/helmchart\n",
    "type: application\n",
    "version: 2.5.5\n",
    "```\n",
    "\n",
    "**Note**: More information about the helm chart format can be found here: https://helm.sh/docs/topics/charts/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23336cde-ed8f-43b2-9198-ae5f71492c7d",
   "metadata": {},
   "source": [
    "#### Inspect Dependencies\n",
    "\n",
    "Taking a closer look at the chart, we can wee there are dependencies listed for this chart:\n",
    "\n",
    "```\n",
    "...\n",
    "dependencies:\n",
    "- condition: postgresql.enabled\n",
    "  name: postgresql\n",
    "  repository: file://./dependencies/postgresql\n",
    "  version: 10.8.0\n",
    "- condition: pachd.lokiDeploy\n",
    "  name: loki-stack\n",
    "  repository: https://grafana.github.io/helm-charts\n",
    "  version: 2.8.1\n",
    "...\n",
    "```\n",
    "\n",
    "For the first dependency, we see that there is an instruction to install the postgresql chart from from a local source (the source code for this chart is specified as a relative reference). Looking at the repository in github I was able to find the code [here](https://github.com/pachyderm/pachyderm/blob/master/etc/helm/pachyderm/dependencies/postgresql/Chart.yaml). This points to  a vanilla postgress installtion [provided by bitnami](https://github.com/bitnami/charts/tree/main/bitnami/postgresql).\n",
    "\n",
    "The second dependency points to a package called [loki-stack](https://github.com/grafana/helm-charts/blob/main/charts/loki-stack/Chart.yaml). This package is provided by the grafana project and hosts the Loki service. Grafana is the open source analytics and monitoring solution. Loki is a log aggregation system designed to store and query logs from applications and infrastructure. Loki and Grafana work together to store and to query and display the logs respectively. \n",
    "The official instructions for installing Grafana Loki canbe found [here](https://grafana.com/docs/loki/latest/installation/helm/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067c84a-3d65-46bd-98a3-616d30bae053",
   "metadata": {},
   "source": [
    "#### Inspect Values\n",
    "Helm was designed so that the helm charts could be defined in a flexible and customizable way. One of the ways this is facilitated is through the values object. Helm assumes the chart is a template and allows users to specify values which map into the configurations hosted in the chart. In this way a user might have a single chart for multiple database deployments; a separate values file could be used to configure each instance (i.e. set the password etc.).\n",
    "\n",
    "We can see the values that are packaged with the helm chart in the [git repository](https://github.com/pachyderm/pachyderm/blob/master/etc/helm/pachyderm/values.yaml) or we can ask helm to tell us what values are associated with a given chart with the following:\n",
    "\n",
    "```\n",
    "### \\#\n",
    "[root@os004k8-master001 ~]# helm show values pachyderm/pachyderm\n",
    "# SPDX-FileCopyrightText: Pachyderm, Inc. <info@pachyderm.com>\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "# Deploy Target configures the storage backend to use and cloud provider\n",
    "# settings (storage classes, etc). It must be one of GOOGLE, AMAZON,\n",
    "# MINIO, MICROSOFT, CUSTOM or LOCAL.\n",
    "deployTarget: \"\"\n",
    "\n",
    "global:\n",
    "  postgresql:\n",
    "    # postgresqlUsername is the username to access the pachyderm and dex databases\n",
    "    postgresqlUsername: \"pachyderm\"\n",
    "    # postgresqlPassword to access the postgresql database.  We set a default well-known password to\n",
    "    # facilitate easy upgrades when testing locally.  Any sort of install that needs to be secure\n",
    "    # must specify a secure password here, or provide the postgresqlExistingSecretName and\n",
    "    # postgresqlExistingSecretKey secret.  If using an external Postgres instance (CloudSQL / RDS /\n",
    "    # etc.), this is the password that Pachyderm will use to connect to it.\n",
    "    postgresqlPassword: \"insecure-user-password\"\n",
    "    # When installing a local Postgres instance, postgresqlPostgresPassword defines the root\n",
    "    # ('postgres') user's password.  It must remain consistent between upgrades, and must be\n",
    "    # explicitly set to a value if security is desired.  Pachyderm does not use this account; this\n",
    "    # password is only required so that administrators can manually perform administrative tasks.\n",
    "    postgresqlPostgresPassword: \"insecure-root-password\"\n",
    "    # The auth type to use with postgres and pg-bouncer. md5 is the default\n",
    "    postgresqlAuthType: \"md5\"\n",
    "    # If you want to supply the postgresql password in an existing secret, leave Password blank and\n",
    "    # Supply the name of the existing secret in the namespace and the key in that secret with the password\n",
    "    postgresqlExistingSecretName: \"\"\n",
    "    postgresqlExistingSecretKey: \"\"\n",
    "    # postgresqlDatabase is the database name where pachyderm data will be stored\n",
    "    postgresqlDatabase: \"pachyderm\"\n",
    "    # The postgresql database host to connect to. Defaults to postgres service in subchart\n",
    "    postgresqlHost: \"postgres\"\n",
    "    # The postgresql database port to connect to. Defaults to postgres server in subchart\n",
    "    postgresqlPort: \"5432\"\n",
    "    # postgresqlSSL is the SSL mode to use for pg-bouncer connecting to Postgres, for the default local postgres it is disabled\n",
    "    postgresqlSSL: \"disable\"\n",
    "    # CA Certificate required to connect to Postgres\n",
    "    postgresqlSSLCACert: \"\"\n",
    "    # TLS Secret with cert/key to connect to Postgres\n",
    "    postgresqlSSLSecret: \"\"\n",
    "    # Indicates the DB name that dex connects to\n",
    "    # Indicates the DB name that dex connects to. Defaults to \"Dex\" if not set.\n",
    "    identityDatabaseFullNameOverride: \"\"\n",
    "  # imagePullSecrets allow you to pull images from private repositories, these will also be added to pipeline workers\n",
    "  # https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n",
    "  # Example:\n",
    "  # imagePullSecrets:\n",
    "  #   - regcred\n",
    "  imagePullSecrets: []\n",
    "  # when set, the certificate file in pachd-tls-cert will be loaded as the root certificate for pachd, console, and enterprise-server pods\n",
    "  customCaCerts: false\n",
    "  # Sets the HTTP/S proxy server address for console, pachd, and enterprise server.  (This is for\n",
    "  # traffic leaving the cluster, not traffic coming into the cluster.)\n",
    "  proxy: \"\"\n",
    "  # If proxy is set, this allows you to set a comma-separated list of destinations that bypass the proxy\n",
    "  noProxy: \"\"\n",
    "  # Set security context runAs users. If running on openshift, set enabled to false as openshift creates its own contexts.\n",
    "  securityContexts:\n",
    "    enabled: true\n",
    "\n",
    "console:\n",
    "  # enabled controls whether the console manifests are created or not.\n",
    "  enabled: true\n",
    "  annotations: {}\n",
    "  image:\n",
    "    # repository is the image repo to pull from; together with tag it\n",
    "    # replicates the --console-image & --registry arguments to pachctl\n",
    "    # deploy.\n",
    "    repository: \"pachyderm/haberdashery\"\n",
    "    pullPolicy: \"IfNotPresent\"\n",
    "    # tag is the image repo to pull from; together with repository it\n",
    "    # replicates the --console-image argument to pachctl deploy.\n",
    "    tag: \"2.5.5-1\"\n",
    "  priorityClassName: \"\"\n",
    "  nodeSelector: {}\n",
    "  tolerations: []\n",
    "  # podLabels specifies labels to add to the console pod.\n",
    "  podLabels: {}\n",
    "  # resources specifies the resource request and limits.\n",
    "  resources:\n",
    "    {}\n",
    "    #limits:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "    #requests:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "  config:\n",
    "    reactAppRuntimeIssuerURI: \"\" # Inferred if running locally or using ingress\n",
    "    oauthRedirectURI: \"\" # Infered if running locally or using ingress\n",
    "    oauthClientID: \"console\"\n",
    "    oauthClientSecret: \"\" # Autogenerated on install if blank\n",
    "    # oauthClientSecretSecretName is used to set the OAuth Client Secret via an existing k8s secret.\n",
    "    # The value is pulled from the key, \"OAUTH_CLIENT_SECRET\".\n",
    "    oauthClientSecretSecretName: \"\"\n",
    "    graphqlPort: 4000\n",
    "    pachdAddress: \"pachd-peer:30653\"\n",
    "    disableTelemetry: false # Disables analytics and error data collection\n",
    "\n",
    "  service:\n",
    "    annotations: {}\n",
    "    # labels specifies labels to add to the console service.\n",
    "    labels: {}\n",
    "    # type specifies the Kubernetes type of the console service.\n",
    "    type: ClusterIP\n",
    "\n",
    "etcd:\n",
    "  affinity: {}\n",
    "  annotations: {}\n",
    "  # dynamicNodes sets the number of nodes in the etcd StatefulSet.  It\n",
    "  # is analogous to the --dynamic-etcd-nodes argument to pachctl\n",
    "  # deploy.\n",
    "  dynamicNodes: 1\n",
    "  image:\n",
    "    repository: \"pachyderm/etcd\"\n",
    "    tag: \"v3.5.5\"\n",
    "    pullPolicy: \"IfNotPresent\"\n",
    "  # maxTxnOps sets the --max-txn-ops in the container args\n",
    "  maxTxnOps: 10000\n",
    "  priorityClassName: \"\"\n",
    "  nodeSelector: {}\n",
    "  # podLabels specifies labels to add to the etcd pod.\n",
    "  podLabels: {}\n",
    "  # resources specifies the resource request and limits\n",
    "  resources:\n",
    "    {}\n",
    "    #limits:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "    #requests:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "  # storageClass indicates the etcd should use an existing\n",
    "  # StorageClass for its storage.  It is analogous to the\n",
    "  # --etcd-storage-class argument to pachctl deploy.\n",
    "  # More info for setting up storage classes on various cloud providers:\n",
    "  # AWS: https://docs.aws.amazon.com/eks/latest/userguide/storage-classes.html\n",
    "  # GCP: https://cloud.google.com/compute/docs/disks/performance#disk_types\n",
    "  # Azure: https://docs.microsoft.com/en-us/azure/aks/concepts-storage#storage-classes\n",
    "  storageClass: \"\"\n",
    "  # storageSize specifies the size of the volume to use for etcd.\n",
    "  # Recommended Minimum Disk size for Microsoft/Azure: 256Gi  - 1,100 IOPS https://azure.microsoft.com/en-us/pricing/details/managed-disks/\n",
    "  # Recommended Minimum Disk size for Google/GCP: 50Gi        - 1,500 IOPS https://cloud.google.com/compute/docs/disks/performance\n",
    "  # Recommended Minimum Disk size for Amazon/AWS: 500Gi (GP2) - 1,500 IOPS https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html\n",
    "  storageSize: 10Gi\n",
    "  service:\n",
    "    # annotations specifies annotations to add to the etcd service.\n",
    "    annotations: {}\n",
    "    # labels specifies labels to add to the etcd service.\n",
    "    labels: {}\n",
    "    # type specifies the Kubernetes type of the etcd service.\n",
    "    type: ClusterIP\n",
    "  tolerations: []\n",
    "\n",
    "enterpriseServer:\n",
    "  enabled: false\n",
    "  affinity: {}\n",
    "  annotations: {}\n",
    "  tolerations: []\n",
    "  priorityClassName: \"\"\n",
    "  nodeSelector: {}\n",
    "  service:\n",
    "    type: ClusterIP\n",
    "    apiGRPCPort: 31650\n",
    "    prometheusPort: 31656\n",
    "    oidcPort: 31657\n",
    "    identityPort: 31658\n",
    "    s3GatewayPort: 31600\n",
    "  # There are three options for TLS:\n",
    "  # 1. Disabled\n",
    "  # 2. Enabled, existingSecret, specify secret name\n",
    "  # 3. Enabled, newSecret, must specify cert, key and name\n",
    "  tls:\n",
    "    enabled: false\n",
    "    secretName: \"\"\n",
    "    newSecret:\n",
    "      create: false\n",
    "      crt: \"\"\n",
    "      key: \"\"\n",
    "  resources:\n",
    "    {}\n",
    "    #limits:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "    #requests:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "  # podLabels specifies labels to add to the pachd pod.\n",
    "  podLabels: {}\n",
    "  clusterDeploymentID: \"\"\n",
    "  image:\n",
    "    repository: \"pachyderm/pachd\"\n",
    "    pullPolicy: \"IfNotPresent\"\n",
    "    # tag defaults to the chart’s specified appVersion.\n",
    "    tag: \"\"\n",
    "\n",
    "ingress:\n",
    "  enabled: false\n",
    "  annotations: {}\n",
    "  host: \"\"\n",
    "  # when set to true, uriHttpsProtoOverride will add the https protocol to the ingress URI routes without configuring certs\n",
    "  uriHttpsProtoOverride: false\n",
    "  # There are three options for TLS:\n",
    "  # 1. Disabled\n",
    "  # 2. Enabled, existingSecret, specify secret name\n",
    "  # 3. Enabled, newSecret, must specify cert, key, secretName and set newSecret.create to true\n",
    "  tls:\n",
    "    enabled: false\n",
    "    secretName: \"\"\n",
    "    newSecret:\n",
    "      create: false\n",
    "      crt: \"\"\n",
    "      key: \"\"\n",
    "\n",
    "# loki-stack contains values that will be passed to the loki-stack subchart\n",
    "loki-stack:\n",
    "  loki:\n",
    "    serviceAccount:\n",
    "      automountServiceAccountToken: false\n",
    "    persistence:\n",
    "      enabled: true\n",
    "      accessModes:\n",
    "        - ReadWriteOnce\n",
    "      size: 10Gi\n",
    "      # More info for setting up storage classes on various cloud providers:\n",
    "      # AWS: https://docs.aws.amazon.com/eks/latest/userguide/storage-classes.html\n",
    "      # GCP: https://cloud.google.com/compute/docs/disks/performance#disk_types\n",
    "      # Azure: https://docs.microsoft.com/en-us/azure/aks/concepts-storage#storage-classes\n",
    "      storageClassName: \"\"\n",
    "      annotations: {}\n",
    "      priorityClassName: \"\"\n",
    "      nodeSelector: {}\n",
    "      tolerations: []\n",
    "    config:\n",
    "      server:\n",
    "        grpc_server_max_recv_msg_size: 67108864 # 64MiB\n",
    "      query_scheduler:\n",
    "        grpc_client_config:\n",
    "          max_send_msg_size: 67108864 # 64MiB\n",
    "      limits_config:\n",
    "        retention_period: 24h\n",
    "        retention_stream:\n",
    "          - selector: '{suite=\"pachyderm\"}'\n",
    "            priority: 1\n",
    "            period: 168h # = 1 week\n",
    "  grafana:\n",
    "    enabled: false\n",
    "  promtail:\n",
    "    config:\n",
    "      clients:\n",
    "        - url: \"http://{{ .Release.Name }}-loki:3100/loki/api/v1/push\"\n",
    "      snippets:\n",
    "        # The scrapeConfigs section is copied from loki-stack-2.6.4\n",
    "        # The pipeline_stages.match stanza has been added to prevent multiple lokis in a cluster from mixing their logs.\n",
    "        scrapeConfigs: |\n",
    "          - job_name: kubernetes-pods\n",
    "            pipeline_stages:\n",
    "              {{- toYaml .Values.config.snippets.pipelineStages | nindent 4 }}\n",
    "              - match:\n",
    "                  selector: '{namespace!=\"{{ .Release.Namespace }}\"}'\n",
    "                  action: drop\n",
    "            kubernetes_sd_configs:\n",
    "              - role: pod\n",
    "            relabel_configs:\n",
    "              - source_labels:\n",
    "                  - __meta_kubernetes_pod_controller_name\n",
    "                regex: ([0-9a-z-.]+?)(-[0-9a-f]{8,10})?\n",
    "                action: replace\n",
    "                target_label: __tmp_controller_name\n",
    "              - source_labels:\n",
    "                  - __meta_kubernetes_pod_label_app_kubernetes_io_name\n",
    "                  - __meta_kubernetes_pod_label_app\n",
    "                  - __tmp_controller_name\n",
    "                  - __meta_kubernetes_pod_name\n",
    "                regex: ^;*([^;]+)(;.*)?$\n",
    "                action: replace\n",
    "                target_label: app\n",
    "              - source_labels:\n",
    "                  - __meta_kubernetes_pod_label_app_kubernetes_io_instance\n",
    "                  - __meta_kubernetes_pod_label_release\n",
    "                regex: ^;*([^;]+)(;.*)?$\n",
    "                action: replace\n",
    "                target_label: instance\n",
    "              - source_labels:\n",
    "                  - __meta_kubernetes_pod_label_app_kubernetes_io_component\n",
    "                  - __meta_kubernetes_pod_label_component\n",
    "                regex: ^;*([^;]+)(;.*)?$\n",
    "                action: replace\n",
    "                target_label: component\n",
    "              {{- if .Values.config.snippets.addScrapeJobLabel }}\n",
    "              - replacement: kubernetes-pods\n",
    "                target_label: scrape_job\n",
    "              {{- end }}\n",
    "              {{- toYaml .Values.config.snippets.common | nindent 4 }}\n",
    "              {{- with .Values.config.snippets.extraRelabelConfigs }}\n",
    "              {{- toYaml . | nindent 4 }}\n",
    "              {{- end }}\n",
    "        pipelineStages:\n",
    "          - cri: {}\n",
    "        common:\n",
    "          # This is copy and paste of existing actions, so we don't lose them.\n",
    "          # Cf. https://github.com/grafana/loki/issues/3519#issuecomment-1125998705\n",
    "          - action: replace\n",
    "            source_labels:\n",
    "              - __meta_kubernetes_pod_node_name\n",
    "            target_label: node_name\n",
    "          - action: replace\n",
    "            source_labels:\n",
    "              - __meta_kubernetes_namespace\n",
    "            target_label: namespace\n",
    "          - action: replace\n",
    "            replacement: $1\n",
    "            separator: /\n",
    "            source_labels:\n",
    "              - namespace\n",
    "              - app\n",
    "            target_label: job\n",
    "          - action: replace\n",
    "            source_labels:\n",
    "              - __meta_kubernetes_pod_name\n",
    "            target_label: pod\n",
    "          - action: replace\n",
    "            source_labels:\n",
    "              - __meta_kubernetes_pod_container_name\n",
    "            target_label: container\n",
    "          - action: replace\n",
    "            replacement: /var/log/pods/*$1/*.log\n",
    "            separator: /\n",
    "            source_labels:\n",
    "              - __meta_kubernetes_pod_uid\n",
    "              - __meta_kubernetes_pod_container_name\n",
    "            target_label: __path__\n",
    "          - action: replace\n",
    "            regex: true/(.*)\n",
    "            replacement: /var/log/pods/*$1/*.log\n",
    "            separator: /\n",
    "            source_labels:\n",
    "              - __meta_kubernetes_pod_annotationpresent_kubernetes_io_config_hash\n",
    "              - __meta_kubernetes_pod_annotation_kubernetes_io_config_hash\n",
    "              - __meta_kubernetes_pod_container_name\n",
    "            target_label: __path__\n",
    "          - action: keep\n",
    "            regex: pachyderm\n",
    "            source_labels:\n",
    "              - __meta_kubernetes_pod_label_suite\n",
    "          # this gets all kubernetes labels as well\n",
    "          - action: labelmap\n",
    "            regex: __meta_kubernetes_pod_label_(.+)\n",
    "    # Tolerations for promtail pods. Promtail must run on any node where pachyderm resources will run or you won't get any logs for them\n",
    "    # For example, GKE gpu nodes have a default taint of nvidia.com/gpu=present:NoSchedule so if you use GPUs we wouldn't have logs\n",
    "    tolerations: []\n",
    "    livenessProbe:\n",
    "      failureThreshold: 5\n",
    "      tcpSocket:\n",
    "        port: http-metrics\n",
    "      initialDelaySeconds: 10\n",
    "      periodSeconds: 10\n",
    "      successThreshold: 1\n",
    "      timeoutSeconds: 1\n",
    "\n",
    "# The pachw controller creates a pool of pachd instances running in 'pachw' mode which can dynamically scale to handle\n",
    "# storage related tasks\n",
    "pachw:\n",
    "  # When set to true, inheritFromPachd defaults below configuration options like 'resources' and 'tolerations' to\n",
    "  # values from pachd. These values can be overridden by defining the corresponding pachw values below.\n",
    "  # When set to false, a nil value will be used by default instead. Some configuration variables will always use their\n",
    "  # corresponding pachd value, regardless of whether 'inheritFromPachd' is true, such as 'serviceAccountName'\n",
    "  inheritFromPachd: true\n",
    "  # inSidecars is enabled by default to also process storage related tasks in pipeline storage sidecars like version 2.4 or less.\n",
    "  # when enabled, pachw instances can still run in their own dedicated kubernetes deployment if maxReplicas is greater than 0.\n",
    "  # For more control of where pachw instances run, 'inSidecars' can be disabled.\n",
    "  inSidecars: true\n",
    "  maxReplicas: 1\n",
    "  # minReplicas: 0\n",
    "  # We recommend defining resources when running pachw with a high value of maxReplicas.\n",
    "  #resources:\n",
    "  #  limits:\n",
    "  #    cpu: \"1\"\n",
    "  #    memory: \"2G\"\n",
    "  #  requests:\n",
    "  #    cpu: \"1\"\n",
    "  #  memory: \"2G\"\n",
    "  #\n",
    "  #tolerations: []\n",
    "  #affinity: {}\n",
    "  #nodeSelector: {}\n",
    "pachd:\n",
    "  enabled: true\n",
    "  preflightChecks:\n",
    "    # if enabled runs kube validation preflight checks.\n",
    "    enabled: true\n",
    "  affinity: {}\n",
    "  annotations: {}\n",
    "  # clusterDeploymentID sets the Pachyderm cluster ID.\n",
    "  clusterDeploymentID: \"\"\n",
    "  configJob:\n",
    "    annotations: {}\n",
    "  # goMaxProcs is passed as GOMAXPROCS to the pachd container.  pachd can automatically pick an\n",
    "  # optimal GOMAXPROCS from the configured CPU limit, but this overrides it.\n",
    "  goMaxProcs: 0\n",
    "  # goMemLimit is passed as GOMEMLIMIT to the pachd container. pachd can automatically pick an\n",
    "  # optimal GOMEMLIMIT from the configured memory request or limit, but this overrides it.  This is a string\n",
    "  # because it can be something like '256MiB'.\n",
    "  goMemLimit: \"\"\n",
    "  # gcPercent sets the initial garbage collection target percentage.\n",
    "  gcPercent: 0\n",
    "  image:\n",
    "    repository: \"pachyderm/pachd\"\n",
    "    pullPolicy: \"IfNotPresent\"\n",
    "    # tag defaults to the chart’s specified appVersion.\n",
    "    # This sets the worker image tag as well (they should be kept in lock step)\n",
    "    tag: \"\"\n",
    "  logLevel: \"info\"\n",
    "  disableLogSampling: false\n",
    "  developmentLogger: false\n",
    "  # If lokiDeploy is true, a Pachyderm-specific instance of Loki will\n",
    "  # be deployed.\n",
    "  lokiDeploy: true\n",
    "  # lokiLogging enables Loki logging if set.\n",
    "  lokiLogging: true\n",
    "  metrics:\n",
    "    # enabled sets the METRICS environment variable if set.\n",
    "    enabled: true\n",
    "    # endpoint should be the URL of the metrics endpoint.\n",
    "    endpoint: \"\"\n",
    "  priorityClassName: \"\"\n",
    "  nodeSelector: {}\n",
    "  # podLabels specifies labels to add to the pachd pod.\n",
    "  podLabels: {}\n",
    "  # resources specifies the resource requests and limits\n",
    "  # replicas sets the number of pachd running pods\n",
    "  replicas: 1\n",
    "  resources:\n",
    "    {}\n",
    "    #limits:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "    #requests:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "  # requireCriticalServersOnly only requires the critical pachd\n",
    "  # servers to startup and run without errors.  It is analogous to the\n",
    "  # --require-critical-servers-only argument to pachctl deploy.\n",
    "  requireCriticalServersOnly: false\n",
    "  # If enabled, External service creates a service which is safe to\n",
    "  # be exposed externally\n",
    "  externalService:\n",
    "    enabled: false\n",
    "    # (Optional) specify the existing IP Address of the load balancer\n",
    "    loadBalancerIP: \"\"\n",
    "    apiGRPCPort: 30650\n",
    "    s3GatewayPort: 30600\n",
    "    annotations: {}\n",
    "  service:\n",
    "    # labels specifies labels to add to the pachd service.\n",
    "    labels: {}\n",
    "    # type specifies the Kubernetes type of the pachd service.\n",
    "    type: \"ClusterIP\"\n",
    "    annotations: {}\n",
    "    apiGRPCPort: 30650\n",
    "    prometheusPort: 30656\n",
    "    oidcPort: 30657\n",
    "    identityPort: 30658\n",
    "    s3GatewayPort: 30600\n",
    "    #apiGrpcPort:\n",
    "    #  expose: true\n",
    "    #  port: 30650\n",
    "  # DEPRECATED: activateEnterprise is no longer used.\n",
    "  activateEnterprise: false\n",
    "  ## if pachd.activateEnterpriseMember is set, enterprise will be activated and connected to an existing enterprise server.\n",
    "  ## if pachd.enterpriseLicenseKey is set, enterprise will be activated.\n",
    "  activateEnterpriseMember: false\n",
    "  ## if pachd.activateAuth is set, auth will be bootstrapped by the config-job.\n",
    "  activateAuth: true\n",
    "  ## the license key used to activate enterprise features\n",
    "  enterpriseLicenseKey: \"\"\n",
    "  # enterpriseLicenseKeySecretName is used to pass the enterprise license key value via an existing k8s secret.\n",
    "  # The value is pulled from the key, \"enterprise-license-key\".\n",
    "  enterpriseLicenseKeySecretName: \"\"\n",
    "  # if a token is not provided, a secret will be autogenerated on install and stored in the k8s secret 'pachyderm-bootstrap-config.rootToken'\n",
    "  rootToken: \"\"\n",
    "  # rootTokenSecretName is used to pass the rootToken value via an existing k8s secret\n",
    "  # The value is pulled from the key, \"root-token\".\n",
    "  rootTokenSecretName: \"\"\n",
    "  # if a secret is not provided, a secret will be autogenerated on install and stored in the k8s secret 'pachyderm-bootstrap-config.enterpriseSecret'\n",
    "  enterpriseSecret: \"\"\n",
    "  # enterpriseSecretSecretName is used to pass the enterprise secret value via an existing k8s secret.\n",
    "  # The value is pulled from the key, \"enterprise-secret\".\n",
    "  enterpriseSecretSecretName: \"\"\n",
    "  # if a secret is not provided, a secret will be autogenerated on install and stored in the k8s secret 'pachyderm-bootstrap-config.authConfig.clientSecret'\n",
    "  oauthClientID: pachd\n",
    "  oauthClientSecret: \"\"\n",
    "  # oauthClientSecretSecretName is used to set the OAuth Client Secret via an existing k8s secret.\n",
    "  # The value is pulled from the key, \"pachd-oauth-client-secret\".\n",
    "  oauthClientSecretSecretName: \"\"\n",
    "  oauthRedirectURI: \"\"\n",
    "  # DEPRECATED: enterpriseRootToken is deprecated, in favor of enterpriseServerToken\n",
    "  # NOTE only used if pachd.activateEnterpriseMember == true\n",
    "  enterpriseRootToken: \"\"\n",
    "  # DEPRECATED: enterpriseRootTokenSecretName is deprecated in favor of enterpriseServerTokenSecretName\n",
    "  # enterpriseRootTokenSecretName is used to pass the enterpriseRootToken value via an existing k8s secret.\n",
    "  # The value is pulled from the key, \"enterprise-root-token\".\n",
    "  enterpriseRootTokenSecretName: \"\"\n",
    "  # enterpriseServerToken represents a token that can authenticate to a separate pachyderm enterprise server,\n",
    "  # and is used to complete the enterprise member registration process for this pachyderm cluster.\n",
    "  # The user backing this token should have either the licenseAdmin & identityAdmin roles assigned, or\n",
    "  # the clusterAdmin role.\n",
    "  # NOTE: only used if pachd.activateEnterpriseMember == true\n",
    "  enterpriseServerToken: \"\"\n",
    "  # enterpriseServerTokenSecretName is used to pass the enterpriseServerToken value via an existing k8s secret.\n",
    "  # The value is pulled from the key, \"enterprise-server-token\".\n",
    "  enterpriseServerTokenSecretName: \"\"\n",
    "  # only used if pachd.activateEnterpriseMember == true\n",
    "  enterpriseServerAddress: \"\"\n",
    "  enterpriseCallbackAddress: \"\"\n",
    "  # Indicates to pachd whether dex is embedded in its process.\n",
    "  localhostIssuer: \"\" # \"true\", \"false\", or \"\" (used string as bool doesn't support empty value)\n",
    "  # set the initial pachyderm cluster role bindings, mapping a user to their list of roles\n",
    "  # ex.\n",
    "  # pachAuthClusterRoleBindings:\n",
    "  #   robot:wallie:\n",
    "  #   - repoReader\n",
    "  #   robot:eve:\n",
    "  #   - repoWriter\n",
    "  pachAuthClusterRoleBindings: {}\n",
    "  # additionalTrustedPeers is used to configure the identity service to recognize additional OIDC clients as trusted peers of pachd.\n",
    "  # For example, see the following example or the dex docs (https://dexidp.io/docs/custom-scopes-claims-clients/#cross-client-trust-and-authorized-party).\n",
    "  # additionalTrustedPeers:\n",
    "  #   - example-app\n",
    "  additionalTrustedPeers: []\n",
    "  serviceAccount:\n",
    "    create: true\n",
    "    additionalAnnotations: {}\n",
    "    name: \"pachyderm\" #TODO Set default in helpers / Wire up in templates\n",
    "  storage:\n",
    "    # backend configures the storage backend to use.  It must be one\n",
    "    # of GOOGLE, AMAZON, MINIO, MICROSOFT or LOCAL. This is set automatically\n",
    "    # if deployTarget is GOOGLE, AMAZON, MICROSOFT, or LOCAL\n",
    "    backend: \"\"\n",
    "    amazon:\n",
    "      # bucket sets the S3 bucket to use.\n",
    "      bucket: \"\"\n",
    "      # cloudFrontDistribution sets the CloudFront distribution in the\n",
    "      # storage secrets.  It is analogous to the\n",
    "      # --cloudfront-distribution argument to pachctl deploy.\n",
    "      cloudFrontDistribution: \"\"\n",
    "      customEndpoint: \"\"\n",
    "      # disableSSL disables SSL.  It is analogous to the --disable-ssl\n",
    "      # argument to pachctl deploy.\n",
    "      disableSSL: false\n",
    "      # id sets the Amazon access key ID to use.  Together with secret\n",
    "      # and token, it implements the functionality of the\n",
    "      # --credentials argument to pachctl deploy.\n",
    "      id: \"\"\n",
    "      # logOptions sets various log options in Pachyderm’s internal S3\n",
    "      # client.  Comma-separated list containing zero or more of:\n",
    "      # 'Debug', 'Signing', 'HTTPBody', 'RequestRetries',\n",
    "      # 'RequestErrors', 'EventStreamBody', or 'all'\n",
    "      # (case-insensitive).  See 'AWS SDK for Go' docs for details.\n",
    "      # logOptions is analogous to the --obj-log-options argument to\n",
    "      # pachctl deploy.\n",
    "      logOptions: \"\"\n",
    "      # maxUploadParts sets the maximum number of upload parts.  It is\n",
    "      # analogous to the --max-upload-parts argument to pachctl\n",
    "      # deploy.\n",
    "      maxUploadParts: 10000\n",
    "      # verifySSL performs SSL certificate verification.  It is the\n",
    "      # inverse of the --no-verify-ssl argument to pachctl deploy.\n",
    "      verifySSL: true\n",
    "      # partSize sets the part size for object storage uploads.  It is\n",
    "      # analogous to the --part-size argument to pachctl deploy.  It\n",
    "      # has to be a string due to Helm and YAML parsing integers as\n",
    "      # floats.  Cf. https://github.com/helm/helm/issues/1707\n",
    "      partSize: \"5242880\"\n",
    "      # region sets the AWS region to use.\n",
    "      region: \"\"\n",
    "      # retries sets the number of retries for object storage\n",
    "      # requests.  It is analogous to the --retries argument to\n",
    "      # pachctl deploy.\n",
    "      retries: 10\n",
    "      # reverse reverses object storage paths.  It is analogous to the\n",
    "      # --reverse argument to pachctl deploy.\n",
    "      reverse: true\n",
    "      # secret sets the Amazon secret access key to use.  Together with id\n",
    "      # and token, it implements the functionality of the\n",
    "      # --credentials argument to pachctl deploy.\n",
    "      secret: \"\"\n",
    "      # timeout sets the timeout for object storage requests.  It is\n",
    "      # analogous to the --timeout argument to pachctl deploy.\n",
    "      timeout: \"5m\"\n",
    "      # token optionally sets the Amazon token to use.  Together with\n",
    "      # id and secret, it implements the functionality of the\n",
    "      # --credentials argument to pachctl deploy.\n",
    "      token: \"\"\n",
    "      # uploadACL sets the upload ACL for object storage uploads.  It\n",
    "      # is analogous to the --upload-acl argument to pachctl deploy.\n",
    "      uploadACL: \"bucket-owner-full-control\"\n",
    "    google:\n",
    "      bucket: \"\"\n",
    "      # cred is a string containing a GCP service account private key,\n",
    "      # in object (JSON or YAML) form.  A simple way to pass this on\n",
    "      # the command line is with the set-file flag, e.g.:\n",
    "      #\n",
    "      #  helm install pachd -f my-values.yaml --set-file storage.google.cred=creds.json pachyderm/pachyderm\n",
    "      cred: \"\"\n",
    "      # Example:\n",
    "      # cred: |\n",
    "      #  {\n",
    "      #    \"type\": \"service_account\",\n",
    "      #    \"project_id\": \"…\",\n",
    "      #    \"private_key_id\": \"…\",\n",
    "      #    \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n…\\n-----END PRIVATE KEY-----\\n\",\n",
    "      #    \"client_email\": \"…@….iam.gserviceaccount.com\",\n",
    "      #    \"client_id\": \"…\",\n",
    "      #    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "      #    \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "      #    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "      #    \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/…%40….iam.gserviceaccount.com\"\n",
    "      #  }\n",
    "    local:\n",
    "      # hostPath indicates the path on the host where the PFS metadata\n",
    "      # will be stored.  It must end in /.  It is analogous to the\n",
    "      # --host-path argument to pachctl deploy.\n",
    "      hostPath: \"\"\n",
    "      requireRoot: true #Root required for hostpath, but we run rootless in CI\n",
    "    microsoft:\n",
    "      container: \"\"\n",
    "      id: \"\"\n",
    "      secret: \"\"\n",
    "    minio:\n",
    "      # minio bucket name\n",
    "      bucket: \"\"\n",
    "      # the minio endpoint. Should only be the hostname:port, no http/https.\n",
    "      endpoint: \"\"\n",
    "      # the username/id with readwrite access to the bucket.\n",
    "      id: \"\"\n",
    "      # the secret/password of the user with readwrite access to the bucket.\n",
    "      secret: \"\"\n",
    "      # enable https for minio with \"true\" defaults to \"false\"\n",
    "      secure: \"\"\n",
    "      # Enable S3v2 support by setting signature to \"1\". This feature is being deprecated\n",
    "      signature: \"\"\n",
    "    # putFileConcurrencyLimit sets the maximum number of files to\n",
    "    # upload or fetch from remote sources (HTTP, blob storage) using\n",
    "    # PutFile concurrently.  It is analogous to the\n",
    "    # --put-file-concurrency-limit argument to pachctl deploy.\n",
    "    putFileConcurrencyLimit: 100\n",
    "    # uploadConcurrencyLimit sets the maximum number of concurrent\n",
    "    # object storage uploads per Pachd instance.  It is analogous to\n",
    "    # the --upload-concurrency-limit argument to pachctl deploy.\n",
    "    uploadConcurrencyLimit: 100\n",
    "    # The shard size corresponds to the total size of the files in a shard.\n",
    "    # The shard count corresponds to the total number of files in a shard.\n",
    "    # If either criteria is met, a shard will be created.\n",
    "    # values are strings\n",
    "    compactionShardSizeThreshold: \"0\"\n",
    "    compactionShardCountThreshold: \"0\"\n",
    "    memoryThreshold: 0\n",
    "    levelFactor: 0\n",
    "    maxFanIn: 10\n",
    "    maxOpenFileSets: 50\n",
    "    # diskCacheSize and memoryCacheSize are defined in units of 8 Mb chunks. The default is 100 chunks which is 800 Mb.\n",
    "    diskCacheSize: 100\n",
    "    memoryCacheSize: 100\n",
    "  ppsWorkerGRPCPort: 1080\n",
    "  # the number of seconds between pfs's garbage collection cycles.\n",
    "  # if this value is set to 0, it will default to pachyderm's internal configuration.\n",
    "  # if this value is less than 0, it will turn off garbage collection.\n",
    "  storageGCPeriod: 0\n",
    "  # the number of seconds between chunk garbage colletion cycles.\n",
    "  # if this value is set to 0, it will default to pachyderm's internal configuration.\n",
    "  # if this value is less than 0, it will turn off chunk garbage collection.\n",
    "  storageChunkGCPeriod: 0\n",
    "  # There are three options for TLS:\n",
    "  # 1. Disabled\n",
    "  # 2. Enabled, existingSecret, specify secret name\n",
    "  # 3. Enabled, newSecret, must specify cert, key and name\n",
    "  tls:\n",
    "    enabled: false\n",
    "    secretName: \"\"\n",
    "    newSecret:\n",
    "      create: false\n",
    "      crt: \"\"\n",
    "      key: \"\"\n",
    "  tolerations: []\n",
    "  worker:\n",
    "    image:\n",
    "      repository: \"pachyderm/worker\"\n",
    "      pullPolicy: \"IfNotPresent\"\n",
    "      # Worker tag is set under pachd.image.tag (they should be kept in lock step)\n",
    "    serviceAccount:\n",
    "      create: true\n",
    "      additionalAnnotations: {}\n",
    "      # name sets the name of the worker service account.  Analogous to\n",
    "      # the --worker-service-account argument to pachctl deploy.\n",
    "      name: \"pachyderm-worker\" #TODO Set default in helpers / Wire up in templates\n",
    "  rbac:\n",
    "    # create indicates whether RBAC resources should be created.\n",
    "    # Setting it to false is analogous to passing --no-rbac to pachctl\n",
    "    # deploy.\n",
    "    create: true\n",
    "  # Set up default resources for pipelines that don't include any requests or limits.  The values\n",
    "  # are k8s resource quantities, so \"1Gi\", \"2\", etc.  Set to \"0\" to disable setting any defaults.\n",
    "  defaultPipelineCPURequest: \"\"\n",
    "  defaultPipelineMemoryRequest: \"\"\n",
    "  defaultPipelineStorageRequest: \"\"\n",
    "kubeEventTail:\n",
    "  # Deploys a lightweight app that watches kubernetes events and echos them to logs.\n",
    "  enabled: true\n",
    "  # clusterScope determines whether kube-event-tail should watch all events or just events in its namespace.\n",
    "  clusterScope: false\n",
    "  image:\n",
    "    repository: pachyderm/kube-event-tail\n",
    "    pullPolicy: \"IfNotPresent\"\n",
    "    tag: \"v0.0.7\"\n",
    "  resources:\n",
    "    limits:\n",
    "      cpu: \"1\"\n",
    "      memory: 100Mi\n",
    "    requests:\n",
    "      cpu: 100m\n",
    "      memory: 45Mi\n",
    "\n",
    "pgbouncer:\n",
    "  service:\n",
    "    type: ClusterIP\n",
    "  annotations: {}\n",
    "  priorityClassName: \"\"\n",
    "  nodeSelector: {}\n",
    "  tolerations: []\n",
    "  image:\n",
    "    repository: pachyderm/pgbouncer\n",
    "    tag: 1.16.2\n",
    "  resources:\n",
    "    {}\n",
    "    #limits:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "    #requests:\n",
    "    #  cpu: \"1\"\n",
    "    #  memory: \"2G\"\n",
    "  # maxConnections specifies the maximum number of concurrent connections into pgbouncer.\n",
    "  maxConnections: 1000\n",
    "  # defaultPoolSize specifies the maximum number of concurrent connections from pgbouncer to the postgresql database.\n",
    "  defaultPoolSize: 20\n",
    "\n",
    "# Note: Postgres values control the Bitnami Postgresql Subchart\n",
    "postgresql:\n",
    "  # enabled controls whether to install postgres or not.\n",
    "  # If not using the built in Postgres, you must specify a Postgresql\n",
    "  # database server to connect to in global.postgresql\n",
    "  # The enabled value is watched by the 'condition' set on the Postgresql\n",
    "  # dependency in Chart.yaml\n",
    "  enabled: true\n",
    "  image:\n",
    "    repository: pachyderm/postgresql\n",
    "    tag: \"13.3.0\"\n",
    "  # DEPRECATED from pachyderm 2.1.5\n",
    "  initdbScripts:\n",
    "    dex.sh: |\n",
    "      #!/bin/bash\n",
    "      set -e\n",
    "      psql -v ON_ERROR_STOP=1 --username \"$POSTGRES_USER\" --dbname \"$POSTGRES_DB\" <<-EOSQL\n",
    "        CREATE DATABASE dex;\n",
    "        GRANT ALL PRIVILEGES ON DATABASE dex TO \"$POSTGRES_USER\";\n",
    "      EOSQL\n",
    "  fullnameOverride: postgres\n",
    "  persistence:\n",
    "    # Specify the storage class for the postgresql Persistent Volume (PV)\n",
    "    # See notes in Bitnami chart values.yaml file for more information.\n",
    "    # More info for setting up storage classes on various cloud providers:\n",
    "    # AWS: https://docs.aws.amazon.com/eks/latest/userguide/storage-classes.html\n",
    "    # GCP: https://cloud.google.com/compute/docs/disks/performance#disk_types\n",
    "    # Azure: https://docs.microsoft.com/en-us/azure/aks/concepts-storage#storage-classes\n",
    "    storageClass: \"\"\n",
    "    # storageSize specifies the size of the volume to use for postgresql\n",
    "    # Recommended Minimum Disk size for Microsoft/Azure: 256Gi  - 1,100 IOPS https://azure.microsoft.com/en-us/pricing/details/managed-disks/\n",
    "    # Recommended Minimum Disk size for Google/GCP: 50Gi        - 1,500 IOPS https://cloud.google.com/compute/docs/disks/performance\n",
    "    # Recommended Minimum Disk size for Amazon/AWS: 500Gi (GP2) - 1,500 IOPS https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html\n",
    "    size: 10Gi\n",
    "    labels:\n",
    "      suite: pachyderm\n",
    "  primary:\n",
    "    priorityClassName: \"\"\n",
    "    nodeSelector: {}\n",
    "    tolerations: []\n",
    "  readReplicas:\n",
    "    priorityClassName: \"\"\n",
    "    nodeSelector: {}\n",
    "    tolerations: []\n",
    "\n",
    "cloudsqlAuthProxy:\n",
    "  # connectionName may be found by running `gcloud sql instances describe INSTANCE_NAME --project PROJECT_ID`\n",
    "  connectionName: \"\"\n",
    "  serviceAccount: \"\"\n",
    "  iamLogin: false\n",
    "  port: 5432\n",
    "  enabled: false\n",
    "  image:\n",
    "    # repository is the image repo to pull from; together with tag it\n",
    "    # replicates the --dash-image & --registry arguments to pachctl\n",
    "    # deploy.\n",
    "    repository: \"gcr.io/cloudsql-docker/gce-proxy\"\n",
    "    pullPolicy: \"IfNotPresent\"\n",
    "    # tag is the image repo to pull from; together with repository it\n",
    "    # replicates the --dash-image argument to pachctl deploy.\n",
    "    tag: \"1.23.0\"\n",
    "  priorityClassName: \"\"\n",
    "  nodeSelector: {}\n",
    "  tolerations: []\n",
    "  # podLabels specifies labels to add to the dash pod.\n",
    "  podLabels: {}\n",
    "  # resources specifies the resource request and limits.\n",
    "  resources: {}\n",
    "  #  requests:\n",
    "  #    # The proxy's memory use scales linearly with the number of active\n",
    "  #    # connections. Fewer open connections will use less memory. Adjust\n",
    "  #    # this value based on your application's requirements.\n",
    "  #    memory: \"\"\n",
    "  #    # The proxy's CPU use scales linearly with the amount of IO between\n",
    "  #    # the database and the application. Adjust this value based on your\n",
    "  #    # application's requirements.\n",
    "  #    cpu: \"\"\n",
    "  service:\n",
    "    # labels specifies labels to add to the cloudsql auth proxy service.\n",
    "    labels: {}\n",
    "    # type specifies the Kubernetes type of the cloudsql auth proxy service.\n",
    "    type: ClusterIP\n",
    "\n",
    "oidc:\n",
    "  issuerURI: \"\" #Inferred if running locally or using ingress\n",
    "  requireVerifiedEmail: false\n",
    "  # IDTokenExpiry is parsed into golang's time.Duration: https://pkg.go.dev/time#example-ParseDuration\n",
    "  IDTokenExpiry: 24h\n",
    "  # (Optional) If set, enables OIDC rotation tokens, and specifies the duration where they are valid.\n",
    "  # RotationTokenExpiry is parsed into golang's time.Duration: https://pkg.go.dev/time#example-ParseDuration\n",
    "  RotationTokenExpiry: 48h\n",
    "  # (Optional) Only set in cases where the issuerURI is not user accessible (ie. localhost install)\n",
    "  userAccessibleOauthIssuerHost: \"\"\n",
    "  ## to set up upstream IDPs, set pachd.mockIDP to false,\n",
    "  ## and populate the pachd.upstreamIDPs with an array of Dex Connector configurations.\n",
    "  ## See the example below or https://dexidp.io/docs/connectors/\n",
    "  # upstreamIDPs:\n",
    "  #   - id: idpConnector\n",
    "  #     config:\n",
    "  #       issuer: \"\"\n",
    "  #       clientID: \"\"\n",
    "  #       clientSecret: \"\"\n",
    "  #       redirectURI: \"http://localhost:30658/callback\"\n",
    "  #       insecureEnableGroups: true\n",
    "  #       insecureSkipEmailVerified: true\n",
    "  #       insecureSkipIssuerCallbackDomainCheck: true\n",
    "  #       forwardedLoginParams:\n",
    "  #       - login_hint\n",
    "  #     name: idpConnector\n",
    "  #     type: oidc\n",
    "  #\n",
    "  #   - id: okta\n",
    "  #     config:\n",
    "  #       issuer: \"https://dev-84362674.okta.com\"\n",
    "  #       clientID: \"client_id\"\n",
    "  #       clientSecret: \"notsecret\"\n",
    "  #       redirectURI: \"http://localhost:30658/callback\"\n",
    "  #       insecureEnableGroups: true\n",
    "  #       insecureSkipEmailVerified: true\n",
    "  #       insecureSkipIssuerCallbackDomainCheck: true\n",
    "  #       forwardedLoginParams:\n",
    "  #       - login_hint\n",
    "  #     name: okta\n",
    "  #     type: oidc\n",
    "  upstreamIDPs: []\n",
    "  # upstreamIDPsSecretName is used to pass the upstreamIDPs value via an existing k8s secret.\n",
    "  # The value is pulled from the secret key, \"upstream-idps\".\n",
    "  upstreamIDPsSecretName: \"\"\n",
    "  # Some dex configurations (like Google) require a credential file. Whatever secret is included in this\n",
    "  # below secret will be mounted to the pachd pod at /dexcreds/ so for example serviceAccountFilePath: /dexcreds/googleAuth.json\n",
    "  dexCredentialSecretName: \"\"\n",
    "  mockIDP: true\n",
    "  # additionalClients specifies a list of clients for the cluster to recognize\n",
    "  # See the ecample below or the dex docs (https://dexidp.io/docs/using-dex/#configuring-your-app).\n",
    "  # additionalOIDCClient:\n",
    "  #   - id: example-app\n",
    "  #     secret: example-app-secret\n",
    "  #     name: 'Example App'\n",
    "  #     redirectURIs:\n",
    "  #     - 'http://127.0.0.1:5555/callback'\n",
    "  additionalClients: []\n",
    "  additionalClientsSecretName: \"\"\n",
    "  #TODO scopes:\n",
    "\n",
    "testConnection:\n",
    "  image:\n",
    "    repository: alpine\n",
    "    tag: latest\n",
    "\n",
    "# The proxy is a service to handle all Pachyderm traffic (S3, Console, OIDC, Dex, GRPC) on a single\n",
    "# port; good for exposing directly to the Internet.\n",
    "proxy:\n",
    "  # If enabled, create a proxy deployment (based on the Envoy proxy) and a service to expose it.  If\n",
    "  # ingress is also enabled, any Ingress traffic will be routed through the proxy before being sent\n",
    "  # to pachd or Console.\n",
    "  enabled: true\n",
    "  # The external hostname (including port if nonstandard) that the proxy will be reachable at.\n",
    "  # If you have ingress enabled and an ingress hostname defined, the proxy will use that.\n",
    "  # Ingress will be deprecated in the future so configuring the proxy host instead is recommended.\n",
    "  host: \"\"\n",
    "  # The number of proxy replicas to run.  1 should be fine, but if you want more for higher\n",
    "  # availability, that's perfectly reasonable.  Each replica can handle 50,000 concurrent\n",
    "  # connections.  There is an affinity rule to prefer scheduling the proxy pods on the same node as\n",
    "  # pachd, so a number here that matches the number of pachd replicas is a fine configuration.\n",
    "  # (Note that we don't guarantee to keep the proxy<->pachd traffic on-node or even in-region.)\n",
    "  replicas: 1\n",
    "  # The envoy image to pull.\n",
    "  image:\n",
    "    repository: \"envoyproxy/envoy-distroless\"\n",
    "    tag: \"v1.24.1\"\n",
    "    pullPolicy: \"IfNotPresent\"\n",
    "  # Set up resources.  The proxy is configured to shed traffic before using 500MB of RAM, so that's\n",
    "  # a resonable memory limit.  It doesn't need much CPU.\n",
    "  resources:\n",
    "    requests:\n",
    "      cpu: 100m\n",
    "      memory: 512Mi\n",
    "    limits:\n",
    "      memory: 512Mi\n",
    "  # Any additional labels to add to the pods.  These are also added to the deployment and service\n",
    "  # selectors.\n",
    "  labels: {}\n",
    "  # Any additional annotations to add to the pods.\n",
    "  annotations: {}\n",
    "  # A nodeSelector statement for each pod in the proxy Deployment, if desired.\n",
    "  nodeSelector: {}\n",
    "  # A tolerations statement for each pod in the proxy Deployment, if desired.\n",
    "  tolerations: []\n",
    "  # A priority class name for each pod in the proxy Deployment, if desired.\n",
    "  priorityClassName: \"\"\n",
    "  # Configure the service that routes traffic to the proxy.\n",
    "  service:\n",
    "    # The type of service can be ClusterIP, NodePort, or LoadBalancer.\n",
    "    type: ClusterIP\n",
    "    # If the service is a LoadBalancer, you can specify the IP address to use.\n",
    "    loadBalancerIP: \"\"\n",
    "    # The port to serve plain HTTP traffic on.\n",
    "    httpPort: 80\n",
    "    # The port to serve HTTPS traffic on, if enabled below.\n",
    "    httpsPort: 443\n",
    "    # If the service is a NodePort, you can specify the port to receive HTTP traffic on.\n",
    "    httpNodePort: 30080\n",
    "    httpsNodePort: 30443\n",
    "    # Any additional annotations to add.\n",
    "    annotations: {}\n",
    "    # Any additional labels to add to the service itself (not the selector!).\n",
    "    labels: {}\n",
    "    # The proxy can also serve each backend service on a numbered port, and will do so for any port\n",
    "    # not numbered 0 here.  If this service is of type NodePort, the port numbers here will be used\n",
    "    # for the node port, and will need to be in the node port range.\n",
    "    legacyPorts:\n",
    "      console: 0 # legacy 30080, conflicts with default httpNodePort\n",
    "      grpc: 0 # legacy 30650\n",
    "      s3Gateway: 0 # legacy 30600\n",
    "      oidc: 0 # legacy 30657\n",
    "      identity: 0 # legacy 30658\n",
    "      metrics: 0 # legacy 30656\n",
    "    # externalTrafficPolicy determines cluster-wide routing policy; see \"kubectl explain\n",
    "    # service.spec.externalTrafficPolicy\".\n",
    "    externalTrafficPolicy: \"\"\n",
    "  # Configuration for TLS (SSL, HTTPS).\n",
    "  tls:\n",
    "    # If true, enable TLS serving.  Enabling TLS is incompatible with support for legacy ports (you\n",
    "    # can't get a generally-trusted certificate for port numbers), and disables support for\n",
    "    # cleartext communication (cleartext requests will redirect to the secure server, and HSTS\n",
    "    # headers are set to prevent downgrade attacks).\n",
    "    #\n",
    "    # Note that if you are planning on putting the proxy behind an ingress controller, you probably\n",
    "    # want to configure TLS for the ingress controller, not the proxy.  This is intended for the\n",
    "    # case where the proxy is exposed directly to the Internet.  (It is possible to have your\n",
    "    # ingress controller talk to the proxy over TLS, in which case, it's fine to enable TLS here in\n",
    "    # addition to in the ingress section above.)\n",
    "    enabled: false\n",
    "    # The secret containing \"tls.key\" and \"tls.crt\" keys that contain PEM-encoded private key and\n",
    "    # certificate material.  Generate one with \"kubectl create secret tls <name> --key=tls.key\n",
    "    # --cert=tls.cert\".  This format is compatible with the secrets produced by cert-manager, and\n",
    "    # the proxy will pick up new data when cert-manager rotates the certificate.\n",
    "    secretName: \"\"\n",
    "    # If set, generate the secret from values here.  This is intended only for unit tests.\n",
    "    secret: {}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166e78a-5714-4e68-bfc0-8a4f3fd8efd1",
   "metadata": {},
   "source": [
    "## Deploy Persistent Volumes Kubernetes\n",
    "\n",
    "The pachyderm solution will rely on several services to make the solution work. Such as etcd, postgresql, loki, and others. These services in particular will require access to storage. \n",
    "\n",
    "We will provide storage to kubernetes hosted services through a kubernetes resource called Persistend Volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289d842-22cf-4f7f-a65e-533e6fe476ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54a052d4-bf2f-4b36-a65e-b0fac2797e87",
   "metadata": {},
   "source": [
    "### Understanding Volumes\n",
    "> Volumes\n",
    ">\n",
    "> On-disk files in a container are ephemeral, which presents some problems for non-trivial applications when running in containers. One problem occurs when a container crashes or is stopped. Container state is not saved so all of the files that were created or modified during the lifetime of the container are lost. During a crash, kubelet restarts the container with a clean state. Another problem occurs when multiple containers are running in a Pod and need to share files. It can be challenging to setup and access a shared filesystem across all of the containers. The Kubernetes volume abstraction solves both of these problems.\n",
    ">\n",
    "> ...\n",
    ">\n",
    "> Kubernetes supports many types of volumes. A Pod can use any number of volume types simultaneously. Ephemeral volume types have a lifetime of a pod, but persistent volumes exist beyond the lifetime of a pod. When a pod ceases to exist, Kubernetes destroys ephemeral volumes; however, Kubernetes does not destroy persistent volumes. For any kind of volume in a given pod, data is preserved across container restarts.\n",
    ">\n",
    "> At its core, a volume is a directory, possibly with some data in it, which is accessible to the containers in a pod. How that directory comes to be, the medium that backs it, and the contents of it are determined by the particular volume type used.\n",
    ">\n",
    "\n",
    "> https://kubernetes.io/docs/concepts/storage/volumes/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e0a9a-b8b4-4515-bd0b-8663774c5dab",
   "metadata": {},
   "source": [
    "### Understanding Persistent Volumes\n",
    "Persistent Volumes are a non-ephemeral volume implimentation. They are a kubernetes resource which provides storage.\n",
    "\n",
    "> A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system.\n",
    ">\n",
    "> https://kubernetes.io/docs/concepts/storage/persistent-volumes/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd7bf6d-dbfb-4d70-a472-5fc1243c4277",
   "metadata": {},
   "source": [
    "Persistent Volume Claims are requests to have resources allocated to them.\n",
    "\n",
    "> A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted ReadWriteOnce, ReadOnlyMany or ReadWriteMany, see AccessModes).\n",
    ">\n",
    "> https://kubernetes.io/docs/concepts/storage/persistent-volumes/\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c35265-989f-436f-a71e-3e0aba9948c6",
   "metadata": {},
   "source": [
    "### Understanding Storage Classes\n",
    "\n",
    "The Persistant Volume Claim allows a user to request access to specific storage resources. But in some cases, we may want to logically classify our storage and then make a selection from a particular classification. For example if we want a 7200 rpm disk vs a 5200 rpm disk. Storage Classes provide this abstraction:\n",
    "\n",
    "> A StorageClass provides a way for administrators to describe the \"classes\" of storage they offer. Different classes might map to quality-of-service levels, or to backup policies, or to arbitrary policies determined by the cluster administrators. Kubernetes itself is unopinionated about what classes represent. This concept is sometimes called \"profiles\" in other storage systems\n",
    "> \n",
    "> https://kubernetes.io/docs/concepts/storage/storage-classes/\n",
    ">\n",
    "> While PersistentVolumeClaims allow a user to consume abstract storage resources, it is common that users need PersistentVolumes with varying properties, such as performance, for different problems. Cluster administrators need to be able to offer a variety of PersistentVolumes that differ in more ways than size and access modes, without exposing users to the details of how those volumes are implemented. For these needs, there is the StorageClass resource.\n",
    "> \n",
    "> https://kubernetes.io/docs/concepts/storage/persistent-volumes/\n",
    ">\n",
    "> Each StorageClass has a provisioner that determines what volume plugin is used for provisioning PVs. This field must be specified.\n",
    ">\n",
    "> https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner\n",
    "\n",
    "Kubernetes supports the following Volumn plugins and provisioners:\n",
    "\n",
    "|Volume Plugin | Internal Provisioner | Config Example |\n",
    "|--------------|----------------------|----------------|\n",
    "|AWSElasticBlockStore | ✓ | AWS EBS |\n",
    "|AzureFile | ✓ | Azure File |\n",
    "|AzureDisk | ✓ | Azure Disk |\n",
    "|CephFS | - | - |\n",
    "|Cinder | ✓ | OpenStack Cinder |\n",
    "|FC | - | - |\n",
    "|FlexVolume | - | -\n",
    "|GCEPersistentDisk | ✓ | GCE PD |\n",
    "|iSCSI | - | - |\n",
    "|NFS | - | NFS |\n",
    "|RBD | ✓ | Ceph RBD |\n",
    "|VsphereVolume | ✓ | vSphere |\n",
    "|PortworxVolume | ✓ | Portworx Volume |\n",
    "|Local | - | Local |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd089cd6-4fa6-4508-bd60-51a3a543c0df",
   "metadata": {},
   "source": [
    "### The NFS Storage Class\n",
    "\n",
    "For my deployment I will keep things simple and use an NFS storage volume. In the past I have used ceph, but in this case I will keep things very simple.\n",
    "\n",
    "**Note**: Kubernetes doesn't include an internal NFS provisioner. You need to use an external provisioner to create a StorageClass for NFS. Here are some examples:\n",
    "\n",
    "- NFS Ganesha server and external provisioner\n",
    "- NFS subdir external provisioner\n",
    "\n",
    "Configuration example and documentation can be found [here](https://kubernetes.io/docs/concepts/storage/storage-classes/#nfs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25829d84-e2cd-41fd-8464-e100cdac3d4f",
   "metadata": {},
   "source": [
    "#### Installing the NFS server\n",
    "\n",
    "https://dev.to/prajwalmithun/setup-nfs-server-client-in-linux-and-unix-27id\n",
    "\n",
    "```\n",
    "[root@localhost ~]# yum -y install nfs-utils\n",
    "[root@localhost ~]# vi /etc/exports\n",
    "[root@localhost ~]# cat /etc/exports\n",
    "/nfs_exports   *(rw,root_squash,sync,no_subtree_check)\n",
    "[root@localhost ~]# mkdir /nfs_exports\n",
    "[root@localhost ~]# chmod 777 /nfs_exports\n",
    "[root@localhost ~]# systemctl enable rpcbind\n",
    "[root@localhost ~]# systemctl enable nfs-server\n",
    "[root@localhost ~]# systemctl enable nfs-lock\n",
    "[root@localhost ~]# systemctl enable nfs-idmap\n",
    "[root@localhost ~]# systemctl start rpcbind\n",
    "[root@localhost ~]# systemctl start nfs-server\n",
    "[root@localhost ~]# systemctl start nfs-lock\n",
    "[root@localhost ~]# systemctl start nfs-idmap\n",
    "[root@localhost ~]# systemctl status nfs\n",
    "● nfs-server.service - NFS server and services\n",
    "   Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; disabled; vendor preset: disabled)\n",
    "   Active: active (exited) since Mon 2023-05-01 18:12:08 EDT; 2s ago\n",
    "  Process: 27255 ExecStartPost=/bin/sh -c if systemctl -q is-active gssproxy; then systemctl reload gssproxy ; fi (code=exited, status=0/SUCCESS)\n",
    "  Process: 27253 ExecStart=/usr/sbin/rpc.nfsd $RPCNFSDARGS (code=exited, status=0/SUCCESS)\n",
    "  Process: 27250 ExecStartPre=/usr/sbin/exportfs -r (code=exited, status=0/SUCCESS)\n",
    " Main PID: 27253 (code=exited, status=0/SUCCESS)\n",
    "    Tasks: 0\n",
    "   Memory: 0B\n",
    "   CGroup: /system.slice/nfs-server.service\n",
    "   \n",
    "[root@localhost ~]# exportfs\n",
    "/nfs_exports    <world>\n",
    "```\n",
    "\n",
    "**Note**: Make sure your firewall is properly configured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a5d58-fb3a-4df1-9beb-5a136ddac160",
   "metadata": {},
   "source": [
    "#### Install NFS Client on K8 Nodes\n",
    "This need to be installed on the mater and the workers\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# yum -y install nfs-utils\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec95e2f-2e3b-4ef0-ac4a-dddc487b53ed",
   "metadata": {},
   "source": [
    "#### Test NFS Connection\n",
    "Test we can mount the nfs server and have the permissions to create files and directories\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# mount -t nfs 15.4.22.101:/nfs_exports /mnt/test\n",
    "[root@os004k8-master001 ~]# mkdir /mnt/test/test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff5f37-dc2a-46e5-90a7-c333b10a7695",
   "metadata": {},
   "source": [
    "#### Installing NFS Subdir External Provisioner Using Helm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f596b52-1bdc-484c-bdba-e87ad7054da2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Official instructions can be found [here](https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)\n",
    "```\n",
    "[root@os004k8-master001 ~]# helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/\n",
    "WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config\n",
    "WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config\n",
    "\"nfs-subdir-external-provisioner\" has been added to your repositories\n",
    "\n",
    "[root@os004k8-master001 ~]# helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner  --set nfs.server=15.4.22.101 --set nfs.path=/nfs_exports\n",
    "WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config\n",
    "WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config\n",
    "NAME: nfs-subdir-external-provisioner\n",
    "LAST DEPLOYED: Mon May  1 18:24:08 2023\n",
    "NAMESPACE: default\n",
    "STATUS: deployed\n",
    "REVISION: 1\n",
    "TEST SUITE: None\n",
    "\n",
    "[root@os004k8-master001 ~]# kubectl get deployment nfs-subdir-external-provisioner\n",
    "NAME                              READY   UP-TO-DATE   AVAILABLE   AGE\n",
    "nfs-subdir-external-provisioner   1/1     1            1           102s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d62891-d66b-4290-8ca5-11de6406ed97",
   "metadata": {},
   "source": [
    "<a id=\"define-storage-class\"></a>\n",
    "#### Define Storage Class\n",
    "\n",
    "When we deployed the helm chart in the previous step, a storage class was created for us:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get storageclass\n",
    "NAME         PROVISIONER                                     RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
    "nfs-client   cluster.local/nfs-subdir-external-provisioner   Delete          Immediate           true                   6m31s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113fdbc-f739-4a03-b217-cdab147ba8bc",
   "metadata": {},
   "source": [
    "#### Test the installation\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# cat test-claim.yaml\n",
    "kind: PersistentVolumeClaim\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: test-claim\n",
    "spec:\n",
    "  storageClassName: nfs-client\n",
    "  accessModes:\n",
    "    - ReadWriteMany\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 1Mi\n",
    "      \n",
    "[root@os004k8-master001 pachyderm]# kubectl apply -f test-claim.yaml\n",
    "persistentvolumeclaim/test-claim created\n",
    "[root@os004k8-master001 pachyderm]# kubectl get persistentvolumeclaim/test-claim\n",
    "NAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
    "test-claim   Bound    pvc-c83b7c08-3ff0-4a3d-948e-16436326f31f   1Mi        RWX            nfs-client     10s\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# cat test-pod.yaml\n",
    "kind: Pod\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: test-pod\n",
    "spec:\n",
    "  containers:\n",
    "  - name: test-pod\n",
    "    image: busybox:stable\n",
    "    command:\n",
    "      - \"/bin/sh\"\n",
    "    args:\n",
    "      - \"-c\"\n",
    "      - \"touch /mnt/SUCCESS && exit 0 || exit 1\"\n",
    "    volumeMounts:\n",
    "      - name: nfs-pvc\n",
    "        mountPath: \"/mnt\"\n",
    "  restartPolicy: \"Never\"\n",
    "  volumes:\n",
    "    - name: nfs-pvc\n",
    "      persistentVolumeClaim:\n",
    "        claimName: test-claim\n",
    "\n",
    "[root@os004k8-master001 pachyderm]# kubectl apply -f test-pod.yaml\n",
    "pod/test-pod created\n",
    "\n",
    "[root@os004k8-master001 pachyderm]# kubectl get pod/test-pod\n",
    "NAME       READY   STATUS      RESTARTS   AGE\n",
    "test-pod   0/1     Completed   0          7s\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl delete -f test-pod.yaml\n",
    "pod \"test-pod\" deleted\n",
    "[root@os004k8-master001 pachyderm]# kubectl delete -f test-claim.yaml\n",
    "persistentvolumeclaim \"test-claim\" deleted\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303d1ea-343c-48bd-940c-d5b9a2d11ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb51b0-2de5-43db-8214-455df9246047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cfe5d03-302e-41fa-ba77-b9f4c348b31e",
   "metadata": {},
   "source": [
    "## Deploy Minio Object Store\n",
    "\n",
    "From what I understand, Minio is needed in addition to the Persistent Volumes being made available in the previous step.\n",
    "\n",
    "> An object store is used by Pachyderm’s pachd for storing all your data. The object store you use must be accessible via a low-latency, high-bandwidth connection.\n",
    ">\n",
    "> Storage providers like MinIO (the most common and officially supported option), EMC’s ECS, Ceph, or SwiftStack provide S3-compatible access to enterprise storage for on-premises deployment.\n",
    "> \n",
    "> https://docs.pachyderm.com/latest/deploy-manage/deploy/on-premises/#on-premises-sizing-and-configuring-the-object-store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec90ba1-f38d-4cc9-831c-a6a154ee58a7",
   "metadata": {},
   "source": [
    "I googled around for examples on how to deploy minio on kubernetes. I found a guide [here](https://min.io/docs/minio/kubernetes/upstream/index.html) which got me most of the way home. I needed to make a few tweaks which I will describe below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e86bba-b01d-48c4-81e0-c8ac8e6ea7ca",
   "metadata": {},
   "source": [
    "### Deploy minio pod\n",
    "The first thing we need to do is deploy a pod which runs minio. Most of the work here was done for me. The [article mentioned previously](https://min.io/docs/minio/kubernetes/upstream/index.html) hosted a yaml file with the pod manifest. \n",
    "\n",
    "I needed to tweak this file to expose ports on the container so that external services could connect. I also needed to specify which node to run the service on so it would have direct disk access.\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# cat minio-dev.yaml\n",
    "# Deploys a new MinIO Pod into the metadata.namespace Kubernetes namespace\n",
    "#\n",
    "# The `spec.containers[0].args` contains the command run on the pod\n",
    "# The `/data` directory corresponds to the `spec.containers[0].volumeMounts[0].mountPath`\n",
    "# That mount path corresponds to a Kubernetes HostPath which binds `/data` to a local drive or volume on the worker node where the pod runs\n",
    "#\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  labels:\n",
    "    app: minio\n",
    "  name: minio\n",
    "spec:\n",
    "  containers:\n",
    "  - name: minio\n",
    "    image: quay.io/minio/minio:latest\n",
    "    command:\n",
    "    - /bin/bash\n",
    "    - -c\n",
    "    args:\n",
    "    - minio server /data --console-address :9090 --address :9000\n",
    "    volumeMounts:\n",
    "    - mountPath: /data\n",
    "      name: localvolume # Corresponds to the `spec.volumes` Persistent Volume\n",
    "    ports:\n",
    "    - name: minio-console\n",
    "      containerPort: 9090\n",
    "    - name: minio\n",
    "      containerPort: 9000\n",
    "  nodeSelector:\n",
    "    kubernetes.io/hostname: os004k8-worker001.foobar.com\n",
    "  volumes:\n",
    "  - name: localvolume\n",
    "    hostPath: # MinIO generally recommends using locally-attached volumes\n",
    "      path: /mnt/disk1/data # Specify a path to a local drive or volume on the Kubernetes worker node\n",
    "      type: DirectoryOrCreate # The path to the last directory must exist\n",
    "```\n",
    "\n",
    "Notice the port 9000 and 9090 that are exposed. We will be connecting to the web ui through 9090.\n",
    "\n",
    "We check that the pod is deployed successfully:\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl apply -f minio-dev.yaml\n",
    "pod/minio configured\n",
    "[root@os004k8-master001 pachyderm]# kubectl get pod/minio\n",
    "NAME    READY   STATUS    RESTARTS   AGE\n",
    "minio   1/1     Running   0          10h\n",
    "```\n",
    "\n",
    "We then do a sanity check to confirm the service is online and running\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl exec -ti minio -- netstat -tulpn\n",
    "Active Internet connections (only servers)\n",
    "Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\n",
    "tcp        0      0 127.0.0.1:9000          0.0.0.0:*               LISTEN      1/minio\n",
    "tcp6       0      0 :::9090                 :::*                    LISTEN      1/minio\n",
    "tcp6       0      0 :::9000                 :::*                    LISTEN      1/minio\n",
    "[root@os004k8-master001 pachyderm]# kubectl exec -ti minio -- curl 127.0.0.1:9090\n",
    "<!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"/><base href=\"/\"/><meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/><meta content=\"#081C42\" media=\"(prefers-color-scheme: light)\" name=\"theme-color\"/><meta content=\"#081C42\" media=\"(prefers-color-scheme: dark)\" name=\"theme-color\"/><meta content=\"MinIO Console\" name=\"description\"/><meta name=\"minio-license\" content=\"agpl\" /><link href=\"./styles/root-styles.css\" rel=\"stylesheet\"/><link href=\"./apple-icon-180x180.png\" rel=\"apple-touch-icon\" sizes=\"180x180\"/><link href=\"./favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/><link href=\"./favicon-96x96.png\" rel=\"icon\" sizes=\"96x96\" type=\"image/png\"/><link href=\"./favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/><link href=\"./manifest.json\" rel=\"manifest\"/><link color=\"#3a4e54\" href=\"./safari-pinned-tab.svg\" rel=\"mask-icon\"/><title>MinIO Console</title><script defer=\"defer\" src=\"./static/js/main.ebbcb389.js\"></script><link href=\"./static/css/main.57e739f5.css\" rel=\"stylesheet\"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"><div id=\"preload\"><img src=\"./images/background.svg\"/> <img src=\"./images/background-wave-orig2.svg\"/></div><div id=\"loader-block\"><img src=\"./Loader.svg\"/></div></div></body></html>\n",
    "```\n",
    "\n",
    "We can then confirm the pod networking is setup correctly and the service is exposed properly on the cluster's internal subnet.\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl describe pod/minio | grep -E \"^IP:\"\n",
    "IP:           10.36.0.1\n",
    "[root@os004k8-master001 pachyderm]# curl 10.36.0.1:9090\n",
    "<!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"/><base href=\"/\"/><meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/><meta content=\"#081C42\" media=\"(prefers-color-scheme: light)\" name=\"theme-color\"/><meta content=\"#081C42\" media=\"(prefers-color-scheme: dark)\" name=\"theme-color\"/><meta content=\"MinIO Console\" name=\"description\"/><meta name=\"minio-license\" content=\"agpl\" /><link href=\"./styles/root-styles.css\" rel=\"stylesheet\"/><link href=\"./apple-icon-180x180.png\" rel=\"apple-touch-icon\" sizes=\"180x180\"/><link href=\"./favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/><link href=\"./favicon-96x96.png\" rel=\"icon\" sizes=\"96x96\" type=\"image/png\"/><link href=\"./favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/><link href=\"./manifest.json\" rel=\"manifest\"/><link color=\"#3a4e54\" href=\"./safari-pinned-tab.svg\" rel=\"mask-icon\"/><title>MinIO Console</title><script defer=\"defer\" src=\"./static/js/main.ebbcb389.js\"></script><link href=\"./static/css/main.57e739f5.css\" rel=\"stylesheet\"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"><div id=\"preload\"><img src=\"./images/background.svg\"/> <img src=\"./images/background-wave-orig2.svg\"/></div><div id=\"loader-block\"><img src=\"./Loader.svg\"/></div></div></body></html>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3857de36-d4a1-4b42-8e8c-8d414d82ea44",
   "metadata": {},
   "source": [
    "### Setup a NodePort Service\n",
    "We want minio to be accessible from outside the cluster. To do this we will need to add some additional kubernetes configurations. There are many ways to skin this cat, I am choosing the simplest approach. I will map a port on the kubernetes node to a port on the kubernetes pod. This will allos me to access the service inside the container that is mapped to the pod's external port. I got some help from this [article](https://stackoverflow.com/questions/71909726/how-to-expose-minio-outside-cluster-ip).\n",
    "\n",
    "First I setup the yaml:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# cat minio-node-port.yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: minio-nodeport\n",
    "spec:\n",
    "  ports:\n",
    "  - name: minio-console\n",
    "    port: 9090\n",
    "    targetPort: 9090\n",
    "    nodePort: 30090\n",
    "  - name: minio\n",
    "    port: 9000\n",
    "    targetPort: 9000\n",
    "    nodePort: 30000\n",
    "  selector:\n",
    "    app: minio\n",
    "  type: NodePort\n",
    "```\n",
    "\n",
    "This file is assigning port 30090 on the kubernetes node to port 9090 on the container.\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl apply -f minio-node-port.yaml\n",
    "service/minio-nodeport created\n",
    "\n",
    "[root@os004k8-master001 pachyderm]# kubectl get service/minio-nodeport\n",
    "NAME             TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)                         AGE\n",
    "minio-nodeport   NodePort   10.106.5.77   <none>        9090:30090/TCP,9000:30000/TCP   10h\n",
    "\n",
    "[root@os004k8-master001 pachyderm]# kubectl describe service/minio-nodeport\n",
    "Name:                     minio-nodeport\n",
    "Namespace:                default\n",
    "Labels:                   <none>\n",
    "Annotations:              <none>\n",
    "Selector:                 app=minio\n",
    "Type:                     NodePort\n",
    "IP Family Policy:         SingleStack\n",
    "IP Families:              IPv4\n",
    "IP:                       10.106.5.77\n",
    "IPs:                      10.106.5.77\n",
    "Port:                     minio-console  9090/TCP\n",
    "TargetPort:               9090/TCP\n",
    "NodePort:                 minio-console  30090/TCP\n",
    "Endpoints:                10.36.0.1:9090\n",
    "Port:                     minio  9000/TCP\n",
    "TargetPort:               9000/TCP\n",
    "NodePort:                 minio  30000/TCP\n",
    "Endpoints:                10.36.0.1:9000\n",
    "Session Affinity:         None\n",
    "External Traffic Policy:  Cluster\n",
    "Events:                   <none>\n",
    "```\n",
    "\n",
    "We can do a sanity check and see if we can now access the service:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl describe pod/minio | grep \"Node:\"\n",
    "Node:         os004k8-worker001.foobar.com/15.4.7.101\n",
    "[root@os004k8-master001 pachyderm]# curl 15.4.7.101:30090\n",
    "<!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"/><base href=\"/\"/><meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/><meta content=\"#081C42\" media=\"(prefers-color-scheme: light)\" name=\"theme-color\"/><meta content=\"#081C42\" media=\"(prefers-color-scheme: dark)\" name=\"theme-color\"/><meta content=\"MinIO Console\" name=\"description\"/><meta name=\"minio-license\" content=\"agpl\" /><link href=\"./styles/root-styles.css\" rel=\"stylesheet\"/><link href=\"./apple-icon-180x180.png\" rel=\"apple-touch-icon\" sizes=\"180x180\"/><link href=\"./favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/><link href=\"./favicon-96x96.png\" rel=\"icon\" sizes=\"96x96\" type=\"image/png\"/><link href=\"./favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/><link href=\"./manifest.json\" rel=\"manifest\"/><link color=\"#3a4e54\" href=\"./safari-pinned-tab.svg\" rel=\"mask-icon\"/><title>MinIO Console</title><script defer=\"defer\" src=\"./static/js/main.ebbcb389.js\"></script><link href=\"./static/css/main.57e739f5.css\" rel=\"stylesheet\"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"><div id=\"preload\"><img src=\"./images/background.svg\"/> <img src=\"./images/background-wave-orig2.svg\"/></div><div id=\"loader-block\"><img src=\"./Loader.svg\"/></div></div></body></html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955fb1f3-f36d-4a88-afa8-f7c4a685bf85",
   "metadata": {},
   "source": [
    "### Login Through Web Browser\n",
    "\n",
    "Last we can navigate to a web browser on our LAN and confirm we can access the service. According to the [documentation](https://min.io/docs/minio/linux/index.html) the default credentials are:\n",
    "\n",
    "```\n",
    "API: http://192.0.2.10:9000  http://127.0.0.1:9000\n",
    "RootUser: minioadmin\n",
    "RootPass: minioadmin\n",
    "\n",
    "Console: http://192.0.2.10:9090 http://127.0.0.1:9090\n",
    "RootUser: minioadmin\n",
    "RootPass: minioadmin\n",
    "```\n",
    "\n",
    "When logging in we see the following:\n",
    "\n",
    "<center><img src=\"images/minio-login-page.png\"></center>\n",
    "<center><img src=\"images/minio-login-page-2.png\"></center>\n",
    "<center><img src=\"images/minio-login-page-3.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ec7b0-ef87-45c5-927f-9ea32212cb5d",
   "metadata": {},
   "source": [
    "### Generate Access Key And Secret Key\n",
    "According to the [documentation](https://min.io/docs/minio/linux/administration/identity-access-management/minio-user-management.html):\n",
    "\n",
    "> A MinIO user consists of a unique access key (username) and corresponding secret key (password). Clients must authenticate their identity by specifying both a valid access key (username) and the corresponding secret key (password) of an existing MinIO user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0072c0-8c7d-40e6-b616-bad23edb3131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce520c-1ec1-426a-afdd-b75133a6df98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767b79b-7c64-4e4a-bc34-cdd8048121bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668fffd9-6129-4d99-a217-6cde425bfd85",
   "metadata": {},
   "source": [
    "## Create Values File For Helm\n",
    "\n",
    "The helm chart, which deploys the pachyderm solution, requires that values be set to inform the installation. In fact, if the values are not set, helm will raise an exveption suring the installation. The default values file can be found [here](https://github.com/pachyderm/pachyderm/blob/2.3.x/etc/helm/pachyderm/values.yaml).\n",
    "\n",
    "Through a bit of trial and error with the help of helm, who will complain if necessary values are missing, I was able to piece together the configurations required to deploy a working solution. The documentation is a bit messy and some of the links are broken. On some pages the documentation fails to mention what specific configurations must be made (eg. we must configure the loki-stack components). \n",
    "\n",
    "At the end of the day, my config file was as follows:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# cat values.yaml\n",
    "etcd:\n",
    "  storageClass: nfs-client\n",
    "  size: 10Gi\n",
    "\n",
    "postgresql:\n",
    "  persistence:\n",
    "    storageClass: nfs-client\n",
    "    size: 10Gi\n",
    "\n",
    "loki-stack:\n",
    "  loki:\n",
    "    persistence:\n",
    "      size: 10Gi\n",
    "      storageClassName: nfs-client\n",
    "\n",
    "deployTarget: MINIO\n",
    "\n",
    "pachd:\n",
    "  storage:\n",
    "    backend: MINIO\n",
    "    minio:\n",
    "      bucket: pachyderm\n",
    "      endpoint: 15.4.7.101:30000\n",
    "      id: minioadmin\n",
    "      secret: minioadmin\n",
    "      secure: \"false\"\n",
    "\n",
    "proxy:\n",
    "  enabled: true\n",
    "  service:\n",
    "    type: LoadBalancer\n",
    "```\n",
    "\n",
    "In the next sections I explain the configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66605f5-810f-4c9e-96cc-14e91e360197",
   "metadata": {},
   "source": [
    "<a id=\"persistent-volume-claims\"></a>\n",
    "### Storage Class For Persistent Volume Claims \n",
    "\n",
    "The pachyderm helm chart will deploy three services which require Persistant Volumes. This requirement will be specified through a Persistent Volume Claim. There are three services which require a Persistant Volume: etcd, postgresql, and loki-stack. Below are the configurations to inform them which Storage Class we should be using. We defined our Storage Class \"nfs-client\" in this [step](#define-storage-class). Our coresponding entry in the values file was as follows:\n",
    "\n",
    "```\n",
    "etcd:\n",
    "  storageClass: nfs-client\n",
    "  size: 10Gi\n",
    "\n",
    "postgresql:\n",
    "  persistence:\n",
    "    storageClass: nfs-client\n",
    "    size: 10Gi\n",
    "\n",
    "loki-stack:\n",
    "  loki:\n",
    "    persistence:\n",
    "      size: 10Gi\n",
    "      storageClassName: nfs-client\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fdc5f9-e074-47ab-8e5e-761133914538",
   "metadata": {},
   "source": [
    "### Configure Minio Backend\n",
    "\n",
    "We also need to inform the pachd server that we are using a minio backend and provide it the coresponding configurations so that the connection works. The [documentation](https://docs.pachyderm.com/latest/deploy-manage/deploy/on-premises/#on-premises-deploying-an-object-store) provides some guidance, but ultimately it is incomplete and incorrect. \n",
    "\n",
    "The documenation provides the following descriptions of the configurations:\n",
    "\n",
    "> **endpoint**: The access endpoint. For example, MinIO’s endpoints are usually something like minio-server:9000.\n",
    ">\n",
    "> > Do not begin it with the protocol; it is an endpoint, not an url. Also, check if your object store (e.g. MinIO) is using SSL/TLS. If not, disable it using secure: false.\n",
    ">\n",
    ">**bucket**: The bucket name you are dedicating to Pachyderm. Pachyderm will need exclusive access to this bucket.\n",
    ">\n",
    ">**id**: The access key id for the object store.\n",
    ">\n",
    ">**secret**: The secret key for the object store.\n",
    "\n",
    "In total, the configurations for this case were as follows:\n",
    "\n",
    "```\n",
    "deployTarget: MINIO\n",
    "\n",
    "pachd:\n",
    "  storage:\n",
    "    backend: MINIO\n",
    "    minio:\n",
    "      bucket: pachyderm\n",
    "      endpoint: 15.4.7.101:30000\n",
    "      id: minioadmin\n",
    "      secret: minioadmin\n",
    "      secure: \"false\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878bd66-72fa-452b-a239-eba0c60c251a",
   "metadata": {},
   "source": [
    "#### Gotchas\n",
    "\n",
    "**Note**: There were a couple quarks with this configuration which I describe below:\n",
    "\n",
    "Tbe `deployTarget` specifies where pachyderm is being installed. Per the [documentation](https://docs.pachyderm.com/latest/reference/helm-values/deploy-target/#deploy-target-hcvs-values) the following values are supported: GOOGLE, AMAZON, MINIO, MICROSOFT, CUSTOM or LOCAL. Reading between the lines, the choice determines what downstream configurations are required and what assets are deployed to kubernetes.\n",
    "\n",
    "The `secure` setting must be a string. If it's a boolean, helm will complain during the installation.\n",
    "\n",
    "The `backend` must be in all caps despite documentation showing lower case. If we do set it to lower case, we sill see the following errot in the pachd pod logs:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl logs pachd-55467db54f-dwddb | tail -n 5\n",
    "...\n",
    "{\"severity\":\"info\",\"time\":\"2023-05-02T17:16:17.869971271Z\",\"caller\":\"grpcutil/server.go:69\",\"message\":\"TLS disabled\",\"error\":\"could not stat public cert at /pachd-tls-cert/tls.crt: stat /pachd-tls-cert/tls.crt: no such file or directory\",\"errorVerbose\":\"stat /pachd-tls-cert/tls.crt: no such file or directory\\ncould not stat public cert at /pachd-tls-cert/tls.crt\\ngithub.com/pachyderm/pachyderm/v2/src/internal/tls.GetCertPaths\\n\\tsrc/internal/tls/tls.go:32\\ngithub.com/pachyderm/pachyderm/v2/src/internal/grpcutil.NewServer\\n\\tsrc/internal/grpcutil/server.go:67\\ngithub.com/pachyderm/pachyderm/v2/src/internal/pachd.(*builder).initExternalServer\\n\\tsrc/internal/pachd/builder.go:195\\ngithub.com/pachyderm/pachyderm/v2/src/internal/pachd.(*builder).apply\\n\\tsrc/internal/pachd/builder.go:88\\ngithub.com/pachyderm/pachyderm/v2/src/internal/pachd.(*fullBuilder).buildAndRun\\n\\tsrc/internal/pachd/full.go:66\\ngithub.com/pachyderm/pachyderm/v2/src/internal/pachd.FullMode\\n\\tsrc/internal/pachd/full.go:107\\ngithub.com/pachyderm/pachyderm/v2/src/internal/cmdutil.Main\\n\\tsrc/internal/cmdutil/env.go:34\\nmain.main\\n\\tsrc/server/cmd/pachd/main.go:50\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:250\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1594\"}\n",
    "unrecognized storage backend: minio\n",
    "```\n",
    "\n",
    "The `bucket` must exist BEOFRE we go through the installation. The pachyderm pod will to a [quality check](https://github.com/pachyderm/pachyderm/blob/39a975208f55e657b64cf8de11c7375270becc3d/src/internal/obj/testsuite.go#L122) when starting up for the first time; it will create a test object in the backend and then confirm the object is there. If the bucket does not exist, this test will fail and we will see an error that resembles the following:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl describe pod pachd-9c6b4c75b-ddlv6\n",
    "...\n",
    "  Warning  FailedMount  4m34s                  kubelet            MountVolume.SetUp failed for volume \"pachyderm-storage-secret\" : failed to sync secret cache: timed out waiting for the condition\n",
    "...\n",
    "\n",
    "[root@os004k8-master001 pachyderm]# kubectl logs pachd-9c6b4c75b-ddlv6\n",
    "...\n",
    "unable to write to object storage: pachyderm does not contain item: (test/6ac321e4a09147e3917104f7b3d4ae38)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424c3f8-fb23-474f-ae60-3747cd5a1c1d",
   "metadata": {},
   "source": [
    "<a id=\"configure-proxy\"><a/>\n",
    "### Configure Proxy\n",
    "\n",
    "Currently Pachyderm supports the use of an optional proxy. While the deployment of the proxy is optional at the moment, it will become permanent in the next minor release of Pachyderm.\n",
    "\n",
    "In my case the configuration was as follows:\n",
    "\n",
    "```\n",
    "proxy:\n",
    "  enabled: true\n",
    "  service:\n",
    "    type: LoadBalancer\n",
    "```\n",
    "\n",
    "The purpose of the proxy is to provide a single point of contact for all user facing traffic. Like any proxy, the pachyderm proxy accepts requests from and each call to the appropriate backend microservice without any additional configuration.\n",
    "\n",
    "It's not explicitly stated, but I belived the service specification maps to kubernetes service types. To confirm this I have seen mention of setting the type to be either LoadBalancer or NodePort, but I imagine Ingress and other services may also be possible. A good article on the differencescan be found [here](https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0).\n",
    "\n",
    "The pachyderm proxy exposes one TCP port for all incoming traffic:\n",
    "- grpc (grpcs)\n",
    "- console (HTTP/HTTPS)\n",
    "- s3 gateway, OIDC\n",
    "- dex traffic\n",
    "\n",
    "The following diagram outlines the kubernetes footprint and usage of the proxy:\n",
    "\n",
    "<center><img src=\"images/pachyderm-proxy.png\"></center>\n",
    "\n",
    "More information and configuration examples can be found [here](https://docs.pachyderm.com/2.3.x/deploy-manage/deploy/deploy-w-proxy/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769836c5-de13-4973-ad63-d9f29ccbd642",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71aad4-fba3-4d31-a209-4fc555bc3963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4b8ec-3983-4be0-a5ee-30d9008129e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed87b1-46cf-43a1-a706-8239b35047ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "771b6bca-c889-4043-9427-1a21313eecfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install Pachyderm using helm\n",
    "\n",
    "Pachyderm uses the client server model. The pachD damon is packaged as a kubernetes pod and the pachctl cli connects to the server (the daemon running in the pod) to execute commands etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a38a1-3154-4eb4-8211-cad203e5e977",
   "metadata": {},
   "source": [
    "### Run installation Using Helm Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a7a6d-8c8e-44af-9c83-79e61af0fc6b",
   "metadata": {},
   "source": [
    "We can ask helm to list all the charts it can find. In my case I only have one repo (the pachyderm repo) and we can list out all the charts available for a given repo:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# helm repo list\n",
    "NAME            URL\n",
    "pachyderm       https://helm.pachyderm.com\n",
    "\n",
    "[root@os004k8-master001 ~]# helm search repo -l -r pachyderm 2>/dev/null\n",
    "NAME                    CHART VERSION   APP VERSION     DESCRIPTION\n",
    "pachyderm/pachyderm     2.5.5           2.5.5           Explainable, repeatable, scalable data science\n",
    "pachyderm/pachyderm     2.5.4           2.5.4           Explainable, repeatable, scalable data science\n",
    "pachyderm/pachyderm     2.5.3           2.5.3           Explainable, repeatable, scalable data science\n",
    "pachyderm/pachyderm     2.5.2           2.5.2           Explainable, repeatable, scalable data science\n",
    "pachyderm/pachyderm     2.5.1           2.5.1           Explainable, repeatable, scalable data science\n",
    "pachyderm/pachyderm     2.5.0           2.5.0           Explainable, repeatable, scalable data science\n",
    "pachyderm/pachyderm     2.4.6           2.4.6           Explainable, repeatable, scalable data science\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd57d3-71b1-4661-877d-fe1b39d486b8",
   "metadata": {},
   "source": [
    "We can then instruct helm to install the desired version of pachyderm and to apply the value settings from the values file we created previously:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# helm install pachd -f values.yaml pachyderm/pachyderm --version 2.5.5\n",
    "WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config\n",
    "WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /root/.kube/config\n",
    "W0502 14:47:18.489877   22677 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
    "W0502 14:47:18.733281   22677 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
    "NAME: pachd\n",
    "LAST DEPLOYED: Tue May  2 14:47:17 2023\n",
    "NAMESPACE: default\n",
    "STATUS: deployed\n",
    "REVISION: 1\n",
    "NOTES:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503db86b-21ae-4a54-960e-2337018707d2",
   "metadata": {},
   "source": [
    "### Sanity Check: All Pods Are Running\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get pods\n",
    "NAME                                               READY   STATUS    RESTARTS   AGE\n",
    "console-5d4686d94-45d8j                            1/1     Running   0          6h14m\n",
    "etcd-0                                             1/1     Running   0          6h14m\n",
    "minio                                              1/1     Running   0          10h\n",
    "nfs-subdir-external-provisioner-7f9cf64cd8-7pv5g   1/1     Running   0          26h\n",
    "pachd-5586c8845d-6dfgk                             1/1     Running   0          6h14m\n",
    "pachd-loki-0                                       1/1     Running   0          6h14m\n",
    "pachd-promtail-6cf4t                               1/1     Running   0          6h14m\n",
    "pachd-promtail-6mp89                               0/1     Running   0          6h14m\n",
    "pachd-promtail-9plcr                               0/1     Running   0          6h14m\n",
    "pachd-promtail-cnf22                               1/1     Running   0          6h14m\n",
    "pachd-promtail-xplb5                               1/1     Running   0          6h14m\n",
    "pachd-promtail-xsdxx                               1/1     Running   0          6h14m\n",
    "pachyderm-kube-event-tail-6c6598cd5-9jxfm          1/1     Running   0          6h14m\n",
    "pachyderm-proxy-7f4545985c-t4zjq                   1/1     Running   0          6h14m\n",
    "pg-bouncer-88dbc966b-ldbwh                         1/1     Running   0          6h14m\n",
    "postgres-0                                         1/1     Running   0          6h14m\n",
    "```\n",
    "\n",
    "**Note**: This will take some time before all the pods are running. Remember, the kubernetes cluster is going to download a bunch of docker images from dockerhub. This may take some time. It then neets to start the pods (containers) and wait for their internal services to come online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b49d2-be10-4355-a3fe-3d94570ab1a7",
   "metadata": {},
   "source": [
    "### Sanity Check: Proxy Is Internally Accessible\n",
    "Here we want to check that the proxy is internally available:\n",
    "\n",
    "We can get a list of services associated with pachyderm\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get services | grep pach\n",
    "pachd                   ClusterIP      10.98.169.23     <none>        30650/TCP,30657/TCP,30658/TCP,30600/TCP,30656/TCP   6h41m\n",
    "pachd-loki              ClusterIP      10.100.200.46    <none>        3100/TCP                                            6h41m\n",
    "pachd-loki-headless     ClusterIP      None             <none>        3100/TCP                                            6h41m\n",
    "pachd-loki-memberlist   ClusterIP      None             <none>        7946/TCP                                            6h41m\n",
    "pachd-peer              ClusterIP      10.107.149.154   <none>        30653/TCP                                           6h41m\n",
    "pachd-proxy-backend     ClusterIP      None             <none>        1650/TCP,1657/TCP,1658/TCP,1600/TCP,1656/TCP        6h41m\n",
    "pachyderm-proxy         LoadBalancer   10.100.12.105    <pending>     80:30409/TCP                                        6h41m\n",
    "```\n",
    "We can then drill down into the specific LoadBalancer which we see is named \"pachydrm-proxy\"\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get service pachyderm-proxy\n",
    "NAME              TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n",
    "pachyderm-proxy   LoadBalancer   10.100.12.105   <pending>     80:30409/TCP   6h41m\n",
    "```\n",
    "\n",
    "Finally we can curl the internal cluster ip and port to see if we get an html response indicating the UI is up\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# curl 10.100.12.105:80\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
    "    <meta name=\"description\" content=\"Visualize your Pachyderm workspace\" />\n",
    "    <link rel=\"shortcut icon\" href=\"/favicon.ico\">\n",
    "    <title>Pachyderm Console</title>\n",
    "    <script type=\"module\" crossorigin src=\"/assets/index.822e4a40.js\"></script>\n",
    "    <link rel=\"stylesheet\" href=\"/assets/index.572e5d88.css\">\n",
    "  </head>\n",
    "  <body>\n",
    "\n",
    "      <script>\n",
    "        window.pachDashConfig = {\"REACT_APP_RUNTIME_DISABLE_TELEMETRY\":\"false\",\"REACT_APP_RUNTIME_ISSUER_URI\":\"http://localhost:30658\",\"NODE_ENV\":\"production\",\"REACT_APP_BACKEND_GRAPHQL_PREFIX\":\"/graphql\",\"REACT_APP_BACKEND_PREFIX\":\"/\",\"REACT_APP_BUILD_ENV\":\"production\",\"REACT_APP_RELEASE_VERSION\":\"unversioned-production\",\"REACT_APP_SENTRY_DSN\":\"https://5208a9e666bf4d85aa9f8281a7fdaf9a@o309125.ingest.sentry.io/6771948\",\"REACT_APP_RUDDERSTACK_ID\":\"2FBfmxTHtnOO4VphcX0PsKWVUiU\",\"REACT_APP_POLLING\":\"10000\"}\n",
    "      </script>\n",
    "\n",
    "\n",
    "    <noscript>You need to enable JavaScript to run this app.</noscript>\n",
    "    <div id=\"root\"></div>\n",
    "\n",
    "  </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "We got hrml. It looks like the service is up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853325dc-89ec-4651-9e4d-3cd3d48f9c6d",
   "metadata": {},
   "source": [
    "### Sanity Check: Proxy Is Allocated An External IP\n",
    "\n",
    "We should see that the LoadBalancer is allocated an external IP. This is the IP that the users should use to access the service.\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get service pachyderm-proxy\n",
    "NAME              TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n",
    "pachyderm-proxy   LoadBalancer   10.100.227.99   15.4.25.1     80:30855/TCP   43s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0def390-595f-4842-893e-54f4d8480039",
   "metadata": {},
   "source": [
    "### Sanity Check: Web UI Is Working And Accessible\n",
    "At this point, the helm chart has stood up a bunch of pods (which we confirmed are running) and a proxy service. \n",
    "\n",
    "In some cases we may want to bypass the proxy and do some sanity checking and trouble shooting. For example, in a situation when the proxy is only accessible from within the cluster's overlay network and it is not accessible to nodes outside the cluster. In this case we can do some linux magic to tell the operating system on my kubernetes master to map one of it's public facing ports to the cluster ip and port provided by the pachyderm proxy. In short, I am creating an externally available proxy to reach my internally available proxy.\n",
    "\n",
    "To do this hackery I can use socat. Below we see the command which maps port 8080 on the kubernetes master to 10.47.0.1:8080 (the ip and port of the proxy). This is a blocking command; as long as it's running the proxy is up\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# socat TCP-LISTEN:8080,fork TCP:10.47.0.1:8080\n",
    "```\n",
    "\n",
    "From another machine on the same LAN segment, we can open a web browser and navigate to the master node's ip and port.\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# route -nv\n",
    "Kernel IP routing table\n",
    "Destination     Gateway         Genmask         Flags Metric Ref    Use Iface\n",
    "0.0.0.0         15.1.1.1        0.0.0.0         UG    100    0        0 eth0\n",
    "10.32.0.0       0.0.0.0         255.240.0.0     U     0      0        0 weave\n",
    "15.0.0.0        0.0.0.0         255.0.0.0       U     100    0        0 eth0\n",
    "172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0\n",
    "[root@os004k8-master001 pachyderm]# ip addr show eth0\n",
    "2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n",
    "    link/ether 8e:cb:b0:2a:b5:1e brd ff:ff:ff:ff:ff:ff\n",
    "    inet 15.4.7.11/8 brd 15.255.255.255 scope global noprefixroute eth0\n",
    "       valid_lft forever preferred_lft forever\n",
    "    inet6 fe80::8ccb:b0ff:fe2a:b51e/64 scope link\n",
    "       valid_lft forever preferred_lft forever\n",
    "```\n",
    "\n",
    "In my case we can see this url would be 15.4.7.11:8080. When we open this url in our web browser we see:\n",
    "\n",
    "<center><img src=\"images/pachyderm-landing-page.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a25759-cc74-464b-87e3-6c0224099824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef962f2c-d7c4-445f-9c94-a7325b45cf6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d3edd3-4cc1-4dc6-92b2-53bb2b783c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bb0b0-a132-49d7-803c-bf2515e010ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92a34cad-8094-45eb-8c02-233f47362751",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get service pachd\n",
    "NAME    TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)                                             AGE\n",
    "pachd   ClusterIP   10.109.63.8   <none>        30650/TCP,30657/TCP,30658/TCP,30600/TCP,30656/TCP   15m\n",
    "[root@os004k8-master001 pachyderm]# kubectl get service pachd -o yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  annotations:\n",
    "    meta.helm.sh/release-name: pachd\n",
    "    meta.helm.sh/release-namespace: default\n",
    "    prometheus.io/port: \"1656\"\n",
    "    prometheus.io/scrape: \"true\"\n",
    "  creationTimestamp: \"2023-05-02T16:06:43Z\"\n",
    "  labels:\n",
    "    app: pachd\n",
    "    app.kubernetes.io/managed-by: Helm\n",
    "    suite: pachyderm\n",
    "  name: pachd\n",
    "  namespace: default\n",
    "  resourceVersion: \"222366\"\n",
    "  uid: 3bf89370-b142-43cb-930c-66bd0d041c68\n",
    "spec:\n",
    "  clusterIP: 10.109.63.8\n",
    "  clusterIPs:\n",
    "  - 10.109.63.8\n",
    "  ipFamilies:\n",
    "  - IPv4\n",
    "  ipFamilyPolicy: SingleStack\n",
    "  ports:\n",
    "  - name: api-grpc-port\n",
    "    port: 30650\n",
    "    protocol: TCP\n",
    "    targetPort: api-grpc-port\n",
    "  - name: oidc-port\n",
    "    port: 30657\n",
    "    protocol: TCP\n",
    "    targetPort: oidc-port\n",
    "  - name: identity-port\n",
    "    port: 30658\n",
    "    protocol: TCP\n",
    "    targetPort: identity-port\n",
    "  - name: s3gateway-port\n",
    "    port: 30600\n",
    "    protocol: TCP\n",
    "    targetPort: s3gateway-port\n",
    "  - name: prom-metrics\n",
    "    port: 30656\n",
    "    protocol: TCP\n",
    "    targetPort: prom-metrics\n",
    "  selector:\n",
    "    app: pachd\n",
    "  sessionAffinity: None\n",
    "  type: ClusterIP\n",
    "status:\n",
    "  loadBalancer: {}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38ee45-1e0e-486a-a70e-83a5e987a108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2174f4-ec9f-4bb2-8337-99e6b797d500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2dc029-fb82-4470-8cf0-3851e623e89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39251f4d-b60a-4716-82e0-acdfa1703d70",
   "metadata": {},
   "source": [
    "We can then ask helm to install our preferred version:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# helm install pachd pachyderm/pachyderm --set deployTarget=LOCAL --set proxy.enabled=true --set proxy.service.type=LoadBalancer --version 2.5.5\n",
    "W0501 12:39:42.848489   21435 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
    "W0501 12:39:43.115008   21435 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
    "NAME: pachd\n",
    "LAST DEPLOYED: Mon May  1 12:39:40 2023\n",
    "NAMESPACE: default\n",
    "STATUS: deployed\n",
    "REVISION: 1\n",
    "NOTES:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59349d3-bab2-4ee0-aa0f-c3a6ad815dde",
   "metadata": {},
   "source": [
    "**Note**: In the command above, we are providing a number of parameters to the `helm install` command. The `--version` parameter instructs the help utility which specific version to install. The `--set` parameter instructs helm to override a value specified in a helm chart. Values, as we will discuss, are arbitrary settings that can override default settings or pvide values for templates in a helm chart. As the helm chart is written in yaml and consists of complex objects, the values specified in the ``--set` argument may consist of a json path description of the field being accessed. For example the value proxy.service.type is modifying a value for the type attribute of the service object on the proxy object. Fr more information on the arguments helm install accepts, see the [official documentation](https://helm.sh/docs/helm/helm_install/) for more detail.\n",
    "\n",
    "**Note**: While the `--set` parameter can be used to override individual chart settings, the `helm install` command also allows the user to spcify a values.yaml file (i.e. a values file) to do a bulk override. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e14b67-37f6-402f-8d48-544c2b64a477",
   "metadata": {},
   "source": [
    "### Troublshooting\n",
    "\n",
    "During the installation I had some issues. I have shown some troubleshooting steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac3a13-d3ac-4091-8529-ebba650148c9",
   "metadata": {},
   "source": [
    "#### Uninstall\n",
    "If the helm installation fails (the pods never become ready) we can uninstall using the following:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# helm uninstall pachd\n",
    "W0501 12:58:20.207995   30002 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
    "release \"pachd\" uninstalled\n",
    "```\n",
    "\n",
    "**Note**: This will not delete Persistent Storage Claims. We will need to deletet thoes manually:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get persistentvolumeclaims\n",
    "NAME                   STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
    "data-postgres-0        Pending                                                     23h\n",
    "etcd-storage-etcd-0    Pending                                                     23h\n",
    "storage-pachd-loki-0   Pending                                                     23h\n",
    "[root@os004k8-master001 pachyderm]# kubectl delete persistentvolumeclaims data-postgres-0\n",
    "persistentvolumeclaim \"data-postgres-0\" deleted\n",
    "[root@os004k8-master001 pachyderm]# kubectl delete persistentvolumeclaims etcd-storage-etcd-0\n",
    "persistentvolumeclaim \"etcd-storage-etcd-0\" deleted\n",
    "[root@os004k8-master001 pachyderm]# kubectl delete persistentvolumeclaims storage-pachd-loki-0\n",
    "persistentvolumeclaim \"storage-pachd-loki-0\" deleted\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d8802-84cf-4365-bdf4-067098f5bd87",
   "metadata": {},
   "source": [
    "#### Check Pods Are Running\n",
    "\n",
    "We can get a list of pods and their current status:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get pods\n",
    "NAME                                               READY   STATUS    RESTARTS   AGE\n",
    "console-84865b4d78-s6dmf                           1/1     Running   0          8m18s\n",
    "etcd-0                                             0/1     Pending   0          8m18s\n",
    "minio                                              1/1     Running   0          89m\n",
    "nfs-subdir-external-provisioner-7f9cf64cd8-7pv5g   1/1     Running   0          17h\n",
    "pachd-6ffb7756c6-jlddk                             0/1     Running   1          8m18s\n",
    "pachd-loki-0                                       0/1     Pending   0          8m18s\n",
    "pachd-promtail-2j628                               0/1     Running   0          8m18s\n",
    "pachd-promtail-4xhff                               1/1     Running   0          8m18s\n",
    "pachd-promtail-5c2rc                               1/1     Running   0          8m18s\n",
    "pachd-promtail-9czgl                               1/1     Running   0          8m18s\n",
    "pachd-promtail-m5zr5                               0/1     Running   0          8m18s\n",
    "pachd-promtail-mjlrc                               0/1     Running   0          8m18s\n",
    "pachyderm-kube-event-tail-6c6598cd5-6sj2s          1/1     Running   0          8m18s\n",
    "pachyderm-proxy-7f4545985c-92ntw                   1/1     Running   0          8m18s\n",
    "pg-bouncer-88dbc966b-5c9d8                         1/1     Running   0          8m18s\n",
    "postgres-0                                         0/1     Pending   0          8m18s\n",
    "```\n",
    "\n",
    "We can use the describe command to interrogate why a pod is not running and \n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# kubectl describe pod pachd-loki-0\n",
    "Name:           pachd-loki-0\n",
    "Namespace:      default\n",
    "Priority:       0\n",
    "Node:           <none>\n",
    "Labels:         app=loki\n",
    "                controller-revision-hash=pachd-loki-5bc57fd4dd\n",
    "                name=pachd-loki\n",
    "                release=pachd\n",
    "                statefulset.kubernetes.io/pod-name=pachd-loki-0\n",
    "Annotations:    checksum/config: 9688827d4f9db7e59b48154e6433ef91fdc762d5b7545bfbe786f8d75c4de68a\n",
    "                prometheus.io/port: http-metrics\n",
    "                prometheus.io/scrape: true\n",
    "Status:         Pending\n",
    "IP:\n",
    "IPs:            <none>\n",
    "Controlled By:  StatefulSet/pachd-loki\n",
    "Containers:\n",
    "  loki:\n",
    "    Image:       grafana/loki:2.6.1\n",
    "    Ports:       3100/TCP, 9095/TCP, 7946/TCP\n",
    "    Host Ports:  0/TCP, 0/TCP, 0/TCP\n",
    "    Args:\n",
    "      -config.file=/etc/loki/loki.yaml\n",
    "    Liveness:     http-get http://:http-metrics/ready delay=45s timeout=1s period=10s #success=1 #failure=3\n",
    "    Readiness:    http-get http://:http-metrics/ready delay=45s timeout=1s period=10s #success=1 #failure=3\n",
    "    Environment:  <none>\n",
    "    Mounts:\n",
    "      /data from storage (rw)\n",
    "      /etc/loki from config (rw)\n",
    "      /tmp from tmp (rw)\n",
    "Conditions:\n",
    "  Type           Status\n",
    "  PodScheduled   False\n",
    "Volumes:\n",
    "  storage:\n",
    "    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)\n",
    "    ClaimName:  storage-pachd-loki-0\n",
    "    ReadOnly:   false\n",
    "  tmp:\n",
    "    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)\n",
    "    Medium:\n",
    "    SizeLimit:  <unset>\n",
    "  config:\n",
    "    Type:        Secret (a volume populated by a Secret)\n",
    "    SecretName:  pachd-loki\n",
    "    Optional:    false\n",
    "QoS Class:       BestEffort\n",
    "Node-Selectors:  <none>\n",
    "Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
    "                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
    "Events:\n",
    "  Type     Reason            Age                  From               Message\n",
    "  ----     ------            ----                 ----               -------\n",
    "  Warning  FailedScheduling  45s (x3 over 2m12s)  default-scheduler  0/7 nodes are available: 7 pod has unbound immediate PersistentVolumeClaims.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c533250e-2fb1-4de4-9fb0-34de30ef808c",
   "metadata": {},
   "source": [
    "#### Investigate Issue With Persistant Storage Claim\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get persistentvolumeclaims\n",
    "NAME                   STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
    "data-postgres-0        Pending                                                     23h\n",
    "etcd-storage-etcd-0    Pending                                                     23h\n",
    "storage-pachd-loki-0   Pending                                                     23h\n",
    "```\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl describe persistentvolumeclaims storage-pachd-loki-0\n",
    "Name:          storage-pachd-loki-0\n",
    "Namespace:     default\n",
    "StorageClass:\n",
    "Status:        Pending\n",
    "Volume:\n",
    "Labels:        app=loki\n",
    "               release=pachd\n",
    "Annotations:   <none>\n",
    "Finalizers:    [kubernetes.io/pvc-protection]\n",
    "Capacity:\n",
    "Access Modes:\n",
    "VolumeMode:    Filesystem\n",
    "Used By:       pachd-loki-0\n",
    "Events:\n",
    "  Type    Reason         Age                    From                         Message\n",
    "  ----    ------         ----                   ----                         -------\n",
    "  Normal  FailedBinding  3m8s (x5562 over 23h)  persistentvolume-controller  no persistent volumes available for this claim and no storage class is set\n",
    "```\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get persistentvolumeclaims/storage-pachd-loki-0 -o yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  creationTimestamp: \"2023-05-01T16:39:45Z\"\n",
    "  finalizers:\n",
    "  - kubernetes.io/pvc-protection\n",
    "  labels:\n",
    "    app: loki\n",
    "    release: pachd\n",
    "  name: storage-pachd-loki-0\n",
    "  namespace: default\n",
    "  resourceVersion: \"34516\"\n",
    "  uid: 33d258a0-32a3-4911-a54a-46f57a2c757e\n",
    "spec:\n",
    "  accessModes:\n",
    "  - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 10Gi\n",
    "  volumeMode: Filesystem\n",
    "status:\n",
    "  phase: Pending\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2ae09-9dab-4fa4-8873-3cef298e789c",
   "metadata": {},
   "source": [
    "Uninstalling does not delete persistent volume claims. We need to delete these and recreate. Make sure the values file specifies the correct storage class name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4b7b4-2ecd-49c9-a8af-3c1b36493ce6",
   "metadata": {},
   "source": [
    "**Note**: The claims should resemble the following:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get persistentvolumeclaims\n",
    "NAME                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
    "data-postgres-0        Bound    pvc-6dfab811-746a-4805-9635-911974e1e11c   10Gi       RWO            nfs-client     5s\n",
    "etcd-storage-etcd-0    Bound    pvc-9f4b9c42-50d4-4aac-9059-3025a68e2c60   10Gi       RWO            nfs-client     5s\n",
    "storage-pachd-loki-0   Bound    pvc-28f6a320-2452-436a-b837-52d7fec07d4a   10Gi       RWO            nfs-client     5s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa51a6c-472e-4b8f-ae33-f3db2de2eda6",
   "metadata": {},
   "source": [
    "#### Investigate Sectret For Failed Pod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaeae52-7975-4c5b-9cd2-302d0a529460",
   "metadata": {},
   "source": [
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get pods\n",
    "NAME                                               READY   STATUS             RESTARTS   AGE\n",
    "console-5f7fbb6cb9-qjvlf                           1/1     Running            0          17m\n",
    "etcd-0                                             1/1     Running            0          17m\n",
    "minio                                              1/1     Running            0          122m\n",
    "nfs-subdir-external-provisioner-7f9cf64cd8-7pv5g   1/1     Running            0          17h\n",
    "pachd-55467db54f-dwddb                             0/1     CrashLoopBackOff   7          17m\n",
    "pachd-loki-0                                       1/1     Running            0          17m\n",
    "pachd-promtail-7v65r                               1/1     Running            0          17m\n",
    "pachd-promtail-fzt4t                               0/1     Running            0          17m\n",
    "pachd-promtail-kpq9p                               1/1     Running            0          17m\n",
    "pachd-promtail-lsp8s                               0/1     Running            0          17m\n",
    "pachd-promtail-npmrq                               1/1     Running            0          17m\n",
    "pachd-promtail-vp822                               0/1     Running            0          17m\n",
    "pachyderm-kube-event-tail-6c6598cd5-kjwvm          1/1     Running            0          17m\n",
    "pachyderm-proxy-7f4545985c-xdl6q                   1/1     Running            0          17m\n",
    "pg-bouncer-88dbc966b-vtdw9                         1/1     Running            0          17m\n",
    "postgres-0                                         1/1     Running            0          17m\n",
    "[root@os004k8-master001 pachyderm]# kubectl get pods pachd-55467db54f-dwddb\n",
    "NAME                     READY   STATUS             RESTARTS   AGE\n",
    "pachd-55467db54f-dwddb   0/1     CrashLoopBackOff   7          17m\n",
    "[root@os004k8-master001 pachyderm]# kubectl describe pods pachd-55467db54f-dwddb\n",
    "Name:         pachd-55467db54f-dwddb\n",
    "Namespace:    default\n",
    "Priority:     0\n",
    "Node:         os004k8-worker005.foobar.com/15.4.7.105\n",
    "Start Time:   Tue, 02 May 2023 12:06:43 -0400\n",
    "Labels:       app=pachd\n",
    "              pod-template-hash=55467db54f\n",
    "              suite=pachyderm\n",
    "Annotations:  checksum/helm-values: fd0a0a72dad39a14acf6eb56293e44d48356e0f8fc1a86307621c95b2f20d714\n",
    "              checksum/storage-secret: 44d530a6561604c3aa1902c08580e6d18618f932f5199448520b26bc345bc88d\n",
    "              seccomp.security.alpha.kubernetes.io/pod: runtime/default\n",
    "Status:       Running\n",
    "IP:           10.47.0.2\n",
    "IPs:\n",
    "  IP:           10.47.0.2\n",
    "Controlled By:  ReplicaSet/pachd-55467db54f\n",
    "Containers:\n",
    "  pachd:\n",
    "    Container ID:  docker://0f8409fd13fe1fa106b493b15fedc91e67c4631f57afbf668f1300d9bd7e39af\n",
    "    Image:         pachyderm/pachd:2.5.5\n",
    "    Image ID:      docker-pullable://pachyderm/pachd@sha256:186f8079a393314b5edbf12904019119f3266373dcdf5b2d09b2fc592c5e8237\n",
    "    Ports:         1600/TCP, 1650/TCP, 1653/TCP, 1657/TCP, 1658/TCP, 1656/TCP\n",
    "    Host Ports:    0/TCP, 0/TCP, 0/TCP, 0/TCP, 0/TCP, 0/TCP\n",
    "    Command:\n",
    "      /pachd\n",
    "    Args:\n",
    "      --mode\n",
    "      $(MODE)\n",
    "    State:          Waiting\n",
    "      Reason:       CrashLoopBackOff\n",
    "    Last State:     Terminated\n",
    "      Reason:       Error\n",
    "      Exit Code:    1\n",
    "      Started:      Tue, 02 May 2023 12:24:56 -0400\n",
    "      Finished:     Tue, 02 May 2023 12:24:56 -0400\n",
    "    Ready:          False\n",
    "    Restart Count:  8\n",
    "    Liveness:       exec [/pachd --readiness] delay=0s timeout=30s period=10s #success=1 #failure=10\n",
    "    Readiness:      exec [/pachd --readiness] delay=0s timeout=1s period=10s #success=1 #failure=3\n",
    "    Startup:        exec [/pachd --readiness] delay=0s timeout=30s period=10s #success=1 #failure=10\n",
    "    Environment Variables from:\n",
    "      pachyderm-storage-secret        Secret     Optional: false\n",
    "      pachyderm-deployment-id-secret  Secret     Optional: false\n",
    "      pachd-config                    ConfigMap  Optional: true\n",
    "    Environment:\n",
    "      PACHW_IN_SIDECARS:                         true\n",
    "      PACHW_MIN_REPLICAS:                        0\n",
    "      PACHW_MAX_REPLICAS:                        1\n",
    "      POSTGRES_HOST:                             postgres\n",
    "      POSTGRES_PORT:                             5432\n",
    "      POSTGRES_USER:                             pachyderm\n",
    "      POSTGRES_DATABASE:                         pachyderm\n",
    "      POSTGRES_PASSWORD:                         <set to the key 'postgresql-password' in secret 'postgres'>  Optional: false\n",
    "      PG_BOUNCER_HOST:                           pg-bouncer\n",
    "      PG_BOUNCER_PORT:                           5432\n",
    "      LOKI_LOGGING:                              true\n",
    "      LOKI_SERVICE_HOST:                         $(PACHD_LOKI_SERVICE_HOST)\n",
    "      LOKI_SERVICE_PORT:                         $(PACHD_LOKI_SERVICE_PORT)\n",
    "      PACH_ROOT:                                 /pach\n",
    "      ETCD_PREFIX:\n",
    "      STORAGE_BACKEND:                           minio\n",
    "      WORKER_IMAGE:                              pachyderm/worker:2.5.5\n",
    "      WORKER_SIDECAR_IMAGE:                      pachyderm/pachd:2.5.5\n",
    "      WORKER_IMAGE_PULL_POLICY:                  IfNotPresent\n",
    "      WORKER_SERVICE_ACCOUNT:                    pachyderm-worker\n",
    "      METRICS:                                   true\n",
    "      PACHYDERM_LOG_LEVEL:                       info\n",
    "      PACH_NAMESPACE:                            default (v1:metadata.namespace)\n",
    "      REQUIRE_CRITICAL_SERVERS_ONLY:             false\n",
    "      PACHD_POD_NAME:                            pachd-55467db54f-dwddb (v1:metadata.name)\n",
    "      PPS_WORKER_GRPC_PORT:                      1080\n",
    "      STORAGE_UPLOAD_CONCURRENCY_LIMIT:          100\n",
    "      STORAGE_PUT_FILE_CONCURRENCY_LIMIT:        100\n",
    "      STORAGE_COMPACTION_SHARD_SIZE_THRESHOLD:   0\n",
    "      STORAGE_COMPACTION_SHARD_COUNT_THRESHOLD:  0\n",
    "      STORAGE_COMPACTION_MAX_FANIN:              10\n",
    "      STORAGE_FILESETS_MAX_OPEN:                 50\n",
    "      STORAGE_DISK_CACHE_SIZE:                   100\n",
    "      STORAGE_MEMORY_CACHE_SIZE:                 100\n",
    "      CONSOLE_OAUTH_ID:                          console\n",
    "      CONSOLE_OAUTH_SECRET:                      <set to the key 'OAUTH_CLIENT_SECRET' in secret 'pachyderm-console-secret'>  Optional: false\n",
    "      ENABLE_WORKER_SECURITY_CONTEXTS:           true\n",
    "      ENABLE_PREFLIGHT_CHECKS:                   true\n",
    "      UNPAUSED_MODE:                             full\n",
    "      K8S_MEMORY_REQUEST:                        0 (requests.memory)\n",
    "      K8S_MEMORY_LIMIT:                          node allocatable (limits.memory)\n",
    "    Mounts:\n",
    "      /pach from pach-disk (rw)\n",
    "      /pachyderm-storage-secret from pachyderm-storage-secret (rw)\n",
    "      /tmp from tmp (rw)\n",
    "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-rbrq7 (ro)\n",
    "Conditions:\n",
    "  Type              Status\n",
    "  Initialized       True\n",
    "  Ready             False\n",
    "  ContainersReady   False\n",
    "  PodScheduled      True\n",
    "Volumes:\n",
    "  tmp:\n",
    "    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)\n",
    "    Medium:\n",
    "    SizeLimit:  <unset>\n",
    "  pach-disk:\n",
    "    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)\n",
    "    Medium:\n",
    "    SizeLimit:  <unset>\n",
    "  pachyderm-storage-secret:\n",
    "    Type:        Secret (a volume populated by a Secret)\n",
    "    SecretName:  pachyderm-storage-secret\n",
    "    Optional:    false\n",
    "  kube-api-access-rbrq7:\n",
    "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
    "    TokenExpirationSeconds:  3607\n",
    "    ConfigMapName:           kube-root-ca.crt\n",
    "    ConfigMapOptional:       <nil>\n",
    "    DownwardAPI:             true\n",
    "QoS Class:                   BestEffort\n",
    "Node-Selectors:              <none>\n",
    "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
    "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
    "Events:\n",
    "  Type     Reason     Age                   From               Message\n",
    "  ----     ------     ----                  ----               -------\n",
    "  Normal   Scheduled  18m                   default-scheduler  Successfully assigned default/pachd-55467db54f-dwddb to os004k8-worker005.foobar.com\n",
    "  Warning  Unhealthy  16m (x4 over 17m)     kubelet            Startup probe failed:\n",
    "  Normal   Pulled     15m (x4 over 18m)     kubelet            Container image \"pachyderm/pachd:2.5.5\" already present on machine\n",
    "  Normal   Created    15m (x4 over 18m)     kubelet            Created container pachd\n",
    "  Normal   Started    15m (x4 over 18m)     kubelet            Started container pachd\n",
    "  Warning  BackOff    3m25s (x72 over 16m)  kubelet            Back-off restarting failed container\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683fc267-11b9-4dd8-b48d-5ae7c7cafb51",
   "metadata": {},
   "source": [
    "We see there is some message related to POSTGRES_PASSWORD. I wonder if that is an issue or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cea7e-6cbb-43e3-be29-624404cca3c5",
   "metadata": {},
   "source": [
    "Extracting the yaml for the pod we see:\n",
    "\n",
    "```\n",
    "    - name: POSTGRES_PASSWORD\n",
    "      valueFrom:\n",
    "        secretKeyRef:\n",
    "          key: postgresql-password\n",
    "          name: postgres\n",
    "```\n",
    "\n",
    "Looking at the secrets we see:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get secrets\n",
    "NAME                                                    TYPE                                  DATA   AGE\n",
    "default-token-8ptvk                                     kubernetes.io/service-account-token   3      41h\n",
    "nfs-subdir-external-provisioner-token-f4rr7             kubernetes.io/service-account-token   3      17h\n",
    "pachd-loki                                              Opaque                                1      23m\n",
    "pachd-loki-token-mjvtd                                  kubernetes.io/service-account-token   3      23m\n",
    "pachd-promtail                                          Opaque                                1      23m\n",
    "pachd-promtail-token-4dg6z                              kubernetes.io/service-account-token   3      23m\n",
    "pachyderm-console-secret                                Opaque                                1      23m\n",
    "pachyderm-deployment-id-secret                          Opaque                                1      23m\n",
    "pachyderm-identity                                      Opaque                                1      23m\n",
    "pachyderm-kube-event-tail-token-k477h                   kubernetes.io/service-account-token   3      23m\n",
    "pachyderm-storage-secret                                Opaque                                0      23m\n",
    "pachyderm-token-5lbv2                                   kubernetes.io/service-account-token   3      23m\n",
    "pachyderm-worker-token-dm5h2                            kubernetes.io/service-account-token   3      23m\n",
    "postgres                                                Opaque                                2      23m\n",
    "sh.helm.release.v1.nfs-subdir-external-provisioner.v1   helm.sh/release.v1                    1      17h\n",
    "sh.helm.release.v1.pachd.v1                             helm.sh/release.v1                    1      23m\n",
    "[root@os004k8-master001 pachyderm]# kubectl get secrets postgres\n",
    "NAME       TYPE     DATA   AGE\n",
    "postgres   Opaque   2      25m\n",
    "[root@os004k8-master001 pachyderm]# kubectl describe secrets postgres\n",
    "Name:         postgres\n",
    "Namespace:    default\n",
    "Labels:       app.kubernetes.io/instance=pachd\n",
    "              app.kubernetes.io/managed-by=Helm\n",
    "              app.kubernetes.io/name=postgresql\n",
    "              helm.sh/chart=postgresql-10.8.0\n",
    "Annotations:  meta.helm.sh/release-name: pachd\n",
    "              meta.helm.sh/release-namespace: default\n",
    "\n",
    "Type:  Opaque\n",
    "\n",
    "Data\n",
    "====\n",
    "postgresql-password:           22 bytes\n",
    "postgresql-postgres-password:  22 bytes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754a815-1e9d-4360-bd9f-cf7a3815189f",
   "metadata": {},
   "source": [
    "We can then decode the secrets\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get secrets postgres -o json\n",
    "{\n",
    "    \"apiVersion\": \"v1\",\n",
    "    \"data\": {\n",
    "        \"postgresql-password\": \"aW5zZWN1cmUtdXNlci1wYXNzd29yZA==\",\n",
    "        \"postgresql-postgres-password\": \"aW5zZWN1cmUtcm9vdC1wYXNzd29yZA==\"\n",
    "    },\n",
    "    \"kind\": \"Secret\",\n",
    "    \"metadata\": {\n",
    "        \"annotations\": {\n",
    "            \"meta.helm.sh/release-name\": \"pachd\",\n",
    "            \"meta.helm.sh/release-namespace\": \"default\"\n",
    "        },\n",
    "        \"creationTimestamp\": \"2023-05-02T16:06:42Z\",\n",
    "        \"labels\": {\n",
    "            \"app.kubernetes.io/instance\": \"pachd\",\n",
    "            \"app.kubernetes.io/managed-by\": \"Helm\",\n",
    "            \"app.kubernetes.io/name\": \"postgresql\",\n",
    "            \"helm.sh/chart\": \"postgresql-10.8.0\"\n",
    "        },\n",
    "        \"name\": \"postgres\",\n",
    "        \"namespace\": \"default\",\n",
    "        \"resourceVersion\": \"222291\",\n",
    "        \"uid\": \"ea28f919-4b94-4dfb-ac4e-a9608abc5651\"\n",
    "    },\n",
    "    \"type\": \"Opaque\"\n",
    "}\n",
    "[root@os004k8-master001 pachyderm]# kubectl get secrets postgres -o json | jq '.data | map_values(@base64d)'\n",
    "{\n",
    "  \"postgresql-password\": \"insecure-user-password\",\n",
    "  \"postgresql-postgres-password\": \"insecure-root-password\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285973a7-1446-44c8-bbb2-8cf843e64f40",
   "metadata": {},
   "source": [
    "Looking at the values in the [values file on github](https://github.com/pachyderm/pachyderm/blob/2.5.x/etc/helm/pachyderm/values.yaml), we can see that these reflect the defaults:\n",
    "\n",
    "```\n",
    "global:\n",
    "  postgresql:\n",
    "    # postgresqlUsername is the username to access the pachyderm and dex databases\n",
    "    postgresqlUsername: \"pachyderm\"\n",
    "    # postgresqlPassword to access the postgresql database.  We set a default well-known password to\n",
    "    # facilitate easy upgrades when testing locally.  Any sort of install that needs to be secure\n",
    "    # must specify a secure password here, or provide the postgresqlExistingSecretName and\n",
    "    # postgresqlExistingSecretKey secret.  If using an external Postgres instance (CloudSQL / RDS /\n",
    "    # etc.), this is the password that Pachyderm will use to connect to it.\n",
    "    postgresqlPassword: \"insecure-user-password\"\n",
    "    # When installing a local Postgres instance, postgresqlPostgresPassword defines the root\n",
    "    # ('postgres') user's password.  It must remain consistent between upgrades, and must be\n",
    "    # explicitly set to a value if security is desired.  Pachyderm does not use this account; this\n",
    "    # password is only required so that administrators can manually perform administrative tasks.\n",
    "    postgresqlPostgresPassword: \"insecure-root-password\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b744a00-2327-43e6-a6c3-7d9e7ea2159b",
   "metadata": {},
   "source": [
    "According to the [documentation](https://hub.docker.com/_/postgres), the credentials for the postgresql server are configured through environmental variables\n",
    "\n",
    "We will confirm this. First we connect to the pod\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get pods\n",
    "NAME                                               READY   STATUS             RESTARTS   AGE\n",
    "console-5f7fbb6cb9-qjvlf                           1/1     Running            0          63m\n",
    "etcd-0                                             1/1     Running            0          63m\n",
    "minio                                              1/1     Running            0          169m\n",
    "nfs-subdir-external-provisioner-7f9cf64cd8-7pv5g   1/1     Running            0          18h\n",
    "pachd-55467db54f-dwddb                             0/1     CrashLoopBackOff   16         63m\n",
    "pachd-loki-0                                       1/1     Running            0          63m\n",
    "pachd-promtail-7v65r                               1/1     Running            0          63m\n",
    "pachd-promtail-fzt4t                               0/1     Running            0          63m\n",
    "pachd-promtail-kpq9p                               1/1     Running            0          63m\n",
    "pachd-promtail-lsp8s                               0/1     Running            0          63m\n",
    "pachd-promtail-npmrq                               1/1     Running            0          63m\n",
    "pachd-promtail-vp822                               0/1     Running            0          63m\n",
    "pachyderm-kube-event-tail-6c6598cd5-kjwvm          1/1     Running            0          63m\n",
    "pachyderm-proxy-7f4545985c-xdl6q                   1/1     Running            0          63m\n",
    "pg-bouncer-88dbc966b-vtdw9                         1/1     Running            0          63m\n",
    "postgres-0                                         1/1     Running            0          63m\n",
    "[root@os004k8-master001 pachyderm]# kubectl exec -ti postgres-0 /bin/bash\n",
    "```\n",
    "\n",
    "Once `kubectl exec` connects us to the postgresql pod, we run a command which tests logging in with credentials\n",
    "\n",
    "```\n",
    "pgsql@postgres-0:/$ echo $POSTGRES_USER\n",
    "pachyderm\n",
    "pgsql@postgres-0:/$ echo $POSTGRES_PASSWORD\n",
    "insecure-user-password\n",
    "pgsql@postgres-0:/$ psql -d \"postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost\" -c \"select now()\"\n",
    "              now\n",
    "-------------------------------\n",
    " 2023-05-02 17:17:06.299393+00\n",
    "(1 row)\n",
    "```\n",
    "\n",
    "We see the credentials are working.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c34f9-f8f4-490f-a1fd-ad25c6abe220",
   "metadata": {},
   "source": [
    "#### Investigate Failing Pod (Deployment Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4823e5a-cf2e-456a-9c13-f5348300f9fb",
   "metadata": {},
   "source": [
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl get pods\n",
    "NAME                                               READY   STATUS             RESTARTS   AGE\n",
    "console-5f7fbb6cb9-qjvlf                           1/1     Running            0          72m\n",
    "etcd-0                                             1/1     Running            0          72m\n",
    "minio                                              1/1     Running            0          177m\n",
    "nfs-subdir-external-provisioner-7f9cf64cd8-7pv5g   1/1     Running            0          18h\n",
    "pachd-55467db54f-dwddb                             0/1     CrashLoopBackOff   18         72m\n",
    "...\n",
    "```\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl logs pachd-55467db54f-dwddb | tail -n 5\n",
    "{\"severity\":\"info\",\"time\":\"2023-05-02T17:16:17.858749827Z\",\"logger\":\"ApplyMigrations\",\"caller\":\"migrations/migrations.go:128\",\"message\":\"migration 28 already applied\"}\n",
    "{\"severity\":\"info\",\"time\":\"2023-05-02T17:16:17.860701594Z\",\"logger\":\"ApplyMigrations\",\"caller\":\"migrations/migrations.go:128\",\"message\":\"migration 29 already applied\"}\n",
    "{\"severity\":\"info\",\"time\":\"2023-05-02T17:16:17.86117891Z\",\"logger\":\"ApplyMigrations\",\"caller\":\"migrations/migrations.go:95\",\"message\":\"ApplyMigrations: span finished ok\",\"spanDuration\":0.071345294}\n",
    "{\"severity\":\"info\",\"time\":\"2023-05-02T17:16:17.869971271Z\",\"caller\":\"grpcutil/server.go:69\",\"message\":\"TLS disabled\",\"error\":\"could not stat public cert at /pachd-tls-cert/tls.crt: stat /pachd-tls-cert/tls.crt: no such file or directory\",\"errorVerbose\":\"stat /pachd-tls-cert/tls.crt: no such file or directory\\ncould not stat public cert at /pachd-tls-cert/tls.crt\\ngithub.com/pachyderm/pachyderm/v2/src/internal/tls.GetCertPaths\\n\\tsrc/internal/tls/tls.go:32\\ngithub.com/pachyderm/pachyderm/v2/src/internal/grpcutil.NewServer\\n\\tsrc/internal/grpcutil/server.go:67\\ngithub.com/pachyderm/pachyderm/v2/src/internal/pachd.(*builder).initExternalServer\\n\\tsrc/internal/pachd/builder.go:195\\ngithub.com/pachyderm/pachyderm/v2/src/internal/pachd.(*builder).apply\\n\\tsrc/internal/pachd/builder.go:88\\ngithub.com/pachyderm/pachyderm/v2/src/internal/pachd.(*fullBuilder).buildAndRun\\n\\tsrc/internal/pachd/full.go:66\\ngithub.com/pachyderm/pachyderm/v2/src/internal/pachd.FullMode\\n\\tsrc/internal/pachd/full.go:107\\ngithub.com/pachyderm/pachyderm/v2/src/internal/cmdutil.Main\\n\\tsrc/internal/cmdutil/env.go:34\\nmain.main\\n\\tsrc/server/cmd/pachd/main.go:50\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:250\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1594\"}\n",
    "unrecognized storage backend: minio\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde68b0-2a65-4f88-940d-df833ae775cc",
   "metadata": {},
   "source": [
    "```\n",
    "{\"severity\":\"info\",\"time\":\"2023-05-02T17:26:32.937130467Z\",\"logger\":\"WaitUntilReady\",\"caller\":\"dbutil/db.go:142\",\"message\":\"db is not ready\",\"reason\":\"failed to connect to `host=pg-bouncer user=pachyderm database=pachyderm`: server error (FATAL: pgbouncer cannot connect to server (SQLSTATE 08P01))\"}\n",
    "\n",
    "```\n",
    "this went away, flase alarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a4d91-6413-4fd1-ace2-940c42a11bf7",
   "metadata": {},
   "source": [
    "I changed the backend to MINIO for the pachd section of the values file (documentation wrong)\n",
    "\n",
    "Now i see\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 pachyderm]# kubectl describe pod pachd-9c6b4c75b-ddlv6\n",
    "...\n",
    "  Warning  FailedMount  4m34s                  kubelet            MountVolume.SetUp failed for volume \"pachyderm-storage-secret\" : failed to sync secret cache: timed out waiting for the condition\n",
    "...\n",
    "\n",
    "\n",
    "[root@os004k8-master001 pachyderm]# kubectl logs pachd-9c6b4c75b-ddlv6\n",
    "...\n",
    "unable to write to object storage: pachyderm does not contain item: (test/6ac321e4a09147e3917104f7b3d4ae38)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a84ab-b167-43c3-86c5-e900b60f38ca",
   "metadata": {},
   "source": [
    "Found it in the source code\n",
    "\n",
    "```\n",
    "// TestStorage is a defensive method for checking to make sure that storage is\n",
    "// properly configured.\n",
    "func TestStorage(ctx context.Context, c Client) error {\n",
    "\ttestObj := \"test/\" + uuid.NewWithoutDashes()\n",
    "\tif err := func() (retErr error) {\n",
    "\t\tdata := []byte(\"test\")\n",
    "\t\treturn errors.EnsureStack(c.Put(ctx, testObj, bytes.NewReader(data)))\n",
    "\t}(); err != nil {\n",
    "\t\treturn errors.Wrapf(err, \"unable to write to object storage\")\n",
    "\t}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36b262-0c49-4491-8c93-8d344df8939c",
   "metadata": {},
   "source": [
    "This suggests the minio configurations are wrong. They were. I needed to creat a bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc1a23-fd93-44e0-9c96-4079f5e94c18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c3efa0e-342f-4a3d-9092-87f7804ec70b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64bfb0-4bc7-4dda-bfb8-e8ff88a40635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf85b4f-cfd4-4bb0-8857-9bdba15a2eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157457d7-72e2-4076-8947-7fadc12f4d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b528c7-cd2a-4762-a35e-d37a2cb3ddb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa3957-b884-4727-ae55-c82abdb0b767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "893376a1-e780-4bf4-b057-d0b6c6d4fbfa",
   "metadata": {},
   "source": [
    "#### Persistent Volume Claim Not Working\n",
    "In the events section, I see the pod is not running because it failed to schedule. This failure shows an associated message of \"pod has unbound immediate PersistentVolumeClaims\". I see that the pod is trying to run a loki container provided by the grafana project. I googled this error to try an understand the root cause."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff4826-8bdb-42c6-89d0-2a40b66eb559",
   "metadata": {},
   "source": [
    "I managed to find an [issue](https://community.grafana.com/t/helm-installation-with-persisistent-storage-does-not-bind-storage/45672) from an issue tracker mentioning a similar issue.\n",
    "\n",
    "The first question was to list out the persistent volume claims with a `kubectl get pvc`. Mine was as follows:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# kubectl get PersistentVolumeClaims\n",
    "NAME                   STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
    "data-postgres-0        Pending                                                     128m\n",
    "etcd-storage-etcd-0    Pending                                                     128m\n",
    "storage-pachd-loki-0   Pending                                                     128m\n",
    "```\n",
    "\n",
    "Describing the resource I see the following:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# kubectl describe pvc storage-pachd-loki-0\n",
    "Name:          storage-pachd-loki-0\n",
    "Namespace:     default\n",
    "StorageClass:\n",
    "Status:        Pending\n",
    "Volume:\n",
    "Labels:        app=loki\n",
    "               release=pachd\n",
    "Annotations:   <none>\n",
    "Finalizers:    [kubernetes.io/pvc-protection]\n",
    "Capacity:\n",
    "Access Modes:\n",
    "VolumeMode:    Filesystem\n",
    "Used By:       pachd-loki-0\n",
    "Events:\n",
    "  Type    Reason         Age                     From                         Message\n",
    "  ----    ------         ----                    ----                         -------\n",
    "  Normal  FailedBinding  4m25s (x502 over 129m)  persistentvolume-controller  no persistent volumes available for this claim and no storage class is set\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8640d6c2-3002-4336-9bc5-a48e82b1ce6e",
   "metadata": {},
   "source": [
    "Having a look at the deployment manifest I see:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# kubectl get pvc storage-pachd-loki-0 -o yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  creationTimestamp: \"2023-05-01T16:39:45Z\"\n",
    "  finalizers:\n",
    "  - kubernetes.io/pvc-protection\n",
    "  labels:\n",
    "    app: loki\n",
    "    release: pachd\n",
    "  name: storage-pachd-loki-0\n",
    "  namespace: default\n",
    "  resourceVersion: \"34516\"\n",
    "  uid: 33d258a0-32a3-4911-a54a-46f57a2c757e\n",
    "spec:\n",
    "  accessModes:\n",
    "  - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 10Gi\n",
    "  volumeMode: Filesystem\n",
    "status:\n",
    "  phase: Pending\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e6dc7f-260c-455a-abb1-6183fc308305",
   "metadata": {},
   "source": [
    "I wanted to understand what a PVC was. I had a look at the official kubernetes documentation to dig in.\n",
    "\n",
    "> The PersistentVolume subsystem provides an API for users and administrators that abstracts details of how storage is provided from how it is consumed. To do this, we introduce two new API resources: PersistentVolume and PersistentVolumeClaim.\n",
    ">\n",
    "> A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system.\n",
    ">\n",
    "> A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted ReadWriteOnce, ReadOnlyMany or ReadWriteMany, see AccessModes).\n",
    ">\n",
    "> https://kubernetes.io/docs/concepts/storage/persistent-volumes/\n",
    "\n",
    "At this point I think I am understanding the problem: the helm chart deployed pods which required PersistentVolumes, but those volumes do not exist. I wondered why and continued reading:\n",
    "\n",
    "> Provisioning\n",
    ">\n",
    ">There are two ways PVs may be provisioned: statically or dynamically.\n",
    ">\n",
    "> Static\n",
    ">\n",
    "> A cluster administrator creates a number of PVs. They carry the details of the real storage, which is available for use by cluster users. They exist in the Kubernetes API and are available for consumption.\n",
    ">\n",
    "> Dynamic\n",
    ">\n",
    "> When none of the static PVs the administrator created match a user's PersistentVolumeClaim, the cluster may try to dynamically provision a volume specially for the PVC. This provisioning is based on StorageClasses: the PVC must request a storage class and the administrator must have created and configured that class for dynamic provisioning to occur. Claims that request the class \"\" effectively disable dynamic provisioning for themselves.\n",
    ">\n",
    "> To enable dynamic storage provisioning based on storage class, the cluster administrator needs to enable the DefaultStorageClass admission controller on the API server. This can be done, for example, by ensuring that DefaultStorageClass is among the comma-delimited, ordered list of values for the --enable-admission-plugins flag of the API server component. For more information on API server command-line flags, check kube-apiserver documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa81fa-cf7e-483f-9af2-49e26bd90775",
   "metadata": {},
   "source": [
    "So, if there are no volumes, the volume claims can never be satisfied. So my next question is: \"Are resources being defined/requested but not being deployed correctly (i.e. something is failing) or are resources not being defined but are being requested?\"\n",
    "\n",
    "I checked and confirmed I do not have any persistent volumes provisioned on my cluster:\n",
    "\n",
    "```\n",
    "[root@os004k8-master001 ~]# kubectl get PersistentVolumes\n",
    "No resources found\n",
    "\n",
    "```\n",
    "\n",
    "I would expect that if something was defined and a deployment failed I would see it listed in that output. This is telling me that nothing was provisioned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb6537-bc51-45a3-82e9-58635f050db6",
   "metadata": {},
   "source": [
    "To make sure this suspicion was correct I had a look at loki documentation. It does [mention](https://grafana.com/docs/loki/latest/installation/helm/configure-storage/) that in order to use loki, stoage must be configured. The storage configuration section in the values.yaml file accepts a number of parameters. \n",
    "\n",
    "> Configure storage\n",
    "> The scalable installation requires a managed object store such as AWS S3 or Google Cloud Storage or a self-hosted store such as Minio. The single binary installation can only use the filesystem for storage.\n",
    ">\n",
    "> This guide assumes Loki will be installed in on of the modes above and that a values.yaml has been created.\n",
    ">\n",
    "> https://grafana.com/docs/loki/latest/installation/helm/configure-storage/\n",
    "\n",
    "I had a look at the [values.yaml file from the git repository](https://github.com/grafana/helm-charts/blob/main/charts/loki-stack/values.yaml) and saw that it did not have any definitions specific to a storage provider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d45ce3-7ade-46dc-87f0-7af4e8935141",
   "metadata": {},
   "source": [
    "Ultimately the root issue was that I had not properly defined a Storage Class and associated it with a Persistent Volume Claim. [This section](#persistent-volume-claims) describes how to accomplish this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
