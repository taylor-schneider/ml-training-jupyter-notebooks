{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d52eefb-abd7-4393-a37a-f055f1c5a548",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "[LakeFS](https://docs.lakefs.io/) is a storage solution which provides version control for data lakes. It sits on top of a data lake as an \"overlay filesystem\" meaning it provides an api which maps version info to phsical data stored in the underlying data store.\n",
    "\n",
    "Note: At this point in time the latest release of LakeFS is v0.69.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62604f01-65b7-4a4d-91b4-e7847a9845ed",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "A git-like interface\n",
    "\n",
    "No data duplication\n",
    "\n",
    "An S3 Compatible API\n",
    "\n",
    "LakeFS allows users to leverage the following cloud provided storage services as its underlying data store:\n",
    "- AWS S3\n",
    "- S3 Compatible Stores like MinIO or Ceph\n",
    "- Azure Blob Storage (ABS)\n",
    "- Google Cloud Storage (GCS)\n",
    "- Local Storage\n",
    "\n",
    "\n",
    "LakeFS provides direct integration with popular data frameworks \n",
    "- Spark\n",
    "- Hive\n",
    "- dbt\n",
    "- Trino\n",
    "- and many others\n",
    "\n",
    "[Event hooks](https://docs.lakefs.io/setup/hooks.html) that support CI/CD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd68f68-2d93-464e-94fe-87dd6f63f5dd",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "LakeFS impliments the classic client/server model. As such there is a centralized server(s) that take requests and serve data to clients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88246412-fdef-4efc-9022-c8cc0c7fed2c",
   "metadata": {},
   "source": [
    "## LakeFS Server Architecture\n",
    "\n",
    "lakeFS is distributed as a single binary. The binary, is also referred to as \"the server\". The server encapsulates several logical services including:\n",
    "- UI\n",
    "- OpenAPI Gateway\n",
    "- S3 Gateway\n",
    "- Authentication/Authorization\n",
    "- Graveler\n",
    "- Storage Adapter\n",
    "- Hooks Enginer\n",
    "\n",
    "The [documentation](https://docs.lakefs.io/understand/architecture.html) provides the following documentation:\n",
    "\n",
    "<center><img src=\"images/lakefs-architecture.png\" style=\"width:800px\"></center>\n",
    "\n",
    "\n",
    "Note: The server itself is stateless, meaning you can easily add more instances to handle a bigger load.\n",
    "\n",
    "\n",
    "### Server Components\n",
    "\n",
    "- **S3 Gateway** - LakeFS implements a compatible subset of the S3 API to ensure most data systems can use lakeFS as a drop-in replacement for S3.\n",
    "\n",
    "- **OpenAPI Server** - The Swagger (OpenAPI) server exposes the full set of lakeFS operations including basic CRUD operations against repositories and objects, as well as versioning related operations such as branching, merging, committing and reverting changes to data.\n",
    "\n",
    "- **Storage Adapter** - an abstraction layer for communicating with any underlying object store. Its implementations allow compatibility with many types of underlying storage such as S3, GCS, Azure Blob Storage, or non-production usages such as the local storage adapter.\n",
    "\n",
    "- **Graveler** - handles lakeFS versioning by translating lakeFS addresses to the actual stored objects.\n",
    "\n",
    "- **Authentication & Authorization Service**\n",
    "\n",
    "- **Hooks Engine** - enables CI/CD for data by triggering user defined actions (hooks) that will run during commit/merge\n",
    "\n",
    "- **UI** - a simple browser-based client that uses the OpenAPI server to provides access to repositories, branches, commits and objects in the system.\n",
    "\n",
    "\n",
    "The official documentation can be found [here](https://docs.lakefs.io/understand/architecture.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad022c9-a6bc-46ef-889b-07a312aefc24",
   "metadata": {},
   "source": [
    "## LakeFS Client Architecure\n",
    "As the diagram above indicates our applications will need a client or api to interact with LakeFS.\n",
    "\n",
    "The following clients / apis exist:\n",
    "- The [LakeFS API](https://docs.lakefs.io/reference/api.html) - The rest API\n",
    "- The [Python API](https://docs.lakefs.io/integrations/python.html) - A python library which provides an OOP interface for interacting with the API. Also see [here](https://pydocs.lakefs.io/)\n",
    "- The [Spark Client](https://docs.lakefs.io/reference/spark-client.html) - A library which allows us to interact with LakeFS metadata using spark objects (like dataframes).\n",
    "- The [S3A Gateway](https://docs.lakefs.io/integrations/spark.html#access-lakefs-using-the-s3a-gateway) - This is the S3-compatible endpoint that the lakeFS server provides which allows spark to access objects using the lakeFS S3 path convention and `s3a://...` URIs.\n",
    "- The [lakeFS-specific Hadoop FileSystem]() - To use this mode, you configure the Spark application to perform metadata operations on the lakeFS server and all data operations directly through the same underlying object store that lakeFS uses which significantly increases application scalability and performance by reducing the load on the lakeFS server and reducing the number of hops. In this case one uses `lakefs://repo/ref/path/to/data` URIs to read and write data on lakeFS rather than `s3a://...` URIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29dbcd4-c9c3-41f1-ad13-f4b8a46827e9",
   "metadata": {},
   "source": [
    "## Integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef0bea-3a0b-4041-904a-14bb42333888",
   "metadata": {},
   "source": [
    "### LakeFS and Spark Integration\n",
    "We have two options for getting data from lakefs to spark.\n",
    "1. Through LakeFS' S3 Gateway - Client requests data from the lakefs server using a lakefs repository style url, the server grabs it from the real storage backend path and returns the info to the client.\n",
    "2. LakeFS Hadoop Filesystem - Client requests metadata from the lakefs server and data from the underlying storage backend (s3)\n",
    "\n",
    "\n",
    "#### LakeFS S3 Gateway (LakeFS S3A Filesystem)\n",
    "\n",
    "With this setup, distinguishing between data and metadata operations is done entirely on the lakeFS server. Spark apps read from a lakeFS repository using the S3A filesystem which accesses the lakeFS server via the S3 Gateway. The consequence of this is data throughput becomes dependent on the lakeFS server’s throughput.\n",
    "\n",
    "<center><img src=\"images/s3a-filesystem-data-access.png\" style=\"width:600px\"></center>\n",
    "\n",
    "Comparing this diagram to the one below makes it clear how we are able to get these performance gains with the new lakeFS Hadoop FileSystem.\n",
    "\n",
    "\n",
    "#### LakeFS Hadoop Filesystem\n",
    "\n",
    "**Note**: The lakeFS FileSystem currently only supports Spark with Hadoop Apache 2.7. But support for Hadoop 3 is on the [roadmap](https://docs.lakefs.io/understand/roadmap.html#hadoop-3-support-in-all-lakefs-clients-high-priority).\n",
    "\n",
    "I was curious how this functionality worked so I did some digging. In the [documentation about the spark integration](https://docs.lakefs.io/integrations/spark.html#two-tiered-spark-support) and this article about the [LakeFS Hadoop filesystem](https://lakefs.io/advancing-lakefs-version-data-at-scale-with-spark/) I found some helpful information to explain how this integration works. \n",
    "\n",
    "The LakeFS team has built and released the \"LakeFS Hadoop Filesystem\" which they explain as a \"native Hadoop FileSystem implementation\". What this means is that the LakeFS team have written code for a spark storage adaptor that makes lakefs look like a hadoop filesystem. When we use spark to write data, we can channel spark's write operation through this adaptor. And this is where the magic happens. The storage adaptor allows us to offload the data intensive portions of the read/write to the backend filesystem rather than routing it through the lakefs server as an intermediary. This potentially elminates bottlenecks and reduces latency. This adaptor contains logic to break things down into metadata and data related requests. The metadata requests (like translating a lakefs path to the path on the underlying datastore) still go through the lakefs server, but the access to the data can me made directly to the underlying datastore rather than lakefs. The following image explains the concept:\n",
    "\n",
    "<center><img src=\"images/lakefs-hadoop-filesystem-architecture.png\" style=\"width:600px\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5bc79-f45b-4b5c-9c23-507ffc73ea14",
   "metadata": {},
   "source": [
    "### Deltalake\n",
    "\n",
    "As deltalake sits on top of a filesystem or datalake, it can be supported by lakefs. As deltalake is accessed through spark, one would need to configure spark to spreak to lakefs and deltalake as one normally would.\n",
    "\n",
    "But there is one major limitation to be aware of:\n",
    "\n",
    "As noted in the [documentation](https://www.databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html), a limiting factor to this integration is the detla table's deltalog. The [Delta Lake transaction log](https://www.databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html) (also known as the DeltaLog) is an ordered record of every transaction that has ever been performed on a Delta Lake table since its inception. As such, this exposes us to one of the classical problems of parallel timelines: When merging branches, the human would need to reconcile which events occurred and in which order. One would need to manually audit the transaction log to resolve conflicting sets of transactions. \n",
    "\n",
    "For this reason, the lakefs team reccomends that one only write to a single branch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29232df2-7dcf-4df0-9322-10d32c77b1ad",
   "metadata": {},
   "source": [
    "# Deployment Options\n",
    "\n",
    "According to the documentation there are many [ways](https://docs.lakefs.io/understand/architecture.html#ways-to-deploy-lakefs) to deploy the lakefs server. We can use a public cloud provider like AWS, GCP, or Azure. We can also use a self-hosted solution using Bare Metal, Docker, or Kubernetes.\n",
    "\n",
    "## Self-hosted Options\n",
    "\n",
    "For self-hosted solutions a user can choose between:\n",
    "- [Running](https://docs.lakefs.io/quickstart/more_quickstart_options.html#using-the-binary) the provided [Binaries](https://github.com/treeverse/lakeFS/releases)\n",
    "- Running a [Docker Container](https://hub.docker.com/r/treeverse/lakefs)\n",
    "- Deploying a [Helm Chart](https://artifacthub.io/packages/helm/lakefs/lakefs) in kubernetes\n",
    "\n",
    "Otherwise, there are also cloud hosted options for running lakeFS on K8S, ECS, Google Compute Engine and more.\n",
    "\n",
    "In this [notebook](Basic%20Initial%20Setup.ipynb) I perform a basic setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7bc778-515c-4eb1-874f-8628148b4b5a",
   "metadata": {},
   "source": [
    "# How Does LakeFS Versioning Work\n",
    "\n",
    "As mentioned earlier, LakeFS is an overlay file system. Like git, it does some magic to manage the different versions of files and folders contained in our repository.\n",
    "\n",
    "As with git, in LakeFS, our largest container is the repository. The repository is made up of branches and commits. The branches and commits point to specific versions of files.\n",
    "\n",
    "As such, when we want to access a particular file from LakeFS we need to give the server a few pices of information so it can lookup and serve our data. We need to not only know it's relative path, but also the name of the repository which holds the file, and the branch or commit coresponding to the desired version of that file.\n",
    "\n",
    "We will see that the LakeFS API builds this information into the path of a given file. As such, when we refer to data we would use paths resembling the following:\n",
    "\n",
    "- Repositories: `lakefs://\\<repo-name>`\n",
    "- Commits: `lakefs://\\<repo-name>@\\<commit-id>`\n",
    "- Branches: `lakefs://\\<repo-name>@\\<branch-id>`\n",
    "- Files (objects): `lakefs://\\<repo-name>@\\<branch-id>/\\<object path>`\n",
    "\n",
    "And thus reading a file might resemble this\n",
    "\n",
    "```python\n",
    "df = spark.read.parquet('lakefs://<repo-name>@<branch-id>\\<object path>')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4dc26a-5b0e-4c04-8370-dc80f4f2b9c3",
   "metadata": {},
   "source": [
    "## What Are LakeFS Commits\n",
    "A LakeFS commit maps meta data and a LakeFS file path to an actual file path. In the documentation this is sometimes specified as mapping names to objects or keys to values. As we will see, if a file path changes, the two different keys in two commits will point to the same underlying file. But if the data changes, the two same keys will point to different files on the underlying filesystem. \n",
    "\n",
    "<center><img src='images/commit-example.png'></center>\n",
    "\n",
    "The example above is a simplified representation of commits. In this section we go deeper down the worm hole. As we will see, LakeFS commits Are stored as a B+ Tree of SSTables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb623ad-e534-4969-95eb-c011383caaab",
   "metadata": {},
   "source": [
    "### What are SSTables\n",
    "TL;DR; In short an SSTable is a tree based key value store\n",
    "\n",
    "SSTable refers to a data structure and the coresponding persistent file format. It is used by a number of NoSQL databases, specifically those which impliment Log Structured Merge Tree (LSM) based distributed database systems and key-value stores (like ScyllaDB, Apache Cassandra, and BigTable).\n",
    "\n",
    "An SSTable provides a persistent, ordered, immutable map from keys to values, where both keys and values are arbitrary byte strings. Like any data structure, SSTable implimentation provide operations for accessing an managing the data. For example, methods to look up the value associated with a specified key or to iterate over all key/value pairs in a specified key range.\n",
    "\n",
    "An SSTable is partitioned into blocks and provides a block index. The index is loaded into memory when the SStable file is opened and provides a lookup to locate a given block without excessive disk seeks (i.e. searching the disk). Additionally is resources allow the entire SStable can be loaded into memory avoiding the use of the disk in a search.\n",
    "\n",
    "A helpful conversation on the topic can be found in [this article](https://stackoverflow.com/questions/2576012/what-is-an-sstable) or [this article](http://distributeddatastore.blogspot.com/2013/08/cassandra-sstable-storage-format.html) or [this one](https://en.wikipedia.org/wiki/Log-structured_merge-tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d168638-aecf-4c02-abcb-ac4a65d5ed1f",
   "metadata": {},
   "source": [
    "### Commits Are stored as a B+ Tree of SSTables (ie. Gravelers)\n",
    "\n",
    "Each lakeFS commit is represented as a tree structue (for speed). Specifically a B+ tree with height 2. The way it works is that the namespace of keys, ie. the keyspace, (the list of file paths for all files in the repo) is sorted and split up into blocks or ranges. Each range is mapped in its own SStable in level 2. Each range, because it is sorted, has a start key and and end key indicating the boundaries of the range (ranges do not overlap). The root of the tree (level 1) contains a sorted list of all the last keys from all the ranges and maps them to the coresponding range. With this structure, we can peform a faster lookup of a file in the repository. We do a seek on the root, get the range, and then seek on the range. This is faster than potentially seeking the entire table.\n",
    "\n",
    "We can see an example commit below:\n",
    "\n",
    "<center><img src='images/lakefs-commit-btree.png'</img></center>\n",
    "\n",
    "The commit is stored in a standardized format called “Graveler”. Thus the SSTable files are referred to as graveler files. To be even morespecific, LakeFS uses the RocksDB SSTable file format and its implementation using the Pebble SSTable library from CockroachDB.\n",
    "\n",
    "More information on this file format can be found [here](https://docs.lakefs.io/understand/versioning-internals.html) or [here](https://lakefs.io/concrete-graveler-committing-data-to-pebbledb-sstables) or [here](https://lakefs.io/concrete-graveler-splitting-for-reuse/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225339ca-1c3b-4e82-90aa-21ccac0cccc3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d01bb-9471-4fe7-989e-21a12b2d288c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131371d5-6c64-4178-b7d6-6073c6dba4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
