{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d52eefb-abd7-4393-a37a-f055f1c5a548",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "[LakeFS](https://docs.lakefs.io/) is a storage solution which provides version control for data lakes. It sits on top of a data lake as an \"overlay filesystem\" meaning it provides an api which maps version info to phsical data stored in the underlying data store.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62604f01-65b7-4a4d-91b4-e7847a9845ed",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "A git-like interface\n",
    "\n",
    "No data duplication\n",
    "\n",
    "An S3 Compatible API\n",
    "\n",
    "LakeFS allows users to leverage the following cloud provided storage services as its underlying data store:\n",
    "- AWS S3\n",
    "- S3 Compatible Stores like MinIO or Ceph\n",
    "- Azure Blob Storage (ABS)\n",
    "- Google Cloud Storage (GCS)\n",
    "- Local Storage\n",
    "\n",
    "\n",
    "LakeFS provides direct integration with popular data frameworks \n",
    "- Spark\n",
    "- Hive\n",
    "- dbt\n",
    "- Trino\n",
    "- and many others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88246412-fdef-4efc-9022-c8cc0c7fed2c",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "In the simplest terms, LakeFS stores data and some metadata on the underlying datastore while other metadata (mostly associated with the version information) is stored in a PostreSQL database. But it has a number of other components to provide user comforts.\n",
    "\n",
    "## Components\n",
    "\n",
    "- **S3 Gateway** - LakeFS implements a compatible subset of the S3 API to ensure most data systems can use lakeFS as a drop-in replacement for S3.\n",
    "\n",
    "- **OpenAPI Server** - The Swagger (OpenAPI) server exposes the full set of lakeFS operations including basic CRUD operations against repositories and objects, as well as versioning related operations such as branching, merging, committing and reverting changes to data.\n",
    "\n",
    "- **Storage Adapter** - an abstraction layer for communicating with any underlying object store.\n",
    "\n",
    "- **Graveler** - handles lakeFS versioning by translating lakeFS addresses to the actual stored objects.\n",
    "\n",
    "- **Authentication & Authorization Service**\n",
    "\n",
    "- **Hooks Engine** - enables CI/CD for data by triggering user defined actions (hooks) that will run during commit/merge\n",
    "\n",
    "- **UI** - a simple browser-based client that uses the OpenAPI server to provides access to repositories, branches, commits and objects in the system.\n",
    "\n",
    "\n",
    "The official documentation can be found [here](https://docs.lakefs.io/understand/architecture.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29232df2-7dcf-4df0-9322-10d32c77b1ad",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "https://docs.lakefs.io/understand/architecture.html#ways-to-deploy-lakefs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895cc4d4-0ad8-469d-a02c-b6e9e7888f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c0784-1755-4a2d-bfbd-e9665d78c0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b7bc778-515c-4eb1-874f-8628148b4b5a",
   "metadata": {},
   "source": [
    "# How Does LakeFS Versioning Work\n",
    "\n",
    "With LakeFS, like git, our largest container is the repository. The repository is made up of branches and commits. And the branches and the commits point to files.\n",
    "\n",
    "As such, when we want to access a particular file from we need to not only know it's relative path, but also the name of the repository which holds the file, and the branch or commit coresponding to the desired version of that file.\n",
    "\n",
    "We will see that the LakeFS API builds this information into the path of a given file. As such, when we refer to data we would use paths resembling the following:\n",
    "\n",
    "- Repositories: `lakefs://\\<repo-name>`\n",
    "- Commits: `lakefs://\\<repo-name>@\\<commit-id>`\n",
    "- Branches: `lakefs://\\<repo-name>@\\<branch-id>`\n",
    "- Files (objects): `lakefs://\\<repo-name>@\\<branch-id>/\\<object path>`\n",
    "\n",
    "And thus reading a file might resemble this\n",
    "\n",
    "```python\n",
    "df = spark.read.parquet('lakefs://<repo-name>@<branch-id>\\<object path>')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4dc26a-5b0e-4c04-8370-dc80f4f2b9c3",
   "metadata": {},
   "source": [
    "## What Are LakeFS Commits\n",
    "A LakeFS commit maps meta data and a LakeFS file path to an actual file path. In the documentation this is sometimes specified as mapping names to objects or keys to values. As we will see, if a file path changes, the two different keys in two commits will point to the same underlying file. But if the data changes, the two same keys will point to different files on the underlying filesystem. \n",
    "\n",
    "<center><img src='images/commit-example.png'></center>\n",
    "\n",
    "The example above is a simplified representation of commits. In this section we go deeper down the worm hole. As we will see, LakeFS commits Are stored as a B+ Tree of SSTables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb623ad-e534-4969-95eb-c011383caaab",
   "metadata": {},
   "source": [
    "### What are SSTables\n",
    "TL;DR; In short an SSTable is a tree based key value store\n",
    "\n",
    "SSTable refers to a data structure and the coresponding persistent file format. It is used by a number of NoSQL databases, specifically those which impliment Log Structured Merge Tree (LSM) based distributed database systems and key-value stores (like ScyllaDB, Apache Cassandra, and BigTable).\n",
    "\n",
    "An SSTable provides a persistent, ordered, immutable map from keys to values, where both keys and values are arbitrary byte strings. Like any data structure, SSTable implimentation provide operations for accessing an managing the data. For example, methods to look up the value associated with a specified key or to iterate over all key/value pairs in a specified key range.\n",
    "\n",
    "An SSTable is partitioned into blocks and provides a block index. The index is loaded into memory when the SStable file is opened and provides a lookup to locate a given block without excessive disk seeks (i.e. searching the disk). Additionally is resources allow the entire SStable can be loaded into memory avoiding the use of the disk in a search.\n",
    "\n",
    "A helpful conversation on the topic can be found in [this article](https://stackoverflow.com/questions/2576012/what-is-an-sstable) or [this article](http://distributeddatastore.blogspot.com/2013/08/cassandra-sstable-storage-format.html) or [this one](https://en.wikipedia.org/wiki/Log-structured_merge-tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d168638-aecf-4c02-abcb-ac4a65d5ed1f",
   "metadata": {},
   "source": [
    "### Commits Are stored as a B+ Tree of SSTables (ie. Gravelers)\n",
    "\n",
    "Each lakeFS commit is represented as a tree structue (for speed). Specifically a B+ tree with height 2. And this is done for speed. The way it works is that the namespace of keys (the list of file paths) is sorted and split up into blocks or ranges. Each range is mapped in its own SStable in level 2. Each range, because it is sorted, has a start key and and end key indicating the boundaries of the range (ranges do not overlap). The root of the tree (level 1) contains a sorted list of all the last keys from all the ranges and maps them to the coresponding range. With this structure, we can peform a faster lookup of a file in the repository. We do a seek on the root, get the range, and then seek on the range. This is faster than potentially seeking the entire table.\n",
    "\n",
    "We can see an example commit below:\n",
    "\n",
    "<center><img src='images/lakefs-commit-btree.png'</img></center>\n",
    "\n",
    "The commit is stored in a standardized format called “Graveler”. Thus the SSTable files are referred to as graveler files. To be even morespecific, LakeFS uses the RocksDB SSTable file format and its implementation using the Pebble SSTable library from CockroachDB.\n",
    "\n",
    "More information on this file format can be found [here](https://docs.lakefs.io/understand/versioning-internals.html) or [here](https://lakefs.io/concrete-graveler-committing-data-to-pebbledb-sstables) or [here](https://lakefs.io/concrete-graveler-splitting-for-reuse/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225339ca-1c3b-4e82-90aa-21ccac0cccc3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d01bb-9471-4fe7-989e-21a12b2d288c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131371d5-6c64-4178-b7d6-6073c6dba4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
