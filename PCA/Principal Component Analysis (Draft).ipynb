{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook we explore the concept of Principal Component Analysis. This is a popular feature engineering technique used specifically for dimentionality reduction. In short, PCA will try to measure the importance of a feature using a measurement similar to correlation. If you are unfamiliar with correlation it is suggested you read the [notebook on correlation](Correlation.ipynb). As correlation is affected by linear scale, we will see that normalization is a prerequisite transformation for our data. If you are not famliar with normalization it is suggested you reat the [notebook on normalization]()\n",
    "\n",
    "This notebook is broken down into the following sections:\n",
    "1. Loading our data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our libraires\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>QuizAvg</th>\n",
       "      <th>TestAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>181</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>169</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>176</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>181</td>\n",
       "      <td>66</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>169</td>\n",
       "      <td>89</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>150</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>181</td>\n",
       "      <td>98</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31</td>\n",
       "      <td>163</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>160</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ACT  FinalExam  QuizAvg  TestAvg\n",
       "0    33        181       95       89\n",
       "1    31        169       81       89\n",
       "2    21        176       65       68\n",
       "3    25        181       66       90\n",
       "4    29        169       89       81\n",
       "5    24        103       61       57\n",
       "6    25        150       81       76\n",
       "7    29        147       86       76\n",
       "8    36        181       98      102\n",
       "9    26        163       72       70\n",
       "10   31        163       95       81\n",
       "11   29        147       65       67\n",
       "12   23        160       62       68\n",
       "13   26        100       63       56"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our sample data\n",
    "input_file_path = \"data.csv\"\n",
    "delimiter = \",\"\n",
    "df = pandas.read_csv(input_file_path, delimiter=delimiter)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACT          int64\n",
       "FinalExam    int64\n",
       "QuizAvg      int64\n",
       "TestAvg      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Inspect our data\n",
    "While this notebook is about doing PCA, we need to understand if we CAN do PCA using the data. Lets have a look at the data.\n",
    "\n",
    "- We wee that the scores are different and have different units.\n",
    "- We see that the columns may offer redundant information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. ETL the data\n",
    "Now that we know the problems with our data, lets transform it into a format that does not have these problems\n",
    "\n",
    "\n",
    "why standardize??\n",
    "https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Normalize our data\n",
    "Normalization is a way to transform verctors into scalars (numbers with units into just numbers). Normalization is a handy way to convert all the measurements to a common scale. \n",
    "\n",
    "In our example. We need to compare the ACT (which is 1 to 36) and the average test score (which is 1 to 100). Normalization can help us do that.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Normalization_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Choose a normalization method\n",
    "There are many ways to normalize or standardiaze our data. We will not talk about all the approaches here... but there are a few and they all have different affects and implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Normalize using a Standard Score\n",
    "We will use the **standard score** (z-score) because it is simple and well documented.\n",
    "\n",
    "The standard score is the signed fractional number of standard deviations by which the value of an observation or data point is above or below the mean value of what is being observed or measured. Observed values above the mean have positive standard scores, while values below the mean have negative standard scores.\n",
    "\n",
    "$$ z = \\frac{(x-\\mu)}{\\sigma} $$\n",
    "\n",
    "The higher or lower the score, the farther from the mean, and thus the more exceptional a given score is when compared to the sample. This is how we will compare our scores!!\n",
    "\n",
    "If we look at a sample with a normally distributed random variable, we will see the implications of the various scores:\n",
    "\n",
    "![image](Normalization_method_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will calculate some statistics for our columns. We will use these statistics to normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACT           27.714286\n",
       "FinalExam    156.428571\n",
       "QuizAvg       77.071429\n",
       "TestAvg       76.428571\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean of each column in the data frame\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACT           4.158931\n",
       "FinalExam    26.117234\n",
       "QuizAvg      13.747527\n",
       "TestAvg      13.195071\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the standard deviation of each column in the data frame\n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>QuizAvg</th>\n",
       "      <th>TestAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.270931</td>\n",
       "      <td>0.940813</td>\n",
       "      <td>1.304131</td>\n",
       "      <td>0.952737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790038</td>\n",
       "      <td>0.481346</td>\n",
       "      <td>0.285766</td>\n",
       "      <td>0.952737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.614426</td>\n",
       "      <td>0.749368</td>\n",
       "      <td>-0.878080</td>\n",
       "      <td>-0.638767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.652640</td>\n",
       "      <td>0.940813</td>\n",
       "      <td>-0.805340</td>\n",
       "      <td>1.028523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309145</td>\n",
       "      <td>0.481346</td>\n",
       "      <td>0.867689</td>\n",
       "      <td>0.346450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.893087</td>\n",
       "      <td>-2.045721</td>\n",
       "      <td>-1.169041</td>\n",
       "      <td>-1.472411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.652640</td>\n",
       "      <td>-0.246143</td>\n",
       "      <td>0.285766</td>\n",
       "      <td>-0.032480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.309145</td>\n",
       "      <td>-0.361010</td>\n",
       "      <td>0.649467</td>\n",
       "      <td>-0.032480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.992270</td>\n",
       "      <td>0.940813</td>\n",
       "      <td>1.522352</td>\n",
       "      <td>1.937953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.412194</td>\n",
       "      <td>0.251613</td>\n",
       "      <td>-0.368898</td>\n",
       "      <td>-0.487195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.790038</td>\n",
       "      <td>0.251613</td>\n",
       "      <td>1.304131</td>\n",
       "      <td>0.346450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.309145</td>\n",
       "      <td>-0.361010</td>\n",
       "      <td>-0.878080</td>\n",
       "      <td>-0.714553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.133533</td>\n",
       "      <td>0.136746</td>\n",
       "      <td>-1.096301</td>\n",
       "      <td>-0.638767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.412194</td>\n",
       "      <td>-2.160588</td>\n",
       "      <td>-1.023561</td>\n",
       "      <td>-1.548197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACT  FinalExam   QuizAvg   TestAvg\n",
       "0   1.270931   0.940813  1.304131  0.952737\n",
       "1   0.790038   0.481346  0.285766  0.952737\n",
       "2  -1.614426   0.749368 -0.878080 -0.638767\n",
       "3  -0.652640   0.940813 -0.805340  1.028523\n",
       "4   0.309145   0.481346  0.867689  0.346450\n",
       "5  -0.893087  -2.045721 -1.169041 -1.472411\n",
       "6  -0.652640  -0.246143  0.285766 -0.032480\n",
       "7   0.309145  -0.361010  0.649467 -0.032480\n",
       "8   1.992270   0.940813  1.522352  1.937953\n",
       "9  -0.412194   0.251613 -0.368898 -0.487195\n",
       "10  0.790038   0.251613  1.304131  0.346450\n",
       "11  0.309145  -0.361010 -0.878080 -0.714553\n",
       "12 -1.133533   0.136746 -1.096301 -0.638767\n",
       "13 -0.412194  -2.160588 -1.023561 -1.548197"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the standard score of each element in our data frame (on a per-column basis)\n",
    "normalized_df = ((df - df.mean())/df.std())\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Covariance and Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Quick stats recap:\n",
    "\n",
    "In this step we calculate some statistics for our data frame. Lets have a quick recap.\n",
    "\n",
    "$$ \\mu = \\frac{\\sum(x_i)}{n} $$\n",
    "\n",
    "$$  \\sigma^2 = \\frac{\\sum(x_i-\\mu)^2}{n} $$\n",
    "\n",
    "$$ Cov(X,Y) = \\frac{\\sum(x_i-\\mu_X)(y_i - \\mu_Y)}{n} $$\n",
    "\n",
    "$$ \\rho_XY = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y} $$\n",
    "\n",
    "Given the nature of the z-score, we see that multiplying two z-scores of two columns would yield the correlation coefficient. \n",
    "Using matrices, multiplying a column by its transpose, $Z^TZ$, produces the correlation coefficient matrix. \n",
    "\n",
    "$$ z = \\frac{x-\\mu}{\\sigma} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Calculate Covariance and Correlation by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>QuizAvg</th>\n",
       "      <th>TestAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336186</td>\n",
       "      <td>0.827803</td>\n",
       "      <td>0.710275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalExam</th>\n",
       "      <td>0.336186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>0.795847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuizAvg</th>\n",
       "      <td>0.827803</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestAvg</th>\n",
       "      <td>0.710275</td>\n",
       "      <td>0.795847</td>\n",
       "      <td>0.748696</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ACT  FinalExam   QuizAvg   TestAvg\n",
       "ACT        1.000000   0.336186  0.827803  0.710275\n",
       "FinalExam  0.336186   1.000000  0.499949  0.795847\n",
       "QuizAvg    0.827803   0.499949  1.000000  0.748696\n",
       "TestAvg    0.710275   0.795847  0.748696  1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of rows\n",
    "n = normalized_df.shape[0] - 1\n",
    "\n",
    "# Take the transpose of our matrix\n",
    "normalized_transposed_df = normalized_df.T\n",
    "\n",
    "# Calculate correlation by taking the dot product of our transpose and regular matrix\n",
    "#     Remember that the z-score includes the sigma\n",
    "correlation_df = normalized_transposed_df.dot(normalized_df) / n\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Calculate Correlation using built in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33618637, 0.82780343, 0.7102748 ],\n",
       "       [0.33618637, 1.        , 0.49994932, 0.79584684],\n",
       "       [0.82780343, 0.49994932, 1.        , 0.7486962 ],\n",
       "       [0.7102748 , 0.79584684, 0.7486962 , 1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the transpose of our matrix\n",
    "normalized_transposed_df = normalized_df.T\n",
    "\n",
    "# Compute the correlation matrix (a numpy ndarray)\n",
    "correlation_nda = numpy.corrcoef(normalized_transposed_df)\n",
    "correlation_nda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array into a pandas data frame\n",
    "correlation_df = pandas.DataFrame(correlation_nda, columns=df.columns, index=df.columns)\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that QuizAvg and ACT have the highest correlation meaning that they are redundant features. There is only a small benefit to including both because one of them give us most of the information we need to explain the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Decompose correlation matrix into eigenvalues and eigenvectors\n",
    "\n",
    "In German, “eigen” means “specific of” or “characteristic of”. Eigenvectors and eigenvalues are also referred to as characteristic vectors and latent roots or characteristic equation.The set of eigenvalues of a matrix is also called its spectrum.\n",
    "\n",
    "*Encyclopedia of Measurement and Statistics* ~ Abdi\n",
    "\n",
    "## Fundamental Theory of matrix eigenvectors and eigenvalues\n",
    "A (non-vero) vector $v$ of dimension N is an *eigenvector* of a square NxN matrix A if it satisfies the linear equation\n",
    "\n",
    "$$Av = \\lambda v $$\n",
    "\n",
    "where $\\lambda$ is a scalar, termed the *eigenvlue*, which corespondes to the eigenvector $v$.\n",
    "\n",
    "There are multiple possible eigenvectors for the NxN matrix A. The spectral theroy allows us to capture those.\n",
    "\n",
    "## Spectral Theory\n",
    "\n",
    "Let A be square NxN matrix of eigenvectors. Let Q be a square NxN matrix who's i'th column, denoted $q_i$ is an eigenvector of A.\n",
    "\n",
    "$$ A = Q \\Lambda Q^{-1} $$\n",
    "\n",
    "As this is a special case (square matrix) we can say that $Q$ is orthogonal and thus:\n",
    "\n",
    "$$ A = Q \\Lambda Q^T $$\n",
    "\n",
    "We can apply the spectral theory to decompose our square correlation matrix into its canonical form: two square matrices consisting of eigenvalues $\\Lambda$ and eigenvectors $Q$ respectively.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix\n",
    "\n",
    "We really do not need to know how this works (like the theory and all). Lets focus on the application.\n",
    "\n",
    "We can use a builtin numpy function to do the decomposition:\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the decomposition\n",
    "eigen_values_nda, right_eigen_vectors_nda = numpy.linalg.eig(correlation_nda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eigenvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>2.978867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalExam</th>\n",
       "      <td>0.762946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuizAvg</th>\n",
       "      <td>0.083230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestAvg</th>\n",
       "      <td>0.174956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eigenvalues\n",
       "ACT           2.978867\n",
       "FinalExam     0.762946\n",
       "QuizAvg       0.083230\n",
       "TestAvg       0.174956"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at our lamndas\n",
    "eigen_values_df = pandas.DataFrame(eigen_values_nda, index=df.columns, columns=[\"eigenvalues\"])\n",
    "eigen_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>QuizAvg</th>\n",
       "      <th>TestAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>0.488657</td>\n",
       "      <td>0.548902</td>\n",
       "      <td>-0.485805</td>\n",
       "      <td>0.473196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalExam</th>\n",
       "      <td>0.435042</td>\n",
       "      <td>-0.735297</td>\n",
       "      <td>-0.506504</td>\n",
       "      <td>-0.116321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuizAvg</th>\n",
       "      <td>0.521538</td>\n",
       "      <td>0.330721</td>\n",
       "      <td>0.145362</td>\n",
       "      <td>-0.772976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestAvg</th>\n",
       "      <td>0.547678</td>\n",
       "      <td>-0.220610</td>\n",
       "      <td>0.697364</td>\n",
       "      <td>0.406280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ACT  FinalExam   QuizAvg   TestAvg\n",
       "ACT        0.488657   0.548902 -0.485805  0.473196\n",
       "FinalExam  0.435042  -0.735297 -0.506504 -0.116321\n",
       "QuizAvg    0.521538   0.330721  0.145362 -0.772976\n",
       "TestAvg    0.547678  -0.220610  0.697364  0.406280"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at our Qs\n",
    "#    Note: The term right vector just refers to the orientation of rows vs columns\n",
    "#          This is part of the math that we just do not need to worry about\n",
    "right_eigen_vectors_df = pandas.DataFrame(right_eigen_vectors_nda, columns=df.columns, index=df.columns)\n",
    "right_eigen_vectors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Transform normalized data using eigenvectors\n",
    "This explains the reason why we multiply the normalized data Z with P. The fact that the covariance of ZP is the diagonal matrix indicates that there is no linear relationship between variables other than the one with itself. In other words, there is no relationship among the new variables we created and the new variables are independent of one another. Therefore, we have successfully come up with a new set of dataset (a transformed dataset) which does not have any correlation between them and we can select variables based on the variance, which is represented by the eigenvalues.\n",
    "\n",
    "The important thing here is that the total variance of the original dataset is the same as that of the transformed dataset. That is to say, the sum of the entries of the sum of the entries of the diagonal matrix D is the sum of the variance of the Z scores. With the covariance matrix of ZP being D, each vector of ZP represents the variance of the transformed data and by choosing the vectors that correspond to the highest eigenvalues, the variance is maximized. Thus, by selecting the vectors that correspond to highest eigenvalues, we are selecting the new variables that have high fraction of the variance of the transformed dataset divided by the total variance of the original dataset.\n",
    "\n",
    "https://towardsdatascience.com/principal-component-analysis-ceb42ed04d77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>QuizAvg</th>\n",
       "      <th>TestAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.232289</td>\n",
       "      <td>0.226959</td>\n",
       "      <td>-0.239975</td>\n",
       "      <td>-0.129021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.266294</td>\n",
       "      <td>-0.035954</td>\n",
       "      <td>0.078336</td>\n",
       "      <td>0.484040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.270685</td>\n",
       "      <td>-1.586650</td>\n",
       "      <td>-0.168354</td>\n",
       "      <td>-0.431890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.233659</td>\n",
       "      <td>-1.543257</td>\n",
       "      <td>0.440720</td>\n",
       "      <td>0.622113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.002747</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>-0.026258</td>\n",
       "      <td>-0.439651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.742494</td>\n",
       "      <td>0.952199</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.120785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.294750</td>\n",
       "      <td>-0.075573</td>\n",
       "      <td>0.460618</td>\n",
       "      <td>-0.514281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.314946</td>\n",
       "      <td>0.657097</td>\n",
       "      <td>0.104426</td>\n",
       "      <td>-0.326939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.238168</td>\n",
       "      <td>0.477725</td>\n",
       "      <td>0.128371</td>\n",
       "      <td>0.443908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.551179</td>\n",
       "      <td>-0.425786</td>\n",
       "      <td>-0.320573</td>\n",
       "      <td>-0.137105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.365417</td>\n",
       "      <td>0.603516</td>\n",
       "      <td>-0.080075</td>\n",
       "      <td>-0.522731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.855285</td>\n",
       "      <td>0.302378</td>\n",
       "      <td>-0.593274</td>\n",
       "      <td>0.576706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.416020</td>\n",
       "      <td>-0.944398</td>\n",
       "      <td>-0.123400</td>\n",
       "      <td>0.035607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.523106</td>\n",
       "      <td>1.365455</td>\n",
       "      <td>0.066148</td>\n",
       "      <td>0.218459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACT  FinalExam   QuizAvg   TestAvg\n",
       "0   2.232289   0.226959 -0.239975 -0.129021\n",
       "1   1.266294  -0.035954  0.078336  0.484040\n",
       "2  -1.270685  -1.586650 -0.168354 -0.431890\n",
       "3   0.233659  -1.543257  0.440720  0.622113\n",
       "4   1.002747   0.026290 -0.026258 -0.439651\n",
       "5  -2.742494   0.952199  0.273291  0.120785\n",
       "6  -0.294750  -0.075573  0.460618 -0.514281\n",
       "7   0.314946   0.657097  0.104426 -0.326939\n",
       "8   3.238168   0.477725  0.128371  0.443908\n",
       "9  -0.551179  -0.425786 -0.320573 -0.137105\n",
       "10  1.365417   0.603516 -0.080075 -0.522731\n",
       "11 -0.855285   0.302378 -0.593274  0.576706\n",
       "12 -1.416020  -0.944398 -0.123400  0.035607\n",
       "13 -2.523106   1.365455  0.066148  0.218459"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_transformed_df = pandas.DataFrame(numpy.dot(normalized_df, right_eigen_vectors_df), columns=df.columns)\n",
    "normalized_transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7. Sort our eigenvalues and eigenvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eigenvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>2.978867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalExam</th>\n",
       "      <td>0.762946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuizAvg</th>\n",
       "      <td>0.083230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestAvg</th>\n",
       "      <td>0.174956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eigenvalues\n",
       "ACT           2.978867\n",
       "FinalExam     0.762946\n",
       "QuizAvg       0.083230\n",
       "TestAvg       0.174956"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall our eigenvalues\n",
    "eigen_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2.9788674250300993: 0,\n",
       " 0.7629463524576332: 1,\n",
       " 0.08322983246250416: 2,\n",
       " 0.1749563900497669: 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping of the eigenvalue's value to its position\n",
    "# We will use this mapping to reorder the eigenvector later\n",
    "mapping = {}\n",
    "for x in range(0, eigen_values_nda.size):\n",
    "    mapping[eigen_values_nda[x]] = x\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.97886743, 0.76294635, 0.17495639, 0.08322983])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the eigenvalues from largest to smallest\n",
    "sorted_eigen_values_nda = eigen_values_nda.astype(float)\n",
    "sorted_eigen_values_nda.sort()\n",
    "sorted_eigen_values_nda = sorted_eigen_values_nda[::-1]\n",
    "sorted_eigen_values_nda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACT', 'FinalExam', 'QuizAvg', 'TestAvg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall the original column name order\n",
    "original_order_column_names = df.columns.tolist()\n",
    "original_order_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACT', 'FinalExam', 'TestAvg', 'QuizAvg']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder the columns in the dataframe to match the eigenvalue order\n",
    "sorted_column_names = []\n",
    "for eigenvalue in sorted_eigen_values_nda:\n",
    "    original_order = mapping[eigenvalue]\n",
    "    column_name = original_order_column_names[original_order]\n",
    "    sorted_column_names.append(column_name)\n",
    "sorted_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>TestAvg</th>\n",
       "      <th>QuizAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>0.488657</td>\n",
       "      <td>0.548902</td>\n",
       "      <td>0.473196</td>\n",
       "      <td>-0.485805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalExam</th>\n",
       "      <td>0.435042</td>\n",
       "      <td>-0.735297</td>\n",
       "      <td>-0.116321</td>\n",
       "      <td>-0.506504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuizAvg</th>\n",
       "      <td>0.521538</td>\n",
       "      <td>0.330721</td>\n",
       "      <td>-0.772976</td>\n",
       "      <td>0.145362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestAvg</th>\n",
       "      <td>0.547678</td>\n",
       "      <td>-0.220610</td>\n",
       "      <td>0.406280</td>\n",
       "      <td>0.697364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ACT  FinalExam   TestAvg   QuizAvg\n",
       "ACT        0.488657   0.548902  0.473196 -0.485805\n",
       "FinalExam  0.435042  -0.735297 -0.116321 -0.506504\n",
       "QuizAvg    0.521538   0.330721 -0.772976  0.145362\n",
       "TestAvg    0.547678  -0.220610  0.406280  0.697364"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DF with the eigenvectors in sorted order\n",
    "sorted_right_eigen_vectors_df = right_eigen_vectors_df[sorted_column_names]\n",
    "sorted_right_eigen_vectors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8. Select Principal Components\n",
    "\n",
    "There are a few methods for doing this:\n",
    "1. Guess/Trial and Error\n",
    "\n",
    "    Basically... just pick the ones with the highest eigenvalues and then run the model. Rinse and repeat until you find the sweet spot.\n",
    "    \n",
    "\n",
    "2. Arbitrarily set a variance threshold\n",
    "\n",
    "    Pick a threshold, and add features until you hit that threshold. (For example, if you want to explain 80% of the total variability possibly explained by your model, add features with the largest explained proportion of variance until your proportion of variance explained hits or exceeds 80%.)\n",
    "    \n",
    "\n",
    "3. Scree Plot & Find the Elbow\n",
    "\n",
    "    This is closely related to Method 2. Calculate the proportion of variance explained for each feature, sort features by proportion of variance explained and plot the cumulative proportion of variance explained as you keep more features. (This plot is called a scree plot, shown below.) One can pick how many features to include by identifying the point where adding a new feature has a significant drop in variance explained relative to the previous feature, and choosing features up until that point. (I call this the “find the elbow” method, as looking at the “bend” or “elbow” in the scree plot determines where the biggest drop in proportion of variance explained occurs.)\n",
    "\n",
    "https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2. Method 2: Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.97886743, 0.76294635, 0.17495639, 0.08322983])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review our eigenvalues\n",
    "sorted_eigen_values_nda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0000000000000036"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the total variance explained by the eigenvalues\n",
    "total_variance_explained_by_eigenvalues = sum(sorted_eigen_values_nda)\n",
    "total_variance_explained_by_eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature ACT accounted for 74.47168562575241% of the total variance.\n",
      "The feature FinalExam accounted for 19.073658811440815% of the total variance.\n",
      "The feature TestAvg accounted for 4.3739097512441685% of the total variance.\n",
      "The feature QuizAvg accounted for 2.0807458115626023% of the total variance.\n"
     ]
    }
   ],
   "source": [
    "# Determine the variance explained by each principal component\n",
    "variance_map = {}\n",
    "n = sorted_eigen_values_nda.size\n",
    "for x in range(0,n):\n",
    "    feature_name = sorted_column_names[x]\n",
    "    feature_eigenvalue = sorted_eigen_values_nda[x]\n",
    "    feature_percentage = feature_eigenvalue / total_variance_explained_by_eigenvalues\n",
    "    variance_map[feature_name] = feature_percentage\n",
    "    print(\"The feature {0} accounted for {1}% of the total variance.\".format(feature_name, feature_percentage*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our variance threshold to 90%\n",
    "variance_threshold = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our feature set is:\n",
      "['ACT', 'FinalExam']\n",
      "The percentage of variance explained is:\n",
      "0.9354534443719322\n"
     ]
    }
   ],
   "source": [
    "# Select our PCAs\n",
    "feature_set = []\n",
    "variance_explained_by_feature_set = 0\n",
    "for x in range(0,sorted_eigen_values_nda.size):\n",
    "    if variance_explained_by_feature_set >= variance_threshold:\n",
    "        break\n",
    "    feature_name = sorted_column_names[x]\n",
    "    feature_set.append(feature_name)\n",
    "    feature_percentage = variance_map[feature_name]\n",
    "    variance_explained_by_feature_set += feature_percentage\n",
    "print(\"Our feature set is:\")\n",
    "print(feature_set)\n",
    "print(\"The percentage of variance explained is:\")\n",
    "print(variance_explained_by_feature_set)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3. Method 3: Scree Plot & Find the Elbow\n",
    "This is closely related to Method 2. Calculate the proportion of variance explained for each feature, sort features by proportion of variance explained and plot the cumulative proportion of variance explained as you keep more features. (This plot is called a scree plot, shown below.) One can pick how many features to include by identifying the point where adding a new feature has a significant drop in variance explained relative to the previous feature, and choosing features up until that point. (I call this the “find the elbow” method, as looking at the “bend” or “elbow” in the scree plot determines where the biggest drop in proportion of variance explained occurs.)\n",
    "\n",
    "We need to write some code to render the Scree Plot and allow us to find the elbow visually. There are methods for finding the elbow mathematically, we will not cover those methods here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
