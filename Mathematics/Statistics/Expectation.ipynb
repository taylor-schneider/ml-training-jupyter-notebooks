{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a21afb-dcab-41fc-bc62-0c83063f66f0",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook we discuss expectation. Expectation is a precursor to a number of statistical topics includeing mean, variance, correltaion, etc. A basic understanding of probability is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0806361-169f-4cda-9338-97bf05979662",
   "metadata": {},
   "source": [
    "# Definition\n",
    "\n",
    "The expected value $\\mathbb{E}$ is expressed as the weighted average of the values observed from a random variable $X$.\n",
    "\n",
    "The calculation has several notations which include use of the expected value operator $\\mathbb{E}$ or the expansion of the operator such that the equation usses summation or integral notrations.\n",
    "\n",
    "Recall that summations and integrals in the context of probability are an infinite sum. We will see later that the convergence of this infinite sum is an important property.\n",
    "\n",
    "## Discrete Variables\n",
    "\n",
    "$$ \\mathbb{E}\\left[ X \\right] = \\sum x_i f_X$$\n",
    "\n",
    "Where $f_X$ is the probability mass function of $X$ defined fully as $f_X := f_X(x_i)$.\n",
    "\n",
    "## Continuous Variables\n",
    "\n",
    "$$ \\mathbb{E}\\left[ X \\right] = \\int_i f_X dx $$\n",
    "\n",
    "## Constant Variables\n",
    "\n",
    "In both the discrete and continuous case we see that if $X$ is a constanct such that $x_i = c, \\ \\forall i$ we have:\n",
    "\n",
    "$$ \\mathbb{E}[c] = c $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23041a00-1e55-4032-9e8d-2fd4a49b25c0",
   "metadata": {},
   "source": [
    "# A Note On Implications Of Sample Statistics\n",
    "It is often the case that sample statistics or population parameters will need to be calculated. The formulas in the definition section will still apply and will see derevations of expanded equations for different distributions in the following examples sections.\n",
    "\n",
    "It is worth noting that it is often the case that observations in an experiment setting are regarded as equiprobable independent realizations which is why the formulas used resemble those of the uniform distributions (we will see more on this later). But its important to note that when you see an arethmetic mean being used as the expected value, we have made that assumption.\n",
    "\n",
    "For example we may encounter an arithmetic mean as the sample mean:\n",
    "\n",
    "$$ \\mathbb{E}[X] = \\frac{1}{n} \\sum x_i \\ \\ \\rightarrow f_X = \\frac{1}{n} \\ \\ \\Rightarrow X \\sim \\mathcal{U}(0,n), \\ |x| = n $$\n",
    "\n",
    "$$ \\mathbb{E} \\left[ (X - \\mu)^2 \\right] = \\frac{1}{n} \\sum (X - \\mu)^2 \\ \\ \\rightarrow f_X = \\frac{1}{n} \\ \\ \\Rightarrow X \\sim \\mathcal{U}(0,n), \\ |x| = n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846b0aa-b390-47bd-bb7e-cbf7a890cc59",
   "metadata": {},
   "source": [
    "# Series Expansions\n",
    "\n",
    "Sereis expansions are a technique used to approximate a given value. The basic theory is that a given value can be expressed as an infinite series. If we can calculate a few of the terms in the infinite series we can get an approximation that is close enough to the desired value.\n",
    "\n",
    "There are a number of series that can be selected to perform the approximation. Wikipedia page has a [list of such functions](https://en.wikipedia.org/wiki/List_of_mathematical_series). \n",
    "\n",
    "The selection of the series depends on the structure of the function or variable being approximated.\n",
    "\n",
    "<center>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>Series Name</th>\n",
    "            <th>Value</th>\n",
    "            <th>Series</th>\n",
    "            <th>Summation Notation</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Exponential</td>\n",
    "            <td>$$e^x$$</td>\n",
    "            <td>$$1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots$$</td>\n",
    "            <td>$$\\sum\\frac{x^n}{n!}$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Geometric</td>\n",
    "            <td>$$\\frac{1}{1 - x}$$</td>\n",
    "            <td>$$1 + x + x^2 + x^3 + \\cdots $$</td>\n",
    "            <td>$$\\sum x^n$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Sinusoidal</td>\n",
    "            <td>$$ sin(x) $$</td>\n",
    "            <td>$$ x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots $$</td>\n",
    "            <td>$$ \\sum (-1)^n \\frac{x^{2n+1}}{(2n + 1)!}$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</center>\n",
    "\n",
    "https://bookdown.org/probability/beta/moment-generating-functions.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_mathematical_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b200ca-50dd-4976-829f-4e3acb67cc22",
   "metadata": {},
   "source": [
    "## Exponential Series Expansion Example\n",
    "Let's look at an example, assume we want to approximate $e^2 = 7.389056...$ using the exponential series. We see the expansion below. Notice the accuracy improves with each additional term in the series.\n",
    "\n",
    "<center><img src='images/taylor_series_expansion.png' height='300px' width='300px'></center>\n",
    "\n",
    "https://www.mathsisfun.com/algebra/taylor-series.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cce148-47d2-430d-82cd-a8554e156ca6",
   "metadata": {},
   "source": [
    "# Characteristic Function\n",
    "https://www.randomservices.org/random/expect/Generating.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29207f90-efb2-45fd-b7ac-395eef07a056",
   "metadata": {},
   "source": [
    "# Connection With Moments\n",
    "In the field of descriptive statistics, we use statistics to describe the shape and behavior of distributions and random variables which follow the distribution respectively. Another word for these types of descriptive statistics are [moments](https://en.wikipedia.org/wiki/Moment_(mathematics), and said another way, moments describe the shape of the distribution function's graph mathematically.\n",
    "\n",
    "The [method of moments](https://en.wikipedia.org/wiki/Method_of_moments_(statistics)) is an attempt to estimate population parameters (moments) using empiracle sample statistics (parameters, moments).\n",
    "\n",
    "As we will see there are two types of moments that one can persue for a (frequency) distirbution: raw moments and central moments.\n",
    "\n",
    "## Definition Of Moment\n",
    "\n",
    "### Generic Moment\n",
    "The $n^{th}$ moment of a variable/function $X$ about a point $c$ is denoted as $\\mu_n$ and expressed as:\n",
    "\n",
    "$$ \\mu_n := \\mathbb{E} \\left[ (X - c)^n \\right] $$\n",
    "\n",
    "In some contexts we may also see it expressed as:\n",
    "\n",
    "$$ \\mu_n := \\mathbb{E}[X^n] $$\n",
    "\n",
    "I tend to shy away from this notation as there is a high chance of misinterpretation when taken our of context mistakenly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb25b60-d2c4-43fb-a28b-04eca0e639c7",
   "metadata": {},
   "source": [
    "### Raw Moments\n",
    "Raw moments are defined as moments which vary around the origin (ie. $c=0$).\n",
    "\n",
    "$$ \\mu_n := \\mathbb{E} \\left[ (X - 0)^n \\right] = \\mathbb{E} \\left[ X^n \\right] $$\n",
    "\n",
    "The mean is a common raw moment of a distribution. Often denoted as $\\mu$ or $\\bar x$, the mean is the first raw moment $\\mu_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced8510-ec5b-4cf2-a9b9-5e93e8465928",
   "metadata": {},
   "source": [
    "### Central Moments\n",
    "Central moments $\\bar \\mu_n$ are those which are tied to the distribution's first central moment ( its mean; $\\mu_1$) as with central moments.\n",
    "\n",
    "As such we will define them as:\n",
    "\n",
    "$$ \\bar \\mu_n := \\mathbb{E} \\left[ (x - \\mu_1)^n \\right] \\ $$\n",
    "\n",
    "The variance is a common central moment of a distribution. Often denoted as $\\sigma$, the variance is the second central moment $\\bar \\mu_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddce72-e8d9-4801-9711-5bd915791780",
   "metadata": {},
   "source": [
    "### Standardized Moments\n",
    "A standardized moment $\\tilde \\mu_n$ is one which considers standardized values (ie. a z-score) of a distributions rather than the deviations of the distribution.\n",
    "\n",
    "The typical z-score is expressed as: \n",
    "\n",
    "$$z := \\left( \\frac{x - \\mu}{\\sigma} \\right)$$\n",
    "\n",
    "If we rewrite this to be consistent with the notation conventions we are using and incorporate is into our moment functions we have\n",
    "\n",
    "$$ \\tilde \\mu_n := \\mathbb{E} \\left[ \\left( \\frac{X - \\mu_1}{\\bar \\mu_2} \\right) ^n \\right] = \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{ \\sigma} \\right) ^n \\right] $$\n",
    "\n",
    "The skewness $\\tilde \\mu_3$ and kurtosis $\\tilde \\mu_4$ are common standardized moments of a distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c2838-0239-4dc2-832d-a96ef3235a04",
   "metadata": {},
   "source": [
    "## Common Moments And Symbols\n",
    "There is a set of \"common\" moments which are typically referred to as \"the first four moments\". We see this when looking at the generalized lambda distribution for example. These moments are as follows:\n",
    "\n",
    "- mean := $\\mu_1$\n",
    "- variance := $\\bar \\mu_2$\n",
    "- skewness := $\\tilde \\mu_3$\n",
    "- kurtosis := $\\tilde \\mu_4$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa15a5-f781-4123-955b-726415bc2013",
   "metadata": {},
   "source": [
    "## Moment Generation Function\n",
    "\n",
    "As the name suggests, the moment generating function (MGF), denoted $M_X$ is a parameterized function which is capable of derifing the moments of the distribution of a variable. In doing so, it's important to realize that moment generating functions are alternataive representations of distributions.\n",
    "\n",
    "[Wikipedia article](https://en.wikipedia.org/wiki/Moment-generating_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08227c60-c2c1-4835-8712-009f187245da",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "If $X$ is a random variable with a cumulative density function $F_X$ then the corresponding moment generating function $M_X(c)$ is defined as:\n",
    "\n",
    "$$M_X(c) := \\mathbb{E}[e^{cX}]$$\n",
    "\n",
    "Provided the expecataion exists for $c$ in some neighborhood of $0$. \n",
    "\n",
    "Taking the $n^{th}$ derivative of the MGF will yield the $n^{th}$ moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3af3ce-a1a5-4368-951b-f7a375e0f6fa",
   "metadata": {},
   "source": [
    "### Intuition\n",
    "\n",
    "Seeing is believing. In this section we build our intuition or faith in the definition by looking at clear examples.\n",
    "\n",
    "For any distribution there is a possibility for an infinite number of moments that can be derived. As we will see, the exponential function $e^{cX}$ was the natural selection as the definition of the MGF because of its mathematical properties.\n",
    "\n",
    "** Connection with Taylor series??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e48e81-b4e5-48d5-b969-59644537f6b1",
   "metadata": {},
   "source": [
    "#### Connection with infinite series\n",
    "\n",
    "The first important property is that the expression can be decomposed as an infinite series:\n",
    "\n",
    "$$ e^x = \\sum \\frac{x^n}{n!} = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots$$\n",
    "\n",
    "$$ => e^{ax} = \\sum \\frac{(ax)^n}{n!} = 1 + ax + \\frac{a^2x^2}{2!} + \\frac{a^3x^3}{3!} + \\cdots$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691829de-461c-4635-94c7-9888f98d76e1",
   "metadata": {},
   "source": [
    "#### Differentiate of infinite series\n",
    "The second is that the differentiation of the expected value of the infinite series will produce a moment coresponding to the order of the differentiation. Below we can see the relationship between the $n^{th}$ moment $m_n$ and the $n^{th}$ derivative $\\frac{d^n}{d^na}$.\n",
    "\n",
    "$$ m_n = M^{(n)} := \\frac{d^n}{d^na} \\left[ \\mathbb{E}[e^{aX}] \\right] $$\n",
    "\n",
    "$$ = \\frac{d^n}{d^na} \\left[ \\mathbb{E}\\left[\\sum \\frac{(aX)^n}{n!} \\right]\\right] $$\n",
    "\n",
    "$$ = \\frac{d^n}{d^na} \\left[ 1 + a\\mathbb{E}[X] + \\frac{a^2 \\mathbb{E}[X^2]}{2!} + \\frac{a^3 \\mathbb{E}[X^3]}{3!} + \\cdots \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee94cc0-1ca2-4f98-9ccf-1456a63d50dd",
   "metadata": {},
   "source": [
    "#### Derevations Of Common Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc1aca-2a01-4de7-affb-b1ed79b1512e",
   "metadata": {},
   "source": [
    "##### Derive The Mean\n",
    "Lets have a look at a few examples:\n",
    "\n",
    "$$ \\mu := m_1 $$ \n",
    "\n",
    "$$ = \\frac{d}{da} \\left[ 1 + a\\mathbb{E}[X] + \\frac{a^2 \\mathbb{E}[X^2]}{2!} + \\frac{a^3 \\mathbb{E}[X^3]}{3!} + \\cdots \\right] $$\n",
    "\n",
    "$$ = \\frac{d}{da} \\left[ 1 \\right] + \\frac{d}{da} \\left[ a\\mathbb{E}[X] \\right] + \\frac{d}{da} \\left[ \\frac{a^2 \\mathbb{E}[X^2]}{2!} \\right] + \\frac{d}{da} \\left[ \\frac{a^3 \\mathbb{E}[X^3]}{3!} \\right] + \\cdots] $$\n",
    "\n",
    "$$ = \\frac{d}{da} \\left[ 1 \\right] + \\mathbb{E}[X] \\frac{d}{da} \\left[ a \\right] + \\mathbb{E}[X^2]\\frac{d}{da} \\left[ \\frac{a^2}{2!} \\right] + \\mathbb{E}[X^3]\\frac{d}{da} \\left[ \\frac{a^3 }{3!} \\right] + \\cdots] $$\n",
    "\n",
    "$$ = 0 + \\mathbb{E}[x]  + \\mathbb{E}[X^2]\\frac{d}{da} \\left[ \\frac{a^2}{2!} \\right] + \\mathbb{E}[X^3]\\frac{d}{da} \\left[ \\frac{a^3 }{3!} \\right] + \\cdots] $$\n",
    "\n",
    "$$ = 0 + \\mathbb{E}[X]  + a\\mathbb{E}[X^2]  + a^2\\mathbb{E}[X^3] + \\cdots] $$\n",
    "\n",
    "$$ = \\sum_{n=1} a^{n-1} \\mathbb{E}[X^n] $$\n",
    "\n",
    "Now when we convolute very close to the origin, say $a=0$, we have:\n",
    "\n",
    "$$ = \\sum_{n=1} 0^{n-1} \\mathbb{E}[X^n] $$\n",
    "\n",
    "Only when $n=1$ does an $a$ term have an exponent such that is doesn't cancel out the expectaion term. Recall that $x^0 = 1\\rightarrow 0^0=1$ so we have:\n",
    "\n",
    "$$ = \\mathbb{E}[X] $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c76c0e-9973-466e-a942-8b3cc29778b7",
   "metadata": {},
   "source": [
    "##### Derive the Variance\n",
    "\n",
    "Deriving the variance is a bit more complicated as the variance is a central moment and not a raw moment. The basis of the derevation relies on the fact that:\n",
    "\n",
    "$$ var(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 $$\n",
    "\n",
    "We begin by taking the second derivative of our infinite series and seeing that the $a$ term will again cancel out everything except the term corresponding to the order of the derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82754ff0-2c18-4c39-9fdb-12ccff7659d7",
   "metadata": {},
   "source": [
    "$$ m_2  = \\frac{d^2}{d^2a} \\left[ 1 + a\\mathbb{E}[X] + \\frac{a^2 \\mathbb{E}[X^2]}{2!} + \\frac{a^3 \\mathbb{E}[X^3]}{3!} + \\cdots \\right] $$\n",
    "\n",
    "$$ = \\frac{d^2}{d^2a} \\left[ 1 \\right] + \\frac{d^2}{d^2a} \\left[ a\\mathbb{E}[X] \\right] + \\frac{d^2}{d^2a} \\left[ \\frac{a^2 \\mathbb{E}[X^2]}{2!} \\right] + \\frac{d^2}{d^2a} \\left[ \\frac{a^3 \\mathbb{E}[X^3]}{3!} \\right] + \\cdots] $$\n",
    "\n",
    "$$ = \\frac{d^2}{d^2a} \\left[ 1 \\right] + \\mathbb{E}[X] \\frac{d^2}{d^2a} \\left[ a \\right] + \\mathbb{E}[X^2]\\frac{d^2}{d^2a} \\left[ \\frac{a^2}{2!} \\right] + \\mathbb{E}[X^3]\\frac{d^2}{d^2a} \\left[ \\frac{a^3 }{3!} \\right] + \\cdots] $$\n",
    "\n",
    "$$ = 0 + 0  + \\mathbb{E}[X^2] + a^2 \\mathbb{E}[X^3] + \\cdots] $$\n",
    "\n",
    "$$ = \\sum_{n=2} a^{n-2} \\mathbb{E}[X^n] $$\n",
    "\n",
    "Now when we convolute very close to the origin, say $a=0$, we have:\n",
    "\n",
    "$$ = \\sum_{n=2} 0^{n-2} \\mathbb{E}[X^n] $$\n",
    "\n",
    "Only when $n=2$ does an $a$ term have an exponent such that is doesn't cancel out the expectaion term. Recall that $x^0 = 1\\rightarrow 0^0=1$ so we have:\n",
    "\n",
    "$$ m_2 = \\mathbb{E}[X^2] $$\n",
    "\n",
    "Putting this all together:\n",
    "\n",
    "$$ m_1 = \\mathbb{E}[X] $$\n",
    "$$ m_2 = \\mathbb{E}[X^2] $$\n",
    "$$ m_2 - m_1^2 = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 $$ \n",
    "$$ var(X) = \\bar m_2 =  m_2 - m_1^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d1cdc-8e4e-4de6-a42a-9bd919654a75",
   "metadata": {},
   "source": [
    "For more on the vairance see the [variance notebook](./Variance.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07d080-e8a8-47b5-b185-b31d8a115744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e51ab-a3e1-4b9c-afcd-ee7a4220102e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0bd6d-45fa-4907-8a73-b1f13a42bfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7221c35e-cfa4-46ee-9ee9-0aa9722019b8",
   "metadata": {},
   "source": [
    "### Apply MGF for Specific Distribution\n",
    "\n",
    "#### Examples with different distributions\n",
    "https://www.statlect.com/fundamentals-of-probability/moment-generating-function\n",
    "\n",
    "#### Exponential Distribution\n",
    "Calculating exponential random variable's MGF\n",
    "\n",
    "\n",
    "\n",
    "https://www.randomservices.org/random/expect/Generating.html\n",
    "\n",
    "https://bookdown.org/probability/beta/moment-generating-functions.html\n",
    "\n",
    "#### Poisson Distribution\n",
    "\n",
    "https://www.math.ucdavis.edu/~gravner/MAT135B/materials/ch10.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af151f-80ab-4970-9e30-4fbfd76b57fd",
   "metadata": {},
   "source": [
    "#### Univariate Normal Distribution\n",
    "\n",
    "We derive the PDF\n",
    "\n",
    "$$ \\phi(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{ - \\frac{1}{2}\\left( \\frac{x-\\mu}{\\sigma} \\right)^2} $$\n",
    "\n",
    "Now insert into the MGF\n",
    "\n",
    "$$M_X(c) := \\mathbb{E}[e^{cX}]$$\n",
    "\n",
    "$$ = \\int e^{cx} \\phi(x) \\ dx$$\n",
    "\n",
    "$$ = \\int e^{cx} \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{ - \\frac{1}{2}\\left( \\frac{x-\\mu}{\\sigma} \\right)^2} \\ dx$$\n",
    "\n",
    "$$ = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\int e^{cx} e^{ - \\frac{1}{2}\\left( \\frac{x-\\mu}{\\sigma} \\right)^2} \\ dx$$\n",
    "\n",
    "\n",
    "$$ = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\int e^{cx} e^{- \\frac{1}{2\\sigma^2}(x - \\mu)^2} \\ dx$$\n",
    "\n",
    "$$ = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\int  e^{cx - \\frac{1}{2\\sigma^2}(x - \\mu)^2} \\ dx$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1267f4-b122-43ec-9c96-1c832ff13b62",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Note: This is generally speaking, the end of the road for the general formula. The reason is because we are not able to derive an analytical solution for the integral. We cannot manipulate the equation into a format that supports u-substitution. And, if we split the exponential's exponents and try integration by parts we will see that both terms have an infinitely recursive series of integrals/derivatives and cannot be solved.\n",
    "\n",
    "The only option is to plug in values for the distribution parameters and hope they provide an algebraic simplification that allows the resulting eqation to be solved. We will see this is the case with the normal distribution.\n",
    "\n",
    "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3661.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f0d96-8937-4b92-99d2-ea07bee05ffc",
   "metadata": {},
   "source": [
    "#### Univariate Standard Normal\n",
    "\n",
    "We pickup where we left off with the generic MGF for the univariate normal distribution. We introduce constraints on the population parameters ($\\mu=0$ and $\\sigma=1$) to help siplify the equation:\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}} \\int  e^{cx - \\frac{x^2}{2}} \\ dx$$\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}} \\int  e^{\\frac{2cx - x^2}{2}} \\ dx$$\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}} \\int  e^{\\frac{- x^2 + 2cx }{2}} \\ dx$$\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}} \\int  e^{\\frac{- x^2 + 2cx - c^2 + c^2 }{2}} \\ dx \\tag{complete the square}$$\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}} \\int  e^{\\frac{- (x^2 - 2cx + c^2 ) + c^2 }{2}} \\ dx $$\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}} \\int  e^{\\frac{- (x - c)^2 + c^2 }{2}} \\ dx $$\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}} \\int e^{\\frac{- (x - c)^2 }{2}} e^{\\frac{c^2 }{2}} \\ dx $$\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}}e^{\\frac{c^2 }{2}} \\int e^{\\frac{- (x - c)^2 }{2}}  \\ dx $$\n",
    "\n",
    "$$ = \\frac{1}{ \\sqrt{2\\pi}}e^{\\frac{c^2 }{2}} \\int e^{-\\frac{1 }{2} (x - c)^2}  \\ dx $$\n",
    "\n",
    "We can now manipulate the equation so that it resembles a normal distribution density function with $\\sigma=1$ and $\\mu=c$.\n",
    "\n",
    "In doing so, we will be able to calculate the integral using the trivial notion that the integral of a density function sums to 1.\n",
    "\n",
    "$$ = e^{\\frac{c^2 }{2}} \\int \\frac{1}{ \\sqrt{2\\pi}} e^{-\\frac{1 }{2} (x - c)^2}  \\ dx $$\n",
    "\n",
    "$$ = e^{\\frac{c^2 }{2}} $$\n",
    "\n",
    "https://courses.cs.washington.edu/courses/cse312/19sp/schedule/lecture23.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728bda5-2f4c-4455-ab6f-3d363a3dff8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b66bef7-7f56-4ff2-bee0-ee894a5ea0ac",
   "metadata": {},
   "source": [
    "### History\n",
    "\n",
    "https://hsm.stackexchange.com/questions/3420/what-is-the-history-of-moment-generating-functions-and-the-more-general-charact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1434c2f-2823-4c30-a028-026ae013b4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d225856d-b40c-441f-b96f-7b92589a29ac",
   "metadata": {},
   "source": [
    "### Alternatives\n",
    "A problem with moment generating functions is that the it may not always be known or exist. Additionally the desired moments may not exist. This is due to the fact that the integrals do not need to converge absolutely?\n",
    "\n",
    "https://en.wikipedia.org/wiki/Moment-generating_function\n",
    "\n",
    "There are ways to force the MGF to converge. One such way is to make the convolutional interval based on an imaginary number.\n",
    "\n",
    "https://www.cs.toronto.edu/~yuvalf/CLT.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23f071-e098-4967-8de2-721a1c173098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3bb28-290e-4a23-8d06-b156f62bbf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2d57b-16a9-4948-bd89-a6dbd246a769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706300a7-9fcb-4e66-80c7-73c6cc4401a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4d768-78bb-4ad6-8414-174e932e81b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b64ed-ebff-41db-823e-a877eea05882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc334726-3aa3-4692-a312-36ee09d999ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0178862b-a174-4101-9814-7f794dbb8da8",
   "metadata": {},
   "source": [
    "## Properties\n",
    "\n",
    "https://bookdown.org/probability/beta/moment-generating-functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b23ce-ee12-4836-99ca-849efb9e2637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3a60889-5df3-4c72-9d19-e0b39e165696",
   "metadata": {},
   "source": [
    "Taylor Series\n",
    "https://en.wikipedia.org/wiki/Taylor_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a53256-1e6d-433b-a355-7e473fc1a215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4bdf2f9-cc9e-464e-a714-90ba269ede5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbd800-70e5-47fc-8123-bd282fc89c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e828209d-cc50-4d8e-8458-fc777bb0bec7",
   "metadata": {},
   "source": [
    "examples\n",
    "\n",
    "https://www.probabilitycourse.com/chapter6/6_1_3_moment_functions.php\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02bd35-f036-4a70-aa74-65a50bd1449f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34276b-a805-4a36-8998-01a3365108ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c474f5-bfe7-49b9-bbc3-89c54e96f195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d793f9c2-a050-46d3-a53c-b72c4f7a5095",
   "metadata": {},
   "source": [
    "# Expectations Of Linear Combinations\n",
    "Given a random variable $X$ we define a random variable $Y$ as a linear combination of $X$ such that $Y = a_1X_1  + \\cdots a_nX_n + d$. In matrix notation we have $Y = aX + b$.\n",
    "\n",
    "Linear combinations ofter arise while studdying joint probability. For more information see the [joint probability notebook](../Probability/Joint%20Probability.ipynb).\n",
    "\n",
    "We can derive moments for these linear combinations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9495f5-a835-43ab-8e27-a98698f75d87",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "\n",
    "Given that $X = \\{X_i\\}, \\  X_i \\perp X_j$ we define a random variable $Y$ as a linear combination of $X$ such that $Y = a_1X_1  + \\cdots a_nX_n + d$. In other words . $Y = aX + b$.\n",
    "\n",
    "The expected value is defined by the expectation\n",
    "\n",
    "$$ \\mathbb{E}[Y] = \\mathbb{E}[a_1X_1  + \\cdots a_nX_n + b] $$\n",
    "$$ = \\mathbb{E}[a_1X_1]  + \\cdots \\mathbb{E}[a_nX_n] + \\mathbb{E}[b] $$\n",
    "$$ = a_1\\mathbb{E}[X_1]  + \\cdots a_n\\mathbb{E}[X_n] + b $$\n",
    "\n",
    "Because $X$ is iid., we know that $\\mathbb{E}[X_i] = \\mathbb{E}[X_j]$ and therefore:\n",
    "\n",
    "$$ = a\\mathbb{E}[X] + b $$\n",
    "\n",
    "Depending on the values of $a$ and $b$ this expression can be simplieified further. For example if $b=0$, $\\mathbb{E}[Y] = a\\mathbb{E}[X]$. If $a=1$ and $b=0$ we have $\\mathbb{E}[Y] = \\mathbb{E}[X]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27167de5-e54d-4c5b-a0c6-4aec069ea2c6",
   "metadata": {},
   "source": [
    "## Variance\n",
    "$$ Var[Y] = \\mathbb{E} \\left[ (Y-\\mu)^2 \\right] $$\n",
    "\n",
    "$$ = \\mathbb{E}[Y^2] - \\mathbb{E}[Y]^2 $$\n",
    "\n",
    "$$ = \\mathbb{E}[(aX + b)^2] - \\mathbb{E}[aX + b]^2 $$\n",
    "\n",
    "$$ = \\mathbb{E}[a^2X^2 + 2abX + b^2] - (a\\mathbb{E}[X] + b)^2 $$\n",
    "\n",
    "$$ = a^2\\mathbb{E}[X^2] + 2ab\\mathbb{E}[X] + b^2 - a^2\\mathbb{E}[X]^2 - 2ab\\mathbb{E}[x] - b^2 $$\n",
    "\n",
    "$$ = a^2\\mathbb{E}[X^2]  - a^2\\mathbb{E}[X]^2 $$\n",
    "\n",
    "$$ = a^2(\\mathbb{E}[X^2]  - \\mathbb{E}[X]^2) $$\n",
    "\n",
    "$$ = a^2Var[x] $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9985b60-12d3-486c-a09b-8a37d7b1345d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e6fedc-50fe-4c99-a89c-844ac3bac118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83c9f6b4-8fa4-4327-8dbd-344b78238c9e",
   "metadata": {},
   "source": [
    "# Expectations Of Common Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928505f0-bb0c-4b39-9909-3e0bc4e884ed",
   "metadata": {},
   "source": [
    "Put links here to other notebooks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d973638-d50c-4c29-9c20-455999317a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84e42389-9855-4026-b3f6-0fcbc1458a73",
   "metadata": {},
   "source": [
    "# Conditional Expectation\n",
    "\n",
    "Conditional expectation is founded on the notions of conditional probability. If you are not familiar with these topics, please review the [conditional probability notebook](../Probability/Conditional%20Probability.ipynb)\n",
    "\n",
    "## Conditional Mean\n",
    "\n",
    "$$ \\mu_{Y|X} = \\mathbb{E}\\left[ Y|X \\right] $$\n",
    "\n",
    "$$ \\mu_{X|Y} = \\mathbb{E}\\left[ X|Y \\right] $$\n",
    "\n",
    "## Conditional Variance\n",
    "\n",
    "expand the formulas...\n",
    "\n",
    "$$ \\sigma^2_{Y|X} = \\mathbb{E} \\left[ \\left( Y - \\mu_{Y|X} \\right)^2 \\right] $$\n",
    "\n",
    "If there is a specific version of $X$ or $Y$ we have:\n",
    "\n",
    "$$ \\sigma^2_{Y|X=x} = \\mathbb{E} \\left[ \\left( Y - \\mu_{Y|X=x} \\right)^2 \\right] $$\n",
    "\n",
    "\n",
    "https://online.stat.psu.edu/stat414/lesson/19/19.3\n",
    "\n",
    "https://online.stat.psu.edu/stat414/book/export/html/734"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff76fd-0592-4dbe-b025-b732a0da2767",
   "metadata": {},
   "source": [
    "Expanding these equations\n",
    "\n",
    "$$ = \\mathbb{E} \\left[ \\left( Y - \\mu_{Y|X=x} \\right)^T\\left( Y - \\mu_{Y|X=x} \\right) \\right] $$\n",
    "\n",
    "$$ = \\mathbb{E}\\begin{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "y_1 - \\mu_{Y|X}, &\n",
    "y_2 - \\mu_{Y|X}, &\n",
    "\\cdots, &\n",
    "y_n - \\mu_{Y|X}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "y_1 - \\mu_{Y|X} \\\\\n",
    "y_2 - \\mu_{Y|X} \\\\\n",
    "\\vdots \\\\\n",
    "y_n - \\mu_{Y|X}\n",
    "\\end{bmatrix}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$ = \\mathbb{E}\\begin{bmatrix}\n",
    "(y_1 - \\mu_{Y|X})^2, & + &\n",
    "(y_2 - \\mu_{Y|X})^2, & + &\n",
    "\\cdots, & + &\n",
    "(y_n - \\mu_{Y|X})^2\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc18a1-3197-4211-9b0f-5e56e2f16edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb36fe4-7904-4114-a9ac-c7443e83705b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e1903-28a6-48a8-8d13-8c486b1cab68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039f2b5-1408-4801-927c-cf44e5ad788a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "386fd633-67ca-4030-ba00-642be6530f91",
   "metadata": {},
   "source": [
    "Assume that two variables $X$ and $Y$ are jointly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07cb2d-769f-4a3e-a1bb-e19a988425e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a002fdf-8c12-45cd-b198-ec729d59d476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a6cc318-78e7-4a54-a39a-c1abfd4415b9",
   "metadata": {},
   "source": [
    "# Properties Of Expectations\n",
    "## Expected Value\n",
    "### LinearRescaling\n",
    "$$ \\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b$$\n",
    "### Linearity\n",
    "$$ \\mathbb{E}[X +Y] = \\mathbb{E}[X] + \\mathbb{E}[Y] $$\n",
    "## Variance\n",
    "$$ Var[X + Y] = Var[x] + Var[Y] + 2Cov[X,Y] $$\n",
    "$$ Var[X - Y] = Var[x] + Var[Y] - 2Cov[X,Y] $$\n",
    "\n",
    "https://bookdown.org/kevin_davisross/probsim-book/expected-values-of-linear-combinations-of-random-variables.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
