{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2d9879c-9eed-440c-870c-0b8727e40b90",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook we review the concepts related to variance including:\n",
    "- deviation\n",
    "- variance\n",
    "- covariance\n",
    "\n",
    "There is an assumption of familiarity with expectations and matrix algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781c634-7cc7-470e-8914-f1353fe125cd",
   "metadata": {},
   "source": [
    "# 1. Deviation\n",
    "Deviation is a measurement of the distance between a variable and the central measurement (typically the mean) of a distribution. \n",
    "\n",
    "<center><img src=\"images/deviation_one_dimension.png\" alt=\"One Dimensional Deviation\" style=\"width: 400px\"/></center>\n",
    "\n",
    "As we will see, deviation is a foundational measurement used in a wide range of descriptive statistics. For example the standard deviation is based on the concept of deviation. Deviation is loosly interpreted as a measurement for how normal or irregular a particular value is when compared to the distribution. There are a number of different measruements for deviation. \n",
    "\n",
    "The simplest formula is given as:\n",
    "\n",
    "$$ d = x - \\mu $$\n",
    "\n",
    "A positive value indicates a particular value $x \\in X$ is larger than $\\mu$ and a negative indicating the opposite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd46829-7d7a-44cd-a138-1f5a50630602",
   "metadata": {},
   "source": [
    "# 2. Variance\n",
    "\n",
    "See the [notebook on variance](./Variance.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d50c52-3ae9-44db-b187-28f65390634c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aad784b-6739-4134-8cd4-037673a52e9d",
   "metadata": {},
   "source": [
    "# 3. Covariance\n",
    "Covariance is an attempt to explain variance in two dimensions or for two variables. Given two variables X and Y, the covariance multiplies the deviation of X by the deviation of Y. In a two dimentional space this would resemble the following:\n",
    "\n",
    "<center><img src=\"images/deviation_two_dimension.png\" alt=\"Two Dimensional Deviation\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "Here, the horizontal and vertical line represent the means respective to the X and Y variables.\n",
    "\n",
    "The geometric implications here are an important caveat to consider. A square is going to have the largest area of any rectangle with the same parimiter. As such, if the co-variables have the exact same deviations, the covariance value will form a square and thus be the largest possible value. If one variable is deviating while another is not, the area will be very small.\n",
    "\n",
    "The formal definition is given as:\n",
    "\n",
    "$$ Cov(X,Y) = \\sigma_{X,Y} := \\mathbb{E}[(X-\\mu_X)(Y-\\mu_Y)] $$\n",
    "\n",
    "$$ = \\mathbb{E} [ XY - X \\mu_Y - \\mu_X Y + \\mu_X \\mu_Y ] $$\n",
    "\n",
    "\n",
    "$$ = \\mathbb{E} [ XY - X \\mathbb{E}[Y] - \\mathbb{E}[X]Y + \\mathbb{E}[X]\\mathbb{E}[Y] ] $$\n",
    "\n",
    "$$ = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] - \\mathbb{E}[X]\\mathbb{E}[Y] + \\mathbb{E}[X]\\mathbb{E}[Y] $$\n",
    "\n",
    "$$ = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] $$\n",
    "\n",
    "## 3.1. Univariate Case\n",
    "\n",
    "If we expand the Expectation operator $\\mathbb{E}$ for a discrete random uniform random variable, with $p=\\frac{1}{n}$, we would have:\n",
    "\n",
    "$$ Cov(X,Y) = \\sigma_{X,Y} := \\frac{1}{n}\\sum(x_i-\\mu_X)(y_i - \\mu_Y) $$\n",
    "\n",
    "## 3.2. Multiavariate Matrix Algebra\n",
    "\n",
    "Matrix algebra allows us to calculate all the covariances between a set of variables simulatneously:\n",
    "\n",
    "$$ \\Sigma = \\frac{1}{n} (X - \\mu_X)(X - \\mu_X)^T $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54da16e-31ed-40ce-bfe4-07795150d978",
   "metadata": {},
   "source": [
    "# 4. Correlation\n",
    "## 4.1. Types of Correlation\n",
    "\n",
    "There are several types of correlations\n",
    "- Pearson Correlation\n",
    "- Kendal Rank Correlation\n",
    "- Spearman Correlation\n",
    "- Point-Biserial Correlation\n",
    "\n",
    "https://www.statisticssolutions.com/correlation-pearson-kendall-spearman/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2538d0-db35-4b4c-82af-b772cc3df0d3",
   "metadata": {},
   "source": [
    "## 4.2. Pearson Correlation\n",
    "### 4.2.1. Overview\n",
    "The pearson correlation coefficient is the mode widely used statistical measure. It assumes a linear relationship bweteen two variables and measures the strength and direction of that relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fcac1f-e873-453a-b62d-8174dd101a71",
   "metadata": {},
   "source": [
    "### 4.2.2. Definition\n",
    "\n",
    "The correlation coefficient is expressed through the following formula:\n",
    "\n",
    "$$ Cor(X,Y) = \\frac{Cov(X,Y)}{Std. \\ Dev(X) \\ Std. \\ Dev(Y)}  $$\n",
    "\n",
    "$$ \\rho = \\frac{\\sigma_{X,Y}}{\\sigma_X \\sigma_Y} $$\n",
    "\n",
    "It is common to see this expanded for a uniform discrete variable:\n",
    "\n",
    "$$ =\\frac{\\frac{1}{n}\\sum{(x_i - \\mu_X)(y_i-\\mu_Y)}}{\\sqrt{\\frac{1}{n}\\sum{}(x_i-\\mu_X)^2}\\sqrt{\\frac{1}{n}\\sum{(y_i-\\mu_Y)^2}}} $$\n",
    "\n",
    "If we simlify the formula by calcelling out the $1/n$ (ie. removing the probability consideration) we would have something like\n",
    "\n",
    "$$ =\\frac{\\sum{(x_i - \\mu_X)\\sum(y_i-\\mu_Y)}}{\\sqrt{\\sum{(x_i-\\mu_X)^2}}\\sqrt{\\sum{(y_i-\\mu_Y)^2}}} $$\n",
    "\n",
    "$$  =\\frac{\\sum{(x_i - \\mu_X)(y_i-\\mu_Y)}}{\\sqrt{\\sum{(x_i-\\mu_X)^2(y_i-\\mu_Y)^2}}} $$\n",
    "\n",
    "$$ =\\frac{\\sum d_xd_Y}{\\sqrt{\\sum d_x^2}\\sqrt{\\sum d_y^2}} $$\n",
    "\n",
    "From this simplified equation we see the formula is expressed as a fraction of deviations. We have the co-deviation divided by the total deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2868873-a551-4730-a9bb-14a729343658",
   "metadata": {},
   "source": [
    "### 4.2.3. Intuition and Interpretation\n",
    "\n",
    "I think its helpful to consider correlation as a fraction of deviation measurements.\n",
    "\n",
    "In order to understand the correlation coefficient we need to understand that it is a fraction or a proportion of deviations. \n",
    "\n",
    "Thinking about this geometrically helps explain the concept. \n",
    "If we think about deviation in one dimension we would have the following:\n",
    "\n",
    "<img src=\"images/deviation_one_dimension.png\" alt=\"One Dimensional Deviation\" style=\"width: 400px;\"/>\n",
    "\n",
    "If we think about the problem in two dimensions we would have the following:\n",
    "    \n",
    "<img src=\"images/deviation_two_dimension.png\" alt=\"Two Dimensional Deviation\" style=\"width: 400px;\"/>\n",
    "\n",
    "Referring back to the equation, when we look at the numerator\n",
    "\n",
    "$$\\sum d_x d_y$$\n",
    "\n",
    "We can rearange the product of two deviations as a single term (ie. $d_{x_1}*d_{y_1} = d_1$). This can be interpreted as a rectangle representing the deviation caused by the two variables. We can think about the sum of the rectangles as follows:\n",
    "\n",
    "<img src=\"images/deviation_two_dimension_geom.png\" alt=\"Two Dimensional Deviation Sum simple\" style=\"width: 400px;\"/>\n",
    "\n",
    "Now if we consider the denominator of the equation\n",
    "\n",
    "$$\\sqrt{\\sum d_x^2}\\sqrt{\\sum d_y^2}$$\n",
    "\n",
    "It can also be interpreted as an area. This area is intended to represent the maximum possible total deviations of both x and y.\n",
    "\n",
    "To understand this point, consider the geometric implications. An important characteristic of the square is that it has the largest area of any rectangle. This means that the squaring of the deviations represent the largest possible area representing the two dimensional deviation. Taking the quare root of this square gives us the optimal length of an arbitrary side.\n",
    "\n",
    "<img src=\"images/deviation_two_dimension_sum.png\" alt=\"Two Dimensional Deviation Sum\" style=\"width: 400px;\"/>\n",
    "\n",
    "Thus the denominator is again representing the maximum possible total deviation from both variables.\n",
    "\n",
    "So the correclation coefficient is essentially a fraction of covariance to total possible variance!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2675b9-7015-441f-bf80-d0634c7b423f",
   "metadata": {},
   "source": [
    "### 4.2.4. Additional Notes\n",
    "\n",
    "An interesting caveat in this calculation is the way that we determine the total deviation for a specific variable. We are using the squaring technique to find the absolute values rather than using the absolute value function. There are other correlation measurements which instead use the absolute value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
