{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef35ec42-67ec-482a-9af7-7f29f39a97cf",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook we explore multithreading using python. We will first discuss relevant libraries before looking at a specific implimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99653fae-ff99-492f-bd3a-d0ae7dc606c1",
   "metadata": {},
   "source": [
    "# Relevant Libraries\n",
    "## The multiprocessing Module\n",
    "The multiprocessing module is at the heart of python's parallelization capabilities. From this module we gain access to both multithreading and multiprocessing libraries and primitives. Additionally we get access to the synchronization primitives.\n",
    "\n",
    "Below we outline the key objects required for most implimentations:\n",
    "\n",
    "### Lock\n",
    "The [Lock class](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Lock) is the python implimentation of a mutex for threads. Using the lock we can synchronize access to resources shared between threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d246ec-4e2a-4743-8f3d-4bde089078f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lock\n",
    "import multiprocessing\n",
    "lock = multiprocessing.Lock()\n",
    "\n",
    "# Wait until we get exclusive access to shared resource\n",
    "lock.acquire() \n",
    "\n",
    "# Assign a value to a shared resource (pseudo code)\n",
    "shared_int = 5\n",
    "\n",
    "# Allow other threads to access shared resource and avoid deadlocks\n",
    "lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2312479-1f67-4abb-b295-497333088793",
   "metadata": {},
   "source": [
    "We can also use the lock with a context manager and the with clause to simplify our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05e099f-2cac-4a40-95f1-000fe96ab3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lock\n",
    "import multiprocessing\n",
    "lock = multiprocessing.Lock()\n",
    "\n",
    "with lock:\n",
    "    shared_int = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4541c6b-b1bb-4571-b1a3-0fe514ee0590",
   "metadata": {},
   "source": [
    "The problem with this lock is that it is not a reentrant lock. This means that we cannot call acquire multiple times. The second time we will call acquire, we will block and cause a deadlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a58afcd6-4e5d-4fe3-ad3c-903f56d9e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting lock ...\n",
      "Got lock, Getting lock again ...\n",
      "Gave up waiting after three seconds\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Getting lock ...\")\n",
    "    lock.acquire()\n",
    "    print(\"Got lock, Getting lock again ...\")\n",
    "    lock.acquire(timeout=3)\n",
    "    print(\"Gave up waiting after three seconds\")\n",
    "finally:\n",
    "    lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc6d42-05f8-41fe-9e45-a52b95d098e6",
   "metadata": {},
   "source": [
    "As a result we can either impliment our own logic to manage the lock state (bad idea) or use the RLock object from the threading module wich is reentrant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f346b62-28bc-4c3e-9799-8021460f80f9",
   "metadata": {},
   "source": [
    "### Shared Memory\n",
    "Python provides two mechanisms for sharing memory between threads. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df16a3-f09c-45f8-b937-01482a4dd8e4",
   "metadata": {},
   "source": [
    "#### Value\n",
    "The [Value object](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Value) allows c_type objects to be shared between threads. For a list of the typecodes see [this article](https://docs.python.org/3/library/array.html#module-array). To create a shared integer for example, we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a5354ff-5a39-4244-beff-8fb5669138b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the shared integer\n",
    "import multiprocessing\n",
    "shared_int = multiprocessing.Value('i')\n",
    "\n",
    "# Assign a value\n",
    "shared_int.value = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98970655-9dbb-43b4-8b4a-51bc59f32a5d",
   "metadata": {},
   "source": [
    "In addition the Value object is also created with a lock property by default. Rather than manually managing our own locks, we can simply leverage the built in functionality as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "426594ab-c366-43a6-8638-7804f9e57e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with shared_int.get_lock():\n",
    "    shared_int.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b0c37a-fe3d-412f-b839-aee259868a32",
   "metadata": {},
   "source": [
    "In some cases, we may want multiple objects managed by the same Lock. In such an instance we can create the Value and tell the constructor not to create a Lock for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8195ab1-ed7b-4801-ab53-43c38a3a594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_int = multiprocessing.Value('i', lock=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8842d-2076-4de4-bb4c-1d4144e774c9",
   "metadata": {},
   "source": [
    "We can also give it a pointer to an existing lock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e8821-2004-4af2-95ac-be43f4077c61",
   "metadata": {},
   "source": [
    "#### Array\n",
    "The [Array object](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Array) is an array of Values. For example a character string is an array of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba064237-1be1-4ec8-b529-b52e27f1da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'new string'\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "shared_string = multiprocessing.Array('c', b'Hello, World!', lock=lock)\n",
    "shared_string.value = b'new string'\n",
    "print(shared_string.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb51e4be-d6a5-467d-a2d2-eb25d34d2c63",
   "metadata": {},
   "source": [
    "## The threading Module\n",
    "The threading module provides a number of low level utilities related to multithreading. In particular the Thread-Local data.\n",
    "\n",
    "### Non-Shred Memory\n",
    "In some cases we want to have duplicate variables which are private to each thread. For example, if a thread is a person, every person has a pair of shoes but each person has their own pair for their own use.\n",
    "\n",
    "#### local\n",
    "The [local object](https://docs.python.org/3/library/threading.html#thread-local-data) is the python implimentation of Thread-Static or Thread-Local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "919568d1-8df7-4f92-9649-371c643ced07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n"
     ]
    }
   ],
   "source": [
    "# Create instance of thread local memory\n",
    "import threading\n",
    "thread_local_data = threading.local()\n",
    "\n",
    "# Store arbitrary data in this object\n",
    "thread_local_data.x = 5\n",
    "thread_local_data.y = 6\n",
    "\n",
    "# Show our data is there\n",
    "print(\"{0} {1}\".format(thread_local_data.x, thread_local_data.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13241886-ffff-4a88-83fc-33fb44661b0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rlock\n",
    "The [RLock object](https://docs.python.org/3/library/threading.html#rlock-objects) is a reentrant lock which will not block if the acquire function is called multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1bb6feee-9ef3-42bb-a2fa-3681ae626bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting lock ...\n",
      "Getting lock again ...\n",
      "Got lock again\n"
     ]
    }
   ],
   "source": [
    "# Create a lock\n",
    "import threading\n",
    "lock = threading.RLock()\n",
    "\n",
    "try:\n",
    "    print(\"Getting lock ...\")\n",
    "    lock.acquire()\n",
    "    print(\"Getting lock again ...\")\n",
    "    lock.acquire()\n",
    "    print(\"Got lock again\")\n",
    "finally:\n",
    "    lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c0295-4193-4c76-9349-1281c5416a16",
   "metadata": {},
   "source": [
    "## The multiprocessing.pool Module\n",
    "This module provides access to the ThreadPool and must be imported to gain access.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef44b7-6642-4bb1-893d-58b8f45854c2",
   "metadata": {},
   "source": [
    "### ThreadPool\n",
    "The [ThreadPool](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.ThreadPool)  controls a pool of worker threads. The ThreadPool is interface compatable with the Pool object used to manage processes. The ThreadPool provides several mechanisms to running code segments in parallel. We will only cover one method here; the *startmap()* method. Later we will see a non-blocking option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6dbe6ed9-8d2a-44d4-8346-9444f69e72ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0\n",
      "1 -> 0\n",
      "2 -> 0\n",
      "0 -> 1\n",
      "1 -> 1\n",
      "2 -> 1\n",
      "0 -> 2\n",
      "1 -> 2\n",
      "2 -> 2\n",
      "3 -> 0\n",
      "4 -> 0\n",
      "5 -> 0\n",
      "3 -> 1\n",
      "4 -> 1\n",
      "5 -> 1\n",
      "3 -> 2\n",
      "4 -> 2\n",
      "5 -> 2\n",
      "6 -> 0\n",
      "7 -> 0\n",
      "8 -> 0\n",
      "6 -> 1\n",
      "7 -> 1\n",
      "8 -> 1\n",
      "6 -> 2\n",
      "7 -> 2\n",
      "8 -> 2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Create a lock to synchronize access to STDOUT (the console)\n",
    "lock = multiprocessing.Lock()\n",
    "\n",
    "# Create a function to print to the console\n",
    "def my_func(idx, lock):\n",
    "    for i in range(0, 3):\n",
    "        lock.acquire()\n",
    "        print(\"{0} -> {1}\".format(idx, i))\n",
    "        lock.release()\n",
    "        time.sleep(1)\n",
    "    return idx\n",
    "        \n",
    "# Create a ThreadPool with three workers\n",
    "my_pool = multiprocessing.pool.ThreadPool(processes=3)\n",
    "\n",
    "# Create ten sets of parameters for the 10 functions we want to run in parallel\n",
    "params = [(idx, lock) for idx in range(9)]\n",
    "\n",
    "# Parallelize the functions, wait until they all complete, and assemble the results in an array coresponding to the input parameter order\n",
    "apply_result = my_pool.starmap(my_func, params)\n",
    "\n",
    "# Get the results in an array coresponding to the input parameter order\n",
    "print(apply_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11153b-2524-4c59-8e10-d88c3feb1204",
   "metadata": {},
   "source": [
    "It is important to note that the ThreadPool will halt at the first error. All reqults etc will be lost if an unhandled exception is encountered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "507b5652-71df-452f-a991-b54a43f5b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0\n",
      "1 -> 0\n",
      "2 -> 0\n",
      "0 -> 1\n",
      "1 -> 1\n",
      "2 -> 1\n",
      "0 -> 2\n",
      "1 -> 2\n",
      "2 -> 2\n",
      "3 -> 0\n",
      "5 -> 0\n",
      "6 -> 0\n",
      "3 -> 1\n",
      "6 -> 1\n",
      "5 -> 1\n",
      "3 -> 2\n",
      "6 -> 2\n",
      "5 -> 2\n",
      "7 -> 0\n",
      "8 -> 0\n",
      "7 -> 1\n",
      "8 -> 1\n",
      "7 -> 2\n",
      "8 -> 2\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "This should have been caught",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m params \u001b[38;5;241m=\u001b[39m [(idx, lock) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m)]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Parallelize the functions, wait until they all complete, and assemble the results in an array coresponding to the input parameter order\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m apply_result \u001b[38;5;241m=\u001b[39m \u001b[43mmy_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Get the results in an array coresponding to the input parameter order\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(apply_result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py:51\u001b[0m, in \u001b[0;36mstarmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmapstar\u001b[39m(args):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36mmy_func\u001b[0;34m(idx, lock)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_func\u001b[39m(idx, lock):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis should have been caught\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     12\u001b[0m         lock\u001b[38;5;241m.\u001b[39macquire()\n",
      "\u001b[0;31mException\u001b[0m: This should have been caught"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Create a lock to synchronize access to STDOUT (the console)\n",
    "lock = multiprocessing.Lock()\n",
    "\n",
    "# Create a function to print to the console\n",
    "def my_func(idx, lock):\n",
    "    if idx == 4:\n",
    "        raise Exception(\"This should have been caught\")\n",
    "    for i in range(0, 3):\n",
    "        lock.acquire()\n",
    "        print(\"{0} -> {1}\".format(idx, i))\n",
    "        lock.release()\n",
    "        time.sleep(1)\n",
    "    return idx\n",
    "        \n",
    "# Create a ThreadPool with three workers\n",
    "my_pool = multiprocessing.pool.ThreadPool(processes=3)\n",
    "\n",
    "# Create ten sets of parameters for the 10 functions we want to run in parallel\n",
    "params = [(idx, lock) for idx in range(9)]\n",
    "\n",
    "# Parallelize the functions, wait until they all complete, and assemble the results in an array coresponding to the input parameter order\n",
    "apply_result = my_pool.starmap(my_func, params)\n",
    "\n",
    "# Get the results in an array coresponding to the input parameter order\n",
    "print(apply_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ab50b-191a-4420-946b-e124d76e8159",
   "metadata": {},
   "source": [
    "We can see only one exception was raised and we dont know what parameters were responsible.\n",
    "\n",
    "To remedy this problem, and others, we will impliment a more robust object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46337a38-23f2-4d73-82d6-0c734bf567b8",
   "metadata": {},
   "source": [
    "# Example Implimentation\n",
    "In this section we will extend the ThreadPool concept. We want a progress bar to visualize how much of the compute has finished at any given point in time. We also want to automagically capture the exceptions (if the user desires) so that the program does not hault and a graceful exit can be orchestrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a87743d5-ac7e-455c-9ed4-f0bcaf87faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "import multiprocessing.pool\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# This class will keep track of exceptions raised in multithreaded functions if the user\n",
    "# has elected to do so when they create the EnhancedThreadPool\n",
    "\n",
    "class EnhancedThreadPoolException(Exception):\n",
    "    def __init__(self, function, parameters, root_exeption, message):\n",
    "        self.functiom=function\n",
    "        self.parameters=parameters\n",
    "        self.__cause__=root_exeption\n",
    "        super().__init__(message)\n",
    "\n",
    "# This class will act as an enhanced threadpool\n",
    "# Ideally i would extend the ThreadPool class but I do not have enough time to impliment \n",
    "# ALL the required functionality. As such it will remain a separate class until I can extend.\n",
    "\n",
    "class EnhancedThreadPool():\n",
    "\n",
    "    def __init__(self, num_workers=4, handle_exceptions=True):\n",
    "        \n",
    "        self.handle_exceptions = handle_exceptions\n",
    "        \n",
    "        # Create a pointer for a progress bar to track progress\n",
    "        self.progress_bar = None\n",
    "        \n",
    "        # Create a lock to manage internal access to the progress bar\n",
    "        self.lock = multiprocessing.Lock()\n",
    "        \n",
    "        # Create internal pool to manage processes\n",
    "        self.pool = multiprocessing.pool.ThreadPool(processes=num_workers)\n",
    "        \n",
    "        # Create a shared memory object to store the number of completed threads\n",
    "        # between the various threads running in parallel\n",
    "        self.shared_memory_buffer = multiprocessing.Value('i', 0)\n",
    "\n",
    "    def _create_progress_bar(self, num_ops):\n",
    "        \n",
    "        return tqdm(range(num_ops))\n",
    "        \n",
    "    def _update_progress_bar(self, i):\n",
    "        \n",
    "        self.progress_bar.last_print_n = i\n",
    "        self.progress_bar.n = i\n",
    "        self.progress_bar.set_description(f'Completed Ops')\n",
    "        self.progress_bar.refresh()\n",
    "\n",
    "    # To make things simple we will define an internal function to hide the details\n",
    "    # of the progress bar. This way the user can wwrite functions without worrying\n",
    "    # about updating or locking the progress bar.\n",
    "    @staticmethod\n",
    "    def _wrapper_function(func, args, kwargs, internal_params):\n",
    "        \n",
    "        # Extract internal arguments for the manager's internal functions\n",
    "        internal_args, internal_kwargs = internal_params\n",
    "        lock, shared_memory_buffer = internal_args\n",
    "        handle_exceptions = internal_kwargs[\"handle_exceptions\"]\n",
    "        \n",
    "        # Run the user specificed function and return the results\n",
    "        # Handle the exceptions is the user has requested us to do so\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            if handle_exceptions:\n",
    "                return EnhancedThreadPoolException(func, (args,kwargs), e, \"An error ocurred while running the parallel function\")\n",
    "            else:\n",
    "                raise\n",
    "        finally:\n",
    "            # Update the buffer for the progress bar to indicate the function has completed\n",
    "            lock.acquire()\n",
    "            shared_memory_buffer.value = shared_memory_buffer.value + 1\n",
    "            lock.release()\n",
    "        \n",
    "    # This function will run a set of functions in separate processes.\n",
    "    # The main thread will block and update a progress bar as the functions complete\n",
    "    # It will return a result set once all the processes have finished or an\n",
    "    # error has been encountered.\n",
    "    # This function will run a set of functions in separate processes.\n",
    "    # The main thread will block and update a progress bar as the functions complete\n",
    "    # It will return a result set once all the processes have finished or an\n",
    "    # error has been encountered.\n",
    "    def parralelize(self, func, arg_set, kwarg_set):\n",
    "        \n",
    "        # Setup vars to help kick off parallelization\n",
    "        num_ops = len(arg_set)\n",
    "        self.progress_bar = self._create_progress_bar(num_ops)\n",
    "        self.shared_memory_buffer.value = 0\n",
    "        \n",
    "        # Configure the parameters for the parallelization\n",
    "        func_set = [func for i in range(0, num_ops)]\n",
    "        internal_param_set = [\n",
    "            ([self.lock, self.shared_memory_buffer], \n",
    "             {\"handle_exceptions\": self.handle_exceptions}\n",
    "            ) for i in range(0, num_ops)]   \n",
    "        param_set = zip(func_set, arg_set, kwarg_set, internal_param_set)\n",
    "        \n",
    "        # Start the functions in separate parallel processes and don't block\n",
    "        apply_result = self.pool.starmap_async(self._wrapper_function, param_set)\n",
    "        \n",
    "        # Wait for the proceses to finish while updating the progress bar\n",
    "        while not apply_result.ready():\n",
    "            self._update_progress_bar(self.shared_memory_buffer.value)\n",
    "            time.sleep(0.5)\n",
    "        self._update_progress_bar(self.shared_memory_buffer.value)\n",
    "\n",
    "        # Return the results\n",
    "        return apply_result.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1bf903-b2e0-43a6-82ca-c8ccab6ba302",
   "metadata": {},
   "source": [
    "Now that we have these base objects we can test them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f43d8720-325d-4c3f-bda4-52f1f9a929c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e70eb0736541ffb5255c7b252ed090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0\n",
      "1 -> 0\n",
      "2 -> 0\n",
      "3 -> 0\n",
      "1 -> 1\n",
      "2 -> 1\n",
      "0 -> 1\n",
      "3 -> 1\n",
      "1 -> 2\n",
      "2 -> 2\n",
      "3 -> 2\n",
      "0 -> 2\n",
      "5 -> 0\n",
      "6 -> 0\n",
      "7 -> 0\n",
      "8 -> 0\n",
      "6 -> 1\n",
      "5 -> 1\n",
      "7 -> 1\n",
      "8 -> 1\n",
      "6 -> 2\n",
      "5 -> 2\n",
      "7 -> 2\n",
      "8 -> 2\n",
      "9 -> 0\n",
      "9 -> 1\n",
      "9 -> 2\n",
      " \n",
      "[0, 1, 2, 3, EnhancedThreadPoolException('An error ocurred while running the parallel function'), 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the function we want to parallelize\n",
    "def my_func(idx, lock):\n",
    "    if idx == 4:\n",
    "        raise Exception(\"This should have been caught\")\n",
    "    for i in range(0, 3):\n",
    "        lock.acquire()\n",
    "        print(\"{0} -> {1}\".format(idx, i))\n",
    "        lock.release()\n",
    "        time.sleep(1)\n",
    "    return idx\n",
    "\n",
    "# Detine parameters for multithreading\n",
    "num_ops = 10\n",
    "lock = multiprocessing.Lock()\n",
    "my_func_arg_set = list(zip(list(range(0, num_ops)), itertools.repeat(lock)))\n",
    "my_func_kwarg_set = [{} for i in range(0, num_ops)]\n",
    "\n",
    "# Start the process in parallel\n",
    "etp = EnhancedThreadPool(num_workers=4)\n",
    "results = etp.parralelize(my_func, my_func_arg_set, my_func_kwarg_set)\n",
    "print(\" \")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f539d8c3-d882-46c5-a30c-5cc020167d8e",
   "metadata": {},
   "source": [
    "We can see the exception did not blow things up and can be tied back to the original parameter set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
