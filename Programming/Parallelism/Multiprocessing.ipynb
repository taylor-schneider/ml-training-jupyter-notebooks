{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef35ec42-67ec-482a-9af7-7f29f39a97cf",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook we explore multithreading using python. We will first discuss relevant libraries before looking at a specific implimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99653fae-ff99-492f-bd3a-d0ae7dc606c1",
   "metadata": {},
   "source": [
    "# Relevant Libraries\n",
    "## The multiprocessing Module\n",
    "The multiprocessing module is at the heart of python's parallelization capabilities. From this module we gain access to both multithreading and multiprocessing libraries and primitives. Additionally we get access to the synchronization primitives.\n",
    "\n",
    "Below we outline the key objects required for most implimentations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f346b62-28bc-4c3e-9799-8021460f80f9",
   "metadata": {},
   "source": [
    "### Shared Memory\n",
    "Similar to the Value and Array objects used in multithreading, the multiprocessing library provides a mechanism for sharing memory between processes. This is in the shared_memory submodule. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df16a3-f09c-45f8-b937-01482a4dd8e4",
   "metadata": {},
   "source": [
    "#### SharedMemory\n",
    "The [SharedMemory object](https://docs.python.org/3/library/multiprocessing.shared_memory.html) provides a memory buffer which can be shared between processes. Each buffer has a unique name which globally identifies it between processes. The buffer needs to be cleaned up manually. If we are cleaning up for a single process we use the close() function. If we want to destory the buffer once all the processes have called close() we call unlink(). If we do not call unlink, the memory will persist and can be accidentally reloaded with an old state!\n",
    "\n",
    "To create a shared memory buffer we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5354ff-5a39-4244-beff-8fb5669138b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Set a name to uniquely identify the buffer\n",
    "shared_memory_name = \"multiprocessor\"\n",
    "\n",
    "# Create an instance if one does not exist\n",
    "try:\n",
    "    shared_memory = multiprocessing.shared_memory.SharedMemory(name=shared_memory_name, create=True, size=1)\n",
    "except FileExistsError as fee:\n",
    "    shared_memory = multiprocessing.shared_memory.SharedMemory(name=shared_memory_name, create=False, size=1)\n",
    "\n",
    "# Set a value in the buffer\n",
    "shared_memory_buffer = shared_memory.buf\n",
    "shared_memory_buffer[0] = 0\n",
    "\n",
    "# Cleanup\n",
    "shared_memory.close()\n",
    "shared_memory.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98970655-9dbb-43b4-8b4a-51bc59f32a5d",
   "metadata": {},
   "source": [
    "If we create an array of values we can access them via index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426594ab-c366-43a6-8638-7804f9e57e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a name to uniquely identify the buffer\n",
    "shared_memory_name = \"multiprocessor\"\n",
    "\n",
    "# Create an instance if one does not exist\n",
    "try:\n",
    "    shared_memory = multiprocessing.shared_memory.SharedMemory(name=shared_memory_name, create=True, size=4)\n",
    "except FileExistsError as fee:\n",
    "    shared_memory = multiprocessing.shared_memory.SharedMemory(name=shared_memory_name, create=False, size=4)\n",
    "\n",
    "# Set a value in the buffer\n",
    "shared_memory_buffer = shared_memory.buf\n",
    "shared_memory_buffer[0] = 0\n",
    "shared_memory_buffer[1] = 1\n",
    "shared_memory_buffer[2] = 2\n",
    "shared_memory_buffer[3] = 3\n",
    "\n",
    "# Cleanup\n",
    "shared_memory.close()\n",
    "shared_memory.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a10c83-3656-4a68-bdaf-df0301577a7a",
   "metadata": {},
   "source": [
    "### Manager\n",
    "The [Manager object](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.sharedctypes.multiprocessing.Manager) can be used for sharing objects between processes. This object will create proxies between the subprocesses to allow sharing between them.\n",
    "\n",
    "One of the key reasons to use this object to to get access to a Lock() or RLock() object which can be used between processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b5b3a-b2ff-4b0b-b094-16c23b71a907",
   "metadata": {},
   "source": [
    "#### Manager.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb5ce4e-25dd-42e2-99b8-c2a76f2b1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "manager = multiprocessing.Manager()\n",
    "lock = manager.Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c0295-4193-4c76-9349-1281c5416a16",
   "metadata": {},
   "source": [
    "## The multiprocessing.pool Module\n",
    "This module provides access to the ThreadPool and must be imported to gain access.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef44b7-6642-4bb1-893d-58b8f45854c2",
   "metadata": {},
   "source": [
    "### Pool\n",
    "The [Pool](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool)  controls a pool of worker processes. The Pool is interface compatable with the ThreadPool object used to manage thread. The Pool provides several mechanisms to running code segments in parallel. We will only cover one method here; the *startmap()* method. Later we will see a non-blocking option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbe6ed9-8d2a-44d4-8346-9444f69e72ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0\n",
      "1 -> 0\n",
      "2 -> 0\n",
      "0 -> 1\n",
      "1 -> 1\n",
      "2 -> 1\n",
      "0 -> 2\n",
      "1 -> 2\n",
      "2 -> 2\n",
      "3 -> 0\n",
      "4 -> 0\n",
      "5 -> 0\n",
      "3 -> 1\n",
      "4 -> 1\n",
      "5 -> 1\n",
      "3 -> 2\n",
      "4 -> 2\n",
      "5 -> 2\n",
      "6 -> 0\n",
      "7 -> 0\n",
      "8 -> 0\n",
      "6 -> 1\n",
      "7 -> 1\n",
      "8 -> 1\n",
      "6 -> 2\n",
      "7 -> 2\n",
      "8 -> 2\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-7:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 366, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Create a lock to synchronize access to STDOUT (the console)\n",
    "manager = multiprocessing.Manager()\n",
    "lock = manager.Lock()\n",
    "\n",
    "# Create a function to print to the console\n",
    "def my_func(idx, lock):\n",
    "    for i in range(0, 3):\n",
    "        lock.acquire()\n",
    "        print(\"{0} -> {1}\".format(idx, i))\n",
    "        lock.release()\n",
    "        time.sleep(1)\n",
    "    return idx\n",
    "        \n",
    "# Create a ThreadPool with three workers\n",
    "my_pool = multiprocessing.Pool(processes=3)\n",
    "\n",
    "# Create ten sets of parameters for the 10 functions we want to run in parallel\n",
    "params = [(idx, lock) for idx in range(9)]\n",
    "\n",
    "# Parallelize the functions, wait until they all complete, and assemble the results in an array coresponding to the input parameter order\n",
    "apply_result = my_pool.starmap(my_func, params)\n",
    "\n",
    "# Get the results in an array coresponding to the input parameter order\n",
    "print(apply_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11153b-2524-4c59-8e10-d88c3feb1204",
   "metadata": {},
   "source": [
    "It is important to note that the ThreadPool will halt at the first error. All reqults etc will be lost if an unhandled exception is encountered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "507b5652-71df-452f-a991-b54a43f5b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0\n",
      "1 -> 0\n",
      "2 -> 0\n",
      "0 -> 1\n",
      "1 -> 1\n",
      "2 -> 1\n",
      "0 -> 2\n",
      "1 -> 2\n",
      "2 -> 2\n",
      "3 -> 0\n",
      "5 -> 0\n",
      "6 -> 0\n",
      "3 -> 1\n",
      "6 -> 1\n",
      "5 -> 1\n",
      "3 -> 2\n",
      "6 -> 2\n",
      "5 -> 2\n",
      "7 -> 0\n",
      "8 -> 0\n",
      "7 -> 1\n",
      "8 -> 1\n",
      "7 -> 2\n",
      "8 -> 2\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "This should have been caught",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m params \u001b[38;5;241m=\u001b[39m [(idx, lock) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m)]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Parallelize the functions, wait until they all complete, and assemble the results in an array coresponding to the input parameter order\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m apply_result \u001b[38;5;241m=\u001b[39m \u001b[43mmy_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Get the results in an array coresponding to the input parameter order\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(apply_result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py:51\u001b[0m, in \u001b[0;36mstarmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmapstar\u001b[39m(args):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36mmy_func\u001b[0;34m(idx, lock)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_func\u001b[39m(idx, lock):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis should have been caught\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     12\u001b[0m         lock\u001b[38;5;241m.\u001b[39macquire()\n",
      "\u001b[0;31mException\u001b[0m: This should have been caught"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Create a lock to synchronize access to STDOUT (the console)\n",
    "lock = multiprocessing.Lock()\n",
    "\n",
    "# Create a function to print to the console\n",
    "def my_func(idx, lock):\n",
    "    if idx == 4:\n",
    "        raise Exception(\"This should have been caught\")\n",
    "    for i in range(0, 3):\n",
    "        lock.acquire()\n",
    "        print(\"{0} -> {1}\".format(idx, i))\n",
    "        lock.release()\n",
    "        time.sleep(1)\n",
    "    return idx\n",
    "        \n",
    "# Create a ThreadPool with three workers\n",
    "my_pool = multiprocessing.pool.ThreadPool(processes=3)\n",
    "\n",
    "# Create ten sets of parameters for the 10 functions we want to run in parallel\n",
    "params = [(idx, lock) for idx in range(9)]\n",
    "\n",
    "# Parallelize the functions, wait until they all complete, and assemble the results in an array coresponding to the input parameter order\n",
    "apply_result = my_pool.starmap(my_func, params)\n",
    "\n",
    "# Get the results in an array coresponding to the input parameter order\n",
    "print(apply_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ab50b-191a-4420-946b-e124d76e8159",
   "metadata": {},
   "source": [
    "We can see only one exception was raised and we dont know what parameters were responsible.\n",
    "\n",
    "To remedy this problem, and others, we will impliment a more robust object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46337a38-23f2-4d73-82d6-0c734bf567b8",
   "metadata": {},
   "source": [
    "# Example Implimentation\n",
    "In this section we will extend the ThreadPool concept. We want a progress bar to visualize how much of the compute has finished at any given point in time. We also want to automagically capture the exceptions (if the user desires) so that the program does not hault and a graceful exit can be orchestrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a87743d5-ac7e-455c-9ed4-f0bcaf87faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "import multiprocessing.pool\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# This class will keep track of exceptions raised in multitprocess functions if the user\n",
    "# has elected to do so when they create the EnhancedThreadPool\n",
    "\n",
    "class EnhancedProcessPoolException(Exception):\n",
    "    \n",
    "    def __init__(self, message):\n",
    "        super().__init__(message)\n",
    "    def __init__(self, function, parameters, root_exeption, message):\n",
    "        self.functiom=function\n",
    "        self.parameters=parameters\n",
    "        self.__cause__=root_exeption\n",
    "        self.message = message\n",
    "\n",
    "# This class will act as an enhanced threadpool\n",
    "# Ideally i would extend the ThreadPool class but I do not have enough time to impliment \n",
    "# ALL the required functionality. As such it will remain a separate class until I can extend.\n",
    "\n",
    "class EnhancedProcessPool():\n",
    "\n",
    "    def __init__(self, num_workers=4, handle_exceptions=True, shared_memory=\"epp\"):\n",
    "        \n",
    "        self.handle_exceptions = handle_exceptions\n",
    "        \n",
    "        # Create a pointer for a progress bar to track progress\n",
    "        self.progress_bar = None\n",
    "        \n",
    "        # Create a lock to manage internal access to the progress bar\n",
    "        self.manager = multiprocessing.Manager()\n",
    "        self.lock = self.manager.Lock()\n",
    "        \n",
    "        # Create internal pool to manage processes\n",
    "        self.pool = multiprocessing.Pool(processes=num_workers)\n",
    "        \n",
    "        # Create a shared memory object to store the number of completed threads\n",
    "        # between the various threads running in parallel\n",
    "        self.shared_memory_name = shared_memory\n",
    "        try:\n",
    "            self.shared_memory = multiprocessing.shared_memory.SharedMemory(name=self.shared_memory_name, create=True, size=1)\n",
    "        except FileExistsError as fee:\n",
    "            self.shared_memory = multiprocessing.shared_memory.SharedMemory(name=self.shared_memory_name, create=False, size=1)\n",
    "        self.shared_memory_buffer = self.shared_memory.buf\n",
    "        self.shared_memory_buffer[0] = 0\n",
    "\n",
    "    def _create_progress_bar(self, num_ops):\n",
    "        \n",
    "        return tqdm(range(num_ops))\n",
    "        \n",
    "    def _update_progress_bar(self, i):\n",
    "        \n",
    "        self.progress_bar.last_print_n = i\n",
    "        self.progress_bar.n = i\n",
    "        self.progress_bar.set_description(f'Completed Ops')\n",
    "        self.progress_bar.refresh()\n",
    "\n",
    "    # To make things simple we will define an internal function to hide the details\n",
    "    # of the progress bar. This way the user can wwrite functions without worrying\n",
    "    # about updating or locking the progress bar.\n",
    "    @staticmethod\n",
    "    def _wrapper_function(func, args, kwargs, internal_params):\n",
    "        \n",
    "        # Extract internal arguments for the manager's internal functions\n",
    "        internal_args, internal_kwargs = internal_params\n",
    "        lock, shared_memory_name = internal_args\n",
    "        handle_exceptions = internal_kwargs[\"handle_exceptions\"]\n",
    "        \n",
    "        # Create pointer to shared memory (so we can update the progress bar)\n",
    "        sm = multiprocessing.shared_memory.SharedMemory(name=shared_memory_name, create=False, size=1)\n",
    "        smb = sm.buf\n",
    "        \n",
    "        # Run the user specificed function and return the results\n",
    "        # Handle the exceptions is the user has requested us to do so\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            if handle_exceptions:\n",
    "                return EnhancedProcessPoolException(func, (args,kwargs), e, \"An error ocurred while running the parallel function\")\n",
    "            else:\n",
    "                raise\n",
    "        finally:\n",
    "            # Update the buffer for the progress bar to indicate the function has completed\n",
    "            lock.acquire()\n",
    "            smb[0] = int(smb[0]) + 1\n",
    "            lock.release()\n",
    "            sm.close()\n",
    "        \n",
    "    # This function will run a set of functions in separate processes.\n",
    "    # The main thread will block and update a progress bar as the functions complete\n",
    "    # It will return a result set once all the processes have finished or an\n",
    "    # error has been encountered.\n",
    "    # This function will run a set of functions in separate processes.\n",
    "    # The main thread will block and update a progress bar as the functions complete\n",
    "    # It will return a result set once all the processes have finished or an\n",
    "    # error has been encountered.\n",
    "    def parralelize(self, func, arg_set, kwarg_set):\n",
    "        \n",
    "        # Setup vars to help kick off parallelization\n",
    "        num_ops = len(arg_set)\n",
    "        self.progress_bar = self._create_progress_bar(num_ops)\n",
    "        self.shared_memory_buffer[0] = 0\n",
    "        \n",
    "        # Configure the parameters for the parallelization\n",
    "        func_set = [func for i in range(0, num_ops)]\n",
    "        internal_param_set = [\n",
    "            ([self.lock, self.shared_memory_name], \n",
    "             {\"handle_exceptions\": self.handle_exceptions}\n",
    "            ) for i in range(0, num_ops)]   \n",
    "        param_set = zip(func_set, arg_set, kwarg_set, internal_param_set)\n",
    "        \n",
    "        # Start the functions in separate parallel processes and don't block\n",
    "        apply_result = self.pool.starmap_async(self._wrapper_function, param_set)\n",
    "        \n",
    "        # Wait for the proceses to finish while updating the progress bar\n",
    "        while not apply_result.ready():\n",
    "            self._update_progress_bar(self.shared_memory_buffer[0])\n",
    "            time.sleep(0.5)\n",
    "        self._update_progress_bar(self.shared_memory_buffer[0])\n",
    "        \n",
    "        # Cleanup\n",
    "        self.shared_memory.close()\n",
    "        self.shared_memory.unlink()\n",
    "\n",
    "        # Return the results\n",
    "        return apply_result.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1bf903-b2e0-43a6-82ca-c8ccab6ba302",
   "metadata": {},
   "source": [
    "Now that we have these base objects we can test them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f43d8720-325d-4c3f-bda4-52f1f9a929c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865de1cedad246c8a2d0a858f4f599f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0\n",
      "1 -> 0\n",
      "3 -> 0\n",
      "2 -> 0\n",
      "0 -> 1\n",
      "1 -> 1\n",
      "3 -> 1\n",
      "2 -> 1\n",
      "0 -> 2\n",
      "1 -> 2\n",
      "3 -> 2\n",
      "2 -> 2\n",
      "6 -> 0\n",
      "5 -> 0\n",
      "7 -> 0\n",
      "8 -> 0\n",
      "6 -> 15 -> 1\n",
      "\n",
      "7 -> 1\n",
      "8 -> 1\n",
      "6 -> 2\n",
      "5 -> 2\n",
      "7 -> 2\n",
      "8 -> 2\n",
      "9 -> 0\n",
      "9 -> 1\n",
      "9 -> 2\n",
      "\n",
      "[0, 1, 2, 3, EnhancedProcessPoolException(<function my_func at 0x7fbc546748b0>, ((4, <AcquirerProxy object, typeid 'Lock' at 0x7fbc7006bc40>), {}), Exception('This should have been caught'), 'An error ocurred while running the parallel function'), 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the function we want to parallelize\n",
    "def my_func(idx, lock):\n",
    "    if idx == 4:\n",
    "        raise Exception(\"This should have been caught\")\n",
    "    for i in range(0, 3):\n",
    "        lock.acquire()\n",
    "        print(\"{0} -> {1}\".format(idx, i))\n",
    "        lock.release()\n",
    "        time.sleep(1)\n",
    "    return idx\n",
    "\n",
    "# Detine parameters for multithreading\n",
    "num_ops = 10\n",
    "m = multiprocessing.Manager()\n",
    "lock = m.Lock()\n",
    "my_func_arg_set = list(zip(list(range(0, num_ops)), itertools.repeat(lock)))\n",
    "my_func_kwarg_set = [{} for i in range(0, num_ops)]\n",
    "\n",
    "# Start the process in parallel\n",
    "epp = EnhancedProcessPool(num_workers=4)\n",
    "results = epp.parralelize(my_func, my_func_arg_set, my_func_kwarg_set)\n",
    "print(\"\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
