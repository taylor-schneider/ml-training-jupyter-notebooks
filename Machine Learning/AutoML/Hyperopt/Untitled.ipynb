{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be69f70-eb57-49f6-bd1e-4ed80535e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using version 0.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa631d93-1437-484d-accf-7d1279b59088",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conditional things? c1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50f7651-3a6e-42ec-91bc-d72c0f00f856",
   "metadata": {},
   "source": [
    "# Search Spaces\n",
    "As the name suggests, a [Search Space](https://hyperopt.github.io/hyperopt/getting-started/search_spaces/) is a multi-dimensional space through which we will search. The objective of the search is to find an n-dimensional point which yields the optimal result. The optimal result is objectively quantified by an objective function (loss function). In other words, the objective functrion will accept an n-dimensional point and return a numeric representation of the \"goodness\" of the point. \n",
    "\n",
    "The hyperopt framework provides the mechanism to define the search space and the algorithms to conduct the search. The user must define the objective function and the coresponding search space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73641078-04db-45df-b8ff-3d8564575229",
   "metadata": {},
   "source": [
    "## The basic problem\n",
    "I struggled with the notion of a search space at first. It is an abstract concept and the official documentation is not as robust as I would have liked being new to the project/terminology. Additionally there are many examples out there tailored to many use cases which add to the difficulty of making inferences about the library's functionality.\n",
    "\n",
    "Again, the search space is generic and polymorphic. Depending on the problem we are trying to solve the physcial characteristics of the search space (schema/topography) will change. To simplify the presentation of the material we will focus on a single problem: Choosing the best machine learning algorithm given a set of input data. As we progress through this notebook we will examine the different representations of the search space that are possible.\n",
    "\n",
    "Before putting our hands on the code, lets take a moment to think about the the problem philosophically. The first, and most obvious, question to answer (variable in our search space) is \"what model will we use\". Imagine we have a choice between \"model a\" and \"model b\". It is very likely that these models are significatnly different and require different hyperparameters. This would be our second question to answer: \"what hyperparameters will we select for the selected model\". We might be interested in exploring different search methods. We might be interested in comparing different performance metrics.\n",
    "\n",
    "With that being said, we now have a number of variables to think about... but how do we describe this space so hyperopt can search over it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878818c-d4a0-4eef-86bf-d5aa4a92ad71",
   "metadata": {},
   "source": [
    "### The basic syntax\n",
    "As mentioned earlier, there are a number of ways to skin a cat in terms of defining a search space. As we will see everything is going to boil down to an expression of some sort which defines the domain of a variable. \n",
    "\n",
    "```\n",
    "space = expression(label, parameters)\n",
    "```\n",
    "\n",
    "Hyperopt has a number of built in expression types. It also has the ability extend the builtin expressions with custom pyll functions which wee will see later.\n",
    "\n",
    "A point of note here: The label must be globally unique or you may see a *DuplicateLabel* Exception get raised. The label helps the hyperopt framework define a graph like structure through which the search is conducted. If the labels were not uniquely identified, the framework woudl not be able to understand what parameters it is looking for. This will become more clear as we look at the complex nexted examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff693102-a1b9-49cb-93dd-6cb17a9ecbee",
   "metadata": {},
   "source": [
    "### The objective function\n",
    "As stated earlier, the objective function is responsible for evaluating the \"goodness\" or \"performance\" of a model or function when it is provided with a particular parameter set. The evaluation is provided as a globally comparable metric or measurement (some type of number).\n",
    "\n",
    "```\n",
    "metric = objective(parameter_set)\n",
    "```\n",
    "\n",
    "Defining this measure is outside the scope of this notebook. At a high level, the function might be defined as:\n",
    "\n",
    "```\n",
    "def objective(parameters_set):\n",
    "\n",
    "    // Create a machine learning model\n",
    "    // Train the model\n",
    "    // Test the model\n",
    "    // return test results metric\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "For educational purposed we will instead default to a trivial measure. Our objective function will return a number representing the sum of the sample parameters it was provided from the search space. For example, consider the following:\n",
    "\n",
    "```\n",
    "metric = objective(0)\n",
    "# metric == 0\n",
    "\n",
    "metric = objective(1,2,3)\n",
    "# metric == 6\n",
    "\n",
    "```\n",
    "\n",
    "As stated earlier, defining the objective function depends on the search space. If the schema of the search space changes, so must the objective function. As we go through our examples, we will see the objective function's definition change to fit our search space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df9a4f-f40d-447d-b94e-f6a9bcb70c3a",
   "metadata": {},
   "source": [
    "# 1. Parameter Expressions\n",
    "Parameter expressions are the backbone of defining search spaces. There are two types of parameter expressions which we can leverage:\n",
    "- Stochastic Expressions - Define the domain of a stoachastic random variable\n",
    "- Pyll Expressions - Define a deterministic (non-stochastic) variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57c96f-d502-453f-b3e6-397db8800d4b",
   "metadata": {},
   "source": [
    "## 1.1. Stochastic Parameter Expressions\n",
    "Stochastic expressions allow us to define random variables according to a commpon parameterized probability distribution.\n",
    "\n",
    "Currently the following are supported:\n",
    "- choice\n",
    "- pchoice\n",
    "- randint\n",
    "- uniform\n",
    "- quniform\n",
    "- quniformint\n",
    "- loguniform\n",
    "- qloguniform\n",
    "- normal\n",
    "- qnormal\n",
    "- lognormal\n",
    "- qlognormal\n",
    "\n",
    "All of these parameter expressions are found in the hyperopt.hp module. After looking through the code and making some inferences, I believe that hp stands for hyper paremter. Thus these expressions are hyperparameter expressions.\n",
    "\n",
    "We will take a closer look at these individually in the next few sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642885e2-e98b-4bb1-897b-14c2f7558125",
   "metadata": {},
   "source": [
    "### 1.1.1. The Choice Expression\n",
    "With the choice expression, we can define a choice as a set of posisble outcomes with no specific distribution attached to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c89d7-60ab-41d0-8995-53dbc5a0e0c3",
   "metadata": {},
   "source": [
    "#### 1.1.1.1 A Univariate Choice\n",
    "Below we can define a seach space as a binary choice. In this simple case we are choosing between two models (generically named \"model a\" and \"model b\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9c60f1-49c2-42c5-b214-04e892db8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "space = hyperopt.hp.choice('my_choice', [\n",
    "    {'name': 'model a'},\n",
    "    {'name': 'model b'}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494ddcf-1be5-4f32-84b0-c631c162c27b",
   "metadata": {},
   "source": [
    "We can use the hyperopt framework to sable from this search space and examine the arguments that would be provided to our objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1978dc-4bce-4dca-8828-f527a9e69cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'model a'}\n",
      "{'name': 'model b'}\n",
      "{'name': 'model a'}\n"
     ]
    }
   ],
   "source": [
    "print(hyperopt.pyll.stochastic.sample(space))\n",
    "print(hyperopt.pyll.stochastic.sample(space))\n",
    "print(hyperopt.pyll.stochastic.sample(space))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335db2e1-0ebb-4bea-be73-db94312f35b9",
   "metadata": {},
   "source": [
    "We can define a loss function and search through our parameter space for the optimal value using the hyperopt framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6941b1ec-4b0b-483f-ade2-8066cc1da49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'model b', 'x': 2, 'y': 3}                                            \n",
      "{'name': 'model a', 'x': 6}                                                    \n",
      "{'name': 'model a', 'x': 1}                                                    \n",
      "{'name': 'model a', 'x': 4}                                                    \n",
      "{'name': 'model b', 'x': 3, 'y': 3}                                            \n",
      "{'name': 'model b', 'x': 1, 'y': 5}                                            \n",
      "{'name': 'model a', 'x': 8}                                                    \n",
      "{'name': 'model a', 'x': 6}                                                    \n",
      "{'name': 'model a', 'x': 8}                                                    \n",
      "{'name': 'model a', 'x': 2}                                                    \n",
      "100%|███████████████████████| 10/10 [00:00<00:00, 79.36trial/s, best loss: 0.0]\n",
      "=========================\n",
      "Optimal args index:\n",
      "{'model_a_x': 3, 'my_choice': 0}\n",
      "Best hyperparameters:\n",
      "{'name': 'model a', 'x': 6}\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "import numpy\n",
    "\n",
    "# Define the objective function\n",
    "def objective(args):\n",
    "    print(args)\n",
    "    if args[\"name\"] == \"model a\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Define an object to keep track of the \"trials\" in the search path\n",
    "trials = hyperopt.Trials()\n",
    "    \n",
    "# Optimize the search space and retrieve the index which points to the best points in the search space\n",
    "optimal_args_index = hyperopt.fmin(objective, space, algo=hyperopt.tpe.suggest, max_evals=10, trials=trials, rstate= numpy.random.RandomState(42))\n",
    "    \n",
    "# Retrieve the resulting hyperparameter set from the search space using the index\n",
    "optimal_hyperparams = hyperopt.space_eval(space, optimal_args_index)\n",
    "\n",
    "# Print the results\n",
    "print(\"=========================\")\n",
    "print(\"Optimal args index:\")\n",
    "print(optimal_args_index)\n",
    "print(\"Best hyperparameters:\")\n",
    "print(optimal_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406ea6e-7161-4148-a5d9-206ae8e44b73",
   "metadata": {},
   "source": [
    "We can see that \"model a\" was selected as it yields the minimal results from the objective function.\n",
    "\n",
    "**Note:** We see that the search algorithm has a lot of repetitions... This is because it the only boundary on the search is the max_evals parameter. We will look at optimizing the search algorithm later on. For example when we utilize the loss_threshold to allow for early termination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12d795-dd3f-48ba-8369-8f590a04f55f",
   "metadata": {},
   "source": [
    "Having a look at the trials opject we inspect it's type and the useful properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05dbbebf-0999-468a-8b58-cc99f1ae33bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.base.Trials at 0x32c89438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72f96ade-cf7d-42fb-9541-0b9f0ed2cd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_dynamic_trials',\n",
       " '_exp_key',\n",
       " '_ids',\n",
       " '_insert_trial_docs',\n",
       " '_trials',\n",
       " 'aname',\n",
       " 'argmin',\n",
       " 'assert_valid_trial',\n",
       " 'asynchronous',\n",
       " 'attachments',\n",
       " 'average_best_error',\n",
       " 'best_trial',\n",
       " 'count_by_state_synced',\n",
       " 'count_by_state_unsynced',\n",
       " 'delete_all',\n",
       " 'fmin',\n",
       " 'idxs',\n",
       " 'idxs_vals',\n",
       " 'insert_trial_doc',\n",
       " 'insert_trial_docs',\n",
       " 'losses',\n",
       " 'miscs',\n",
       " 'new_trial_docs',\n",
       " 'new_trial_ids',\n",
       " 'refresh',\n",
       " 'results',\n",
       " 'source_trial_docs',\n",
       " 'specs',\n",
       " 'statuses',\n",
       " 'tids',\n",
       " 'trial_attachments',\n",
       " 'trials',\n",
       " 'vals',\n",
       " 'view']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bbe1529-a6dc-4237-8801-a6b0a0ffd197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 2,\n",
       "  'tid': 0,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 1.0, 'status': 'ok'},\n",
       "  'misc': {'tid': 0,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'model_a_x': [],\n",
       "    'model_b_x': [0],\n",
       "    'model_b_y': [0],\n",
       "    'my_choice': [0]},\n",
       "   'vals': {'model_a_x': [],\n",
       "    'model_b_x': [2],\n",
       "    'model_b_y': [1],\n",
       "    'my_choice': [1]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 9, 5, 18, 27, 23, 935000),\n",
       "  'refresh_time': datetime.datetime(2021, 9, 5, 18, 27, 23, 941000)},\n",
       " {'state': 2,\n",
       "  'tid': 1,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 0.0, 'status': 'ok'},\n",
       "  'misc': {'tid': 1,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'model_a_x': [1],\n",
       "    'model_b_x': [],\n",
       "    'model_b_y': [],\n",
       "    'my_choice': [1]},\n",
       "   'vals': {'model_a_x': [3],\n",
       "    'model_b_x': [],\n",
       "    'model_b_y': [],\n",
       "    'my_choice': [0]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 9, 5, 18, 27, 23, 947000),\n",
       "  'refresh_time': datetime.datetime(2021, 9, 5, 18, 27, 23, 952000)}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.trials[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f4063-b48d-44ad-8d44-17de0d2f55f2",
   "metadata": {},
   "source": [
    "#### 1.1.1.2. A Nested Univariate Choice\n",
    "In the example below, we define the search space as a choice between two models. Each model accepts a single hyperparameter which ranges in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc48f8e-ac60-46dd-b8c7-990356156644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 10/10 [00:00<00:00, 222.21trial/s, best loss: 0.0]\n",
      "=========================\n",
      "Optimal args index:\n",
      "{'model_a_x': 0, 'my_choice': 0}\n",
      "Best hyperparameters:\n",
      "{'name': 'model a', 'x': 0}\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "import numpy\n",
    "\n",
    "# Define the search space\n",
    "space = hyperopt.hp.choice('my_choice', [\n",
    "    {\n",
    "        'name': 'model a',\n",
    "        'x': hyperopt.hp.choice('model_a_x', [0,2,4,6,8])\n",
    "    },\n",
    "    {\n",
    "        'name': 'model b',\n",
    "        'x': hyperopt.hp.choice('model_b_x', [1,3,5,7,9])\n",
    "    }\n",
    "])\n",
    "\n",
    "# Define the objective function\n",
    "def objective(args):\n",
    "    x = args['x']\n",
    "    return x\n",
    "\n",
    "# Define an object to keep track of the \"trials\" in the search path\n",
    "trials = hyperopt.Trials()\n",
    "    \n",
    "# Optimize the search space and retrieve the index which points to the best points in the search space\n",
    "optimal_args_index = hyperopt.fmin(objective, space, algo=hyperopt.tpe.suggest, max_evals=10, trials=trials, rstate= numpy.random.RandomState(42))\n",
    "    \n",
    "# Retrieve the resulting hyperparameter set from the search space using the index\n",
    "optimal_hyperparams = hyperopt.space_eval(space, optimal_args_index)\n",
    "\n",
    "# Print the results\n",
    "print(\"=========================\")\n",
    "print(\"Optimal args index:\")\n",
    "print(optimal_args_index)\n",
    "print(\"Best hyperparameters:\")\n",
    "print(optimal_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9fdee-674d-42e3-8b01-91829b96ad58",
   "metadata": {},
   "source": [
    "#### 1.1.1.3. A multivariate nested choice\n",
    "In the next example we will make things a bit more interesting. We will use models which accept a different set of hyper parameters (one of them being multivariate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f819c920-10ed-4713-b085-856240fb46ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|███████████▋       | 618/1000 [00:05<00:03, 104.51trial/s, best loss: 0.0]\n",
      "=========================\n",
      "Optimal args index:\n",
      "{'model_b_x': 0, 'model_b_y': 0, 'my_choice': 1}\n",
      "Best hyperparameters:\n",
      "{'name': 'model b', 'x': 0, 'y': 0}\n"
     ]
    }
   ],
   "source": [
    "# Define the search space\n",
    "space = hyperopt.hp.choice('my_choice', [\n",
    "    {\n",
    "        'name': 'model a',\n",
    "        'x': hyperopt.hp.choice('model_a_x', [1,2,4,6,8])\n",
    "    },\n",
    "    {\n",
    "        'name': 'model b',\n",
    "        'x': hyperopt.hp.choice('model_b_x', [0,1,2,3,4]),\n",
    "        'y': hyperopt.hp.choice('model_b_y', [0,3,5,7,9])        \n",
    "    }\n",
    "])\n",
    "\n",
    "# Define the objective function\n",
    "def objective(args):\n",
    "    x = args['x']\n",
    "    y = args['y'] if 'y' in args.keys() else 0\n",
    "    return x + y\n",
    "\n",
    "# Define an object to keep track of the \"trials\" in the search path\n",
    "trials = hyperopt.Trials()\n",
    "    \n",
    "# Optimize the search space and retrieve the index which points to the best points in the search space\n",
    "optimal_args_index = hyperopt.fmin(objective, space, algo=hyperopt.tpe.suggest, max_evals=1000, trials=trials, rstate= numpy.random.RandomState(42), loss_threshold=0.1)\n",
    "    \n",
    "# Retrieve the resulting hyperparameter set from the search space using the index\n",
    "optimal_hyperparams = hyperopt.space_eval(space, optimal_args_index)\n",
    "\n",
    "# Print the results\n",
    "print(\"=========================\")\n",
    "print(\"Optimal args index:\")\n",
    "print(optimal_args_index)\n",
    "print(\"Best hyperparameters:\")\n",
    "print(optimal_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a3cee-b3cb-488b-8c0a-961aeaae3754",
   "metadata": {},
   "source": [
    "**Note:** We had to significantly increase the mas_evals and add the loss threshold param to allow us to terminate early if the loss is less than the threshold supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6841e-6bbc-4c08-9ef4-7c0e20097fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8192a-e21f-4872-aa1b-4a8f14f5bec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbfd0f-002e-491c-af96-821caf7be6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3a17b-e7b8-40b4-9e8d-8199e64bd2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
