{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d9f478-e0e2-431b-b83f-355331c7dde9",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Recently, the databricks team has contributed the SparkTrials object to the hypeorpt project. This enhancement allows hyperopt to distribute a tuning job across an Apache Spark cluster.\n",
    "\n",
    "If you are unfamiliar with Apache Spark, review the [corresponding notebooks](../../Big%20Data%20And%20Big%20Compute/Apache%20Spark/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1342b-86a1-44b2-a1e8-877328153d06",
   "metadata": {},
   "source": [
    "As we saw in the [Hyperopt Search Trials notebok](Hyperopt%20Search%20Trials.ipynb), philosophically, a **Trial** is sample take from the Search Space. Said another way, a Trial is an observation of one of the possible scenarios defined as part of the Search Space.\n",
    "\n",
    "Under the hood, the Trials object is what controls how the Hyperopt framework iterates over the Search Space and selects the next set of hyperparameters and produces the next Trial object.\n",
    "\n",
    "There are three types of Trial objects: Trials, MongoTrials, SparkTrials. In the [Hyperopt Search Trials notebok](Hyperopt%20Search%20Trials.ipynb) we looked at the \"base\" Trials object. \n",
    "\n",
    "In this notebook We will look at the SparkTrials object produced through the [Spark Integration](Hyperopt%20Spark%20Integration.ipynb). Long story short, we will see that the interface and analysis of this object looks the same as the base Trials object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6651116-975c-41e7-ae60-e87c10f1f8ce",
   "metadata": {},
   "source": [
    "# Gotchas\n",
    "## Hyperopt version 0.2.7+ required for Apache Spark 3.0+\n",
    "It appears that the 0.2.5 release of hyperopt has a bug which makes it incompatible with spark 3.0. This is documented in an [open PR on github](https://github.com/hyperopt/hyperopt/issues/798). We must ensure we are running 0.2.7 to integration with Spark 3.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f8f92c-9238-470b-9b7f-4b8ff7b6d412",
   "metadata": {},
   "source": [
    "## Spark Limitations Affecting fmin() function\n",
    "When using the SparkTrials object, the *fmin()* function is effectively running on a Spark Executor. As such there are a few limitations we need to keep in mind that are inherited from use of the Spark function.\n",
    "\n",
    "### Object must be pickle-able\n",
    "To send information and data to the Spark Worker the Spark framework uses pickle to serialize Python objects. As such, the objects we use must be serializable through the pickle framework. If not, we might see an error like:\n",
    "\n",
    "\n",
    "```\n",
    "TypeError: can't pickle _thread.RLock objects\n",
    "```\n",
    "\n",
    "### Spark Doesn't Support Nested Parallelism\n",
    "As discussed in the [series of notebooks related to Spark](../../Big%20Data%20And%20Big%20Compute/Apache%20Spark/README.md) the Spark Executor cannot kick off trainin sessions for MLlib algorithms or other components of Spark. \n",
    "\n",
    "We may see an error similar to the one listed above when trying to use Spark functionality within the fmin() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755df42-02e1-4834-a8d6-5254d7ba2250",
   "metadata": {},
   "source": [
    "# 1. How It Works\n",
    "\n",
    "Recall from the [README.md](README.md) that hyperopt's hyperparameter tuning functionlity is invoked via the *fmin()* function. As we have seen, this function allows us to pass in a trials object to which hyperopt records information about the various training trials that are conducted while it is searching the search space.\n",
    "\n",
    "Under the hood (looking at the [github code](https://github.com/hyperopt/hyperopt/blob/master/hyperopt/fmin.py#L540)) we can see that the trials object is what actually impliments the searching process. Thus the SparkTrials object's *fmin()* function is configured to run batches of training tasks in parallel, one on each Spark executor, allowing massive scale-out for tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec8d06-8edc-417c-96ad-793d43eb7c09",
   "metadata": {},
   "source": [
    "## 1.1. Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2456c-1ce0-4590-baa2-d0e8362f6ce5",
   "metadata": {},
   "source": [
    "### 1.1.1. The Parallelism Parameter\n",
    "The databricks team has a [post](https://databricks.com/blog/2021/04/15/how-not-to-tune-your-model-with-hyperopt.html) providing insights about running hyperopt on spark. One important note is how one might use the **parallelism** parameter. this parameter dictates how many spark jobs to run in parallel. \n",
    "\n",
    "One of the major gotchas of this parameter comes from the fact that hyperopt's  [TPE search algorithm](Hyperopt%20Search%20Algorithms.ipynb) is iterative; information from the previous trials are used to determine where to look next. In the case where parallelism is set equal to the **max_evals** parameter then we are effectively doing random search as all the trials would be conducted in parallel.\n",
    "\n",
    "Another gotcha has to do with spark cluster utilization. Setting the parallelism parameter too low wastes resources. If running on a cluster with 32 cores, then running just 2 trials in parallel leaves 30 cores idle. Setting parallelism too high can cause a subtler problem. With a 32-core cluster, it’s natural to choose parallelism=32 of course, to maximize usage of the cluster’s resources. Setting it higher than cluster parallelism is counterproductive, as each wave of trials will see some trials waiting to execute.\n",
    "\n",
    "The article reccomends we **set parallelism to a small multiple of the number of hyperparameters**, and allocate cluster resources accordingly. For example, if searching over 4 hyperparameters, parallelism should not be much larger than 4. 8 or 16 may be fine, but 64 may not help a lot. 64 doesn’t hurt, it just may not help much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5d6df-ec76-443a-9e87-c441cb67febe",
   "metadata": {},
   "source": [
    "### 1.1.2. ML Library Built-in Parralelism\n",
    "Some ML libraries have the ability to take advantage of multithreading while training models. For example scikit-learn accepts the **n_jobs** parameter while xgboost accepts the **nthread** parameter. \n",
    "\n",
    "Although a single Spark task is assumed to use one core, nothing stops the task from using multiple cores. For example, with 16 cores available, one can run 16 single-threaded tasks, or 4 tasks that use 4 cores each. The latter is actually advantageous if the fitting process can efficiently use 4 cores and return the results in a timely manner. This is because Hyperopt is iterative, and returning fewer results faster improves its ability to learn from early results to schedule the next trials. That is, in this scenario, trials 5-8 could learn from the results of 1-4 if those first 4 tasks used 4 cores each to complete quickly and so on, whereas if all were run at once, none of the trials’ hyperparameter choices have the benefit of information from any of the others’ results.\n",
    "\n",
    "This affects thinking about the setting of parallelism. If a Hyperopt fitting process can reasonably use parallelism = 8, then by default one would allocate a cluster with 8 cores to execute it. But if the individual tasks can each use 4 cores, then allocating a 4 * 8 = 32-core cluster would be advantageous.\n",
    "\n",
    "One of the dangers of this approach is that Spark may schedule too many core-hungry tasks on one machine causing the cluster to be slow or unresponsive. This can be particularely troublesome if operating in a shared environment where other users/workflows are trying to share the cluster resources.\n",
    "\n",
    "A workaround is to execute the spark job using the **spark.task.cpus** parameter to tell spark the number of cores to allocate to each task. The disadvantage is that this is a cluster-wide configuration, which will cause all Spark jobs executed in the session to assume 4 cores for any task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11687d1f-34b2-4c3f-bcc4-e3149687e754",
   "metadata": {},
   "source": [
    "### 1.1.3. Spark's Serialization Impacts To Objective Function Definitions\n",
    "Recall that Spark was written as a master/slave (rebranded as driver/executor) architecture. The work on the master node is split into chunks and sent to the slaves for processing. The mechanism by which this information is sent is serialization; ie. objects are converted into a serial byte stream and sent over the network and then rebuilt at the destination.\n",
    "\n",
    "This process has an obvious overhead of computation as well as network bandwidth.\n",
    "\n",
    "In the use case of hyperparameter tuning, we will likely be using the same train/test data within our objective function which is grading the search space (we likely only be changing the hyperparameters or ML algorithm). While prototyping we may be inclined to pass this data directly to the objective function within each call. This is a bad idea. This means every time we run a task, we have to serialize the data from the driver to the executor. This is unnecessary computation.\n",
    "\n",
    "We might instead decide to broadcast the data. Reading through thespark documentaiton see that Broadcast variables are read-only variables that are cached and available to tasks on all nodes in a cluster. Instead of sending this data along with every task, spark distributes broadcast variables to the machine using efficient broadcast algorithms to reduce communication costs. The problem with broadcast variables however is that they are limited to 2GB of data.\n",
    "\n",
    "As each spark task is a separate java process, the only other option is to do some advanced programming to load the data into a large shared memory object in the heap that can be used between tasks. Or possibly setting up a caching server of some kind that can quickly serve a raw byte stream. But that is outside our scope.\n",
    "\n",
    "Practically speaking, if the train/test set is larger that 2GB you might simply have to reach out to the datastore and load the data each time the function runs. The benefit to this approach is you free up resources on the executor which will likely allow your workflow to run more moothly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832b73b-3662-4fb0-a39d-9fbc04719d96",
   "metadata": {},
   "source": [
    "### 1.1.4. Suggestions on setting max_evals\n",
    "We have seen that the *fmin()* function takes a parameter called max_evals which dictates how many trials within the search space to conduct. For example, if we set max_evals=20 then the search algorithm would run 20 times on data points selected from the search space.\n",
    "\n",
    "Databricks has made a [reccomendation](https://databricks.com/blog/2021/04/15/how-not-to-tune-your-model-with-hyperopt.html) on a method for choosing the value for max_evals:\n",
    "\n",
    "<table>\n",
    "  <tbody>\n",
    "<tr>\n",
    "<th>Parameter Expression</th>\n",
    "<th>Optimal Results</th>\n",
    "<th>Fastest Results</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>(ordinal parameters)<p></p>\n",
    "<p>hp.uniform<br>\n",
    "hp.quniform<br>\n",
    "hp.loguniform<br>\n",
    "hp.qloguniform</p></td>\n",
    "<td>20 x # parameters</td>\n",
    "<td>10 x # parameters</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>(categorical parameters)<p></p>\n",
    "<p>hp.choice</p></td>\n",
    "<td colspan=\"2\">15 x total categorical breadth*</td>\n",
    "</tr>\n",
    "</tbody>  \n",
    "</table>\n",
    "\n",
    "**Note:** “total categorical breadth” is the total number of categorical choices in the space.  If you have hp.choice with two options “on, off”, and another with five options “a, b, c, d, e”, your total categorical breadth is 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610cdd8-ff0b-4bdf-a542-94c609ec6007",
   "metadata": {},
   "source": [
    "# 2. Define Search Space And Conduct Search Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb446f9-30ea-4330-922c-b454cbb1144c",
   "metadata": {},
   "source": [
    "## 2.1. Setup Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b9dd35-0a09-4360-9564-e829ab7f6887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ml-training-jupyter-notebooks\n"
     ]
    }
   ],
   "source": [
    "import pyprojroot\n",
    "project_root_dir  = pyprojroot.here()\n",
    "print(project_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0873fb-c67c-4ff7-909f-51c2881bb67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading module: /root/ml-training-jupyter-notebooks/Utilities/spark_helper.py\n"
     ]
    }
   ],
   "source": [
    "# Load a helper module\n",
    "import os\n",
    "import importlib.util\n",
    "module_name = \"spark_helper\"\n",
    "module_dir = os.path.join(project_root_dir, \"Utilities\", \"{0}.py\".format(module_name))\n",
    "if not os.path.exists(module_dir):\n",
    "    print(\"The helper module does not exist\")\n",
    "print(\"Loading module: {0}\".format(module_dir))\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_dir)\n",
    "spark_helper = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(spark_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0caaa2-86f9-4229-85de-d13bc67bd7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting SPARK_HOME\n",
      "/opt/spark\n",
      "\n",
      "Running findspark.init() function\n",
      "['/opt/spark/python', '/opt/spark/python/lib/py4j-0.10.9-src.zip', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '', '/usr/local/lib64/python3.6/site-packages', '/usr/local/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', '/usr/local/lib/python3.6/site-packages/IPython/extensions', '/root/.ipython']\n",
      "\n",
      "Setting PYSPARK_PYTHON\n",
      "/usr/bin/python3\n",
      "\n",
      "Configuring URL for kubernetes master\n",
      "k8s://https://15.4.7.11:6443\n",
      "\n",
      "Determining IP Of Server\n",
      "The ip was detected as: 15.4.12.12\n",
      "\n",
      "Creating SparkConf Object\n",
      "('spark.master', 'k8s://https://15.4.7.11:6443')\n",
      "('spark.app.name', 'spark-jupyter-mlib')\n",
      "('spark.submit.deploy.mode', 'cluster')\n",
      "('spark.kubernetes.container.image', 'tschneider/pyspark:v6-beta')\n",
      "('spark.kubernetes.namespace', 'spark')\n",
      "('spark.kubernetes.pyspark.pythonVersion', '3')\n",
      "('spark.kubernetes.authenticate.driver.serviceAccountName', 'spark-sa')\n",
      "('spark.kubernetes.authenticate.serviceAccountName', 'spark-sa')\n",
      "('spark.executor.instances', '3')\n",
      "('spark.executor.cores', '2')\n",
      "('spark.executor.memory', '4096m')\n",
      "('spark.executor.memoryOverhead', '1024m')\n",
      "('spark.driver.memory', '1024m')\n",
      "('spark.driver.host', '15.4.12.12')\n",
      "('spark.files.overwrite', 'true')\n",
      "('spark.files.useFetchCache', 'false')\n",
      "\n",
      "Creating SparkSession Object\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "spark_app_name = \"spark-jupyter-mlib\"\n",
    "docker_image = \"tschneider/pyspark:v6-beta\"\n",
    "k8_master_ip = \"15.4.7.11\"\n",
    "spark_session = spark_helper.create_spark_session(spark_app_name, docker_image, k8_master_ip)\n",
    "sc = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d19ad6c-d7f2-4d21-8915-c97381d2491e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                         READY     STATUS    RESTARTS   AGE\n",
      "spark-jupyter-mlib-cffb937dd4846132-exec-1   1/1       Running   0          32s\n",
      "spark-jupyter-mlib-cffb937dd4846132-exec-2   1/1       Running   0          31s\n",
      "spark-jupyter-mlib-cffb937dd4846132-exec-3   1/1       Running   0          31s\n"
     ]
    }
   ],
   "source": [
    "! kubectl -n spark get pod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf82e6b-5ffb-4802-88c9-7e037579c424",
   "metadata": {},
   "source": [
    "## 2.2. Define Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef9c60f1-49c2-42c5-b214-04e892db8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "# Define the search space\n",
    "space = hyperopt.hp.choice('my_choice', [\n",
    "    {\n",
    "        'name': 'model a',\n",
    "        'x': hyperopt.hp.choice('model_a_x', [1,2,4,6,8])\n",
    "    },\n",
    "    {\n",
    "        'name': 'model b',\n",
    "        'x': hyperopt.hp.choice('model_b_x', [0,1,2,3,4]),\n",
    "        'y': hyperopt.hp.choice('model_b_y', [0,3,5,7,9])        \n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398c851-3d7f-4d78-8d16-918b57f117df",
   "metadata": {},
   "source": [
    "We can have a look at a single sample to see what is passed to the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307a1aa8-7369-4656-8469-95ad6372d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'model b', 'x': 3, 'y': 3}\n"
     ]
    }
   ],
   "source": [
    "print(hyperopt.pyll.stochastic.sample(space))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c631f5-b6ab-49b3-87c6-7461c3c229be",
   "metadata": {},
   "source": [
    "## 2.3. Define Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fad6b41-e55d-4783-b3a0-0dc67de04dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    x = args['x']\n",
    "    y = args['y'] if 'y' in args.keys() else 0\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28237c-9d8e-47d7-8b35-0600c8fc78a4",
   "metadata": {},
   "source": [
    "## 2.4. Create SparkTrials Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a637b1d-a8f8-4413-a248-9102b65a96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = hyperopt.SparkTrials(parallelism=3, spark_session=spark_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92fbe46-e7ea-4cbe-9981-423b31fac4ff",
   "metadata": {},
   "source": [
    "## 2.5. Perform Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335db2e1-0ebb-4bea-be73-db94312f35b9",
   "metadata": {},
   "source": [
    "We can define a loss function and search through our parameter space for the optimal value using the hyperopt framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b63cd78-5606-4167-92ae-688d0b544f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.12s/trial, best loss: 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Trials: 10: 10 succeeded, 0 failed, 0 cancelled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Optimal args index:\n",
      "{'model_a_x': 0, 'my_choice': 0}\n",
      "Best hyperparameters:\n",
      "{'name': 'model a', 'x': 1}\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "import numpy\n",
    "\n",
    "# Optimize the search space and retrieve the index which points to the best points in the search space\n",
    "optimal_args_index = hyperopt.fmin(objective, \n",
    "                                   space, \n",
    "                                   algo=hyperopt.tpe.suggest, \n",
    "                                   max_evals=10, \n",
    "                                   trials=trials, \n",
    "                                   rstate=numpy.random.default_rng(42))\n",
    "\n",
    "# Retrieve the resulting hyperparameter set from the search space using the index\n",
    "optimal_hyperparams = hyperopt.space_eval(space, optimal_args_index)\n",
    "\n",
    "# Print the results\n",
    "print(\"=========================\")\n",
    "print(\"Optimal args index:\")\n",
    "print(optimal_args_index)\n",
    "print(\"Best hyperparameters:\")\n",
    "print(optimal_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406ea6e-7161-4148-a5d9-206ae8e44b73",
   "metadata": {},
   "source": [
    "We can see that \"model a\" was selected as it yields the minimal results from the objective function.\n",
    "\n",
    "**Note:** We see that the search algorithm has a lot of repetitions... This is because it the only boundary on the search is the max_evals parameter. We will look at optimizing the search algorithm later on. For example when we utilize the loss_threshold to allow for early termination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12d795-dd3f-48ba-8369-8f590a04f55f",
   "metadata": {},
   "source": [
    "Having a look at the trials opject we inspect it's type and the useful properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05dbbebf-0999-468a-8b58-cc99f1ae33bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.spark.SparkTrials at 0x7f6bb18376d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "564a84c2-14c2-43c2-9b90-cbe6931bd48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAX_CONCURRENT_JOBS_ALLOWED',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_decide_parallelism',\n",
       " '_dynamic_trials',\n",
       " '_exp_key',\n",
       " '_fmin_cancelled',\n",
       " '_fmin_cancelled_reason',\n",
       " '_ids',\n",
       " '_insert_trial_docs',\n",
       " '_spark',\n",
       " '_spark_context',\n",
       " '_spark_pinned_threads_enabled',\n",
       " '_spark_supports_job_cancelling',\n",
       " '_trials',\n",
       " 'aname',\n",
       " 'argmin',\n",
       " 'assert_valid_trial',\n",
       " 'asynchronous',\n",
       " 'attachments',\n",
       " 'average_best_error',\n",
       " 'best_trial',\n",
       " 'count_by_state_synced',\n",
       " 'count_by_state_unsynced',\n",
       " 'count_cancelled_trials',\n",
       " 'count_failed_trials',\n",
       " 'count_successful_trials',\n",
       " 'count_total_trials',\n",
       " 'delete_all',\n",
       " 'fmin',\n",
       " 'idxs',\n",
       " 'idxs_vals',\n",
       " 'insert_trial_doc',\n",
       " 'insert_trial_docs',\n",
       " 'loss_threshold',\n",
       " 'losses',\n",
       " 'miscs',\n",
       " 'new_trial_docs',\n",
       " 'new_trial_ids',\n",
       " 'parallelism',\n",
       " 'refresh',\n",
       " 'results',\n",
       " 'source_trial_docs',\n",
       " 'specs',\n",
       " 'statuses',\n",
       " 'tids',\n",
       " 'timeout',\n",
       " 'trial_attachments',\n",
       " 'trials',\n",
       " 'vals',\n",
       " 'view']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde59ae-21a3-486b-999d-ad219d373957",
   "metadata": {},
   "source": [
    "# 3. Common Analysis Tasks\n",
    "In the next section we look at code examples of extracting valuable information from the Trials object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896901c5-17f6-49f7-87dc-82cf74bc9f26",
   "metadata": {},
   "source": [
    "## 3.1. Get Trial Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "419785e9-6538-408f-8953-41f5879b599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 2,\n",
       "  'tid': 0,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 8.0, 'status': 'ok'},\n",
       "  'misc': {'tid': 0,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'model_a_x': [0],\n",
       "    'model_b_x': [],\n",
       "    'model_b_y': [],\n",
       "    'my_choice': [0]},\n",
       "   'vals': {'model_a_x': [4],\n",
       "    'model_b_x': [],\n",
       "    'model_b_y': [],\n",
       "    'my_choice': [0]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 12, 19, 21, 8, 8, 913000),\n",
       "  'refresh_time': datetime.datetime(2021, 12, 19, 21, 8, 9, 980000)},\n",
       " {'state': 2,\n",
       "  'tid': 1,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 4.0, 'status': 'ok'},\n",
       "  'misc': {'tid': 1,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'model_a_x': [],\n",
       "    'model_b_x': [1],\n",
       "    'model_b_y': [1],\n",
       "    'my_choice': [1]},\n",
       "   'vals': {'model_a_x': [],\n",
       "    'model_b_x': [1],\n",
       "    'model_b_y': [1],\n",
       "    'my_choice': [1]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 12, 19, 21, 8, 9, 916000),\n",
       "  'refresh_time': datetime.datetime(2021, 12, 19, 21, 8, 11, 27000)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.trials[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f7298-f078-4873-b554-e058eb998239",
   "metadata": {},
   "source": [
    "## 3.2. Get Best Trial Metadata\n",
    "We can see the best trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9542c1e8-5b5b-4013-a8ce-3d254c5875eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 2,\n",
       " 'spec': None,\n",
       " 'result': {'loss': 1.0, 'status': 'ok'},\n",
       " 'misc': {'tid': 2,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'model_a_x': [2],\n",
       "   'model_b_x': [],\n",
       "   'model_b_y': [],\n",
       "   'my_choice': [2]},\n",
       "  'vals': {'model_a_x': [0],\n",
       "   'model_b_x': [],\n",
       "   'model_b_y': [],\n",
       "   'my_choice': [0]}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2021, 12, 19, 21, 8, 10, 918000),\n",
       " 'refresh_time': datetime.datetime(2021, 12, 19, 21, 8, 12, 7000)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0c2e4-383a-47c8-bcd5-a93c0faf0217",
   "metadata": {},
   "source": [
    "## 3.3. Get Trial ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "382a1d34-280f-4e4e-9526-2ea9cca6b1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.trials[0][\"tid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d56d6-6065-4865-a2f6-bf11f7ba484e",
   "metadata": {},
   "source": [
    "## 3.4. Get Hyperparameters For Best Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64c510b9-e0b9-4a84-a2f2-46a0fce30ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_a_x': 0, 'my_choice': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f72d001-8c1c-4a18-8d73-362041eeb711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model a', 'x': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperopt.space_eval(space, trials.argmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7607fd-6116-4b48-bfa9-167ff6069058",
   "metadata": {},
   "source": [
    "## 3.5. Get Hyperparameters For Arbitrary Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "540aaf0b-52e8-4ffd-9a11-3786ae86ec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_a_x': [0], 'model_b_x': [], 'model_b_y': [], 'my_choice': [0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.trials[2][\"misc\"][\"vals\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d726993-5987-4d70-b583-84aed964b534",
   "metadata": {},
   "source": [
    "We need to convert this value into another form. The [source code](https://github.com/hyperopt/hyperopt/blob/0b49cde7c0860542b17e8f6102dcf46af4739d23/hyperopt/base.py#L619) for doing this is in the *argmin* property on the Trials object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e0a6d6b-dca2-4bf7-9914-17f796216a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_a_x': 0, 'my_choice': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = trials.trials[2][\"misc\"][\"vals\"]\n",
    "\n",
    "def correct_vals_object_format(vals):\n",
    "    rval = {}\n",
    "    for k, v in list(vals.items()):\n",
    "        if v:\n",
    "            rval[k] = v[0]\n",
    "    return rval\n",
    "        \n",
    "corrected_vals = correct_vals_object_format(vals)\n",
    "corrected_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fb4ca-91ab-4b17-af12-ab788a1e7302",
   "metadata": {},
   "source": [
    "Once converted, we can use the same *space_eval* function to derive the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "820a6044-67b3-4986-878f-6ca3b68361a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model a', 'x': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperopt.space_eval(space, corrected_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538681a2-8eaa-43ec-8f36-514bcdf5d19a",
   "metadata": {},
   "source": [
    "## 3.6. Get Scores For A Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "131cfbfd-d74c-421a-b383-dd1d5cb48e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 8.0, 'status': 'ok'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
