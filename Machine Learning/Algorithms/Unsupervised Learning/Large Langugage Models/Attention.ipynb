{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef02c9-e429-45ff-91c0-d73be3bf541e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a91c2-d9f1-423b-971b-ee9992126db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce3ccf18-a4fe-4b0b-8af7-da092db95036",
   "metadata": {},
   "source": [
    "The attention mechanism was originally popularized in Neural Machine Translation by Jointly Learning to Align and Translate(2014), which is the guiding reference for this particular post. This paper employs an encoder-decoder architecture for english-to-french translation.\n",
    "\n",
    "https://towardsdatascience.com/attention-from-alignment-practically-explained-548ef6588aa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b978d-60f6-448d-95c0-1e73b27da5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63354201-16ed-42b1-990b-7bae461b7d09",
   "metadata": {},
   "source": [
    "Here, alignment is the problem in machine translation that identifies which parts of the input sequence are relevant to each word in the output, whereas translation is the process of using the relevant information to select the appropriate output. \n",
    "\n",
    "https://medium.com/data-science-community-srm/understanding-encoders-decoders-with-attention-based-mechanism-c1eb7164c581\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f1f43-c518-46d6-9492-c49be0833994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aca0dfc2-2069-4b02-a816-81adb26ed126",
   "metadata": {},
   "source": [
    "Human friendly explanation:\n",
    "\n",
    "https://txt.cohere.com/what-is-attention-in-language-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba635acc-05ac-4947-b4d5-9ab6ab6c969c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e482c995-bb62-4dcc-8a31-e768a18c42bf",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1028e-3f66-47c9-afff-14d01b4deb67",
   "metadata": {},
   "source": [
    "A problem with classical word embeddings comes from the fact that they do not provide a mechanism for representing words with multiple meanings. As such, when performing tasks relating to translation or NLP for example, the prediction will be sub optimal because.\n",
    "\n",
    "To solve this problem, researches started considering context (i.e. the neighnoring words in a sentance) as the mechanism through which one could derive the coresponding meaning of a word. That is, certain words in a sentence or paragraph would influence or imply the meaning of a given word. \n",
    "\n",
    "With this a priori expectaion, words would be expected to have multiple meanings as there would inevitably be multiple instances of them appearing within multiple observed contexts. And thus the language models would need to provide a mechanism that considers context.\n",
    "\n",
    "As we will see, Attention is a mechanism (an implimentation) for how we can get a nueral network to understand the context of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014723ed-cbc3-4be2-8403-764d78e5b240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "403d513e-7b01-4487-9185-560976693550",
   "metadata": {},
   "source": [
    "Encouraged by recent advances in caption generation and inspired by recent success in employing attention\n",
    "in machine translation (Bahdanau et al., 2014) and object\n",
    "recognition (Ba et al., 2014; Mnih et al., 2014), we investigate models that can attend to salient part of an image while\n",
    "generating its caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa187402-7d94-459f-b7d7-640063fb50dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52a35fd7-0582-4b8c-95d9-577ff7fb0914",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5ae23-2cb9-42d1-8514-c0bf77a0cd3e",
   "metadata": {},
   "source": [
    "## Kalchbrenner et. al., (2014) - Variable Input Length Using CNNs\n",
    "In April of 2014, a paper titled *\"A Convolutional Neural Network for Modelling Sentences\n",
    "\"* was [published](https://arxiv.org/abs/1404.2188).\n",
    "\n",
    "In this paper, Kalchbrenner et. al. put forward a novel convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) which handles input sentences of varying length. Additionally the model is capable of capturing short and long-range relations.\n",
    "\n",
    "The ability to handle input sequences with variable sizes is facilitated by sequentially processing one token at a time, or by specially designed convolution kernels.\n",
    "\n",
    "> This approach can lead to significant problems when the input is truly of varying size with varying information content, such as in Section 10.7 in the transformation of text (Sutskever et al., 2014). In particular, for long sequences it becomes quite difficult to keep track of everything that has already been generated or even viewed by the network. Even explicit tracking heuristics such as proposed by Yang et al. (2016) only offer limited benefit.\n",
    ">\n",
    "> https://d2l.ai/chapter_attention-mechanisms-and-transformers/queries-keys-values.html\n",
    "\n",
    "Additionally, this sequential processeing leads to a performance hit compared to modern approaches which are able to compute in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a7bb7e-2c67-489a-b360-364da435fbe4",
   "metadata": {},
   "source": [
    "## Mnih et. al. (2014) \n",
    "\n",
    "In June 2014, *Recurrent Models of Visual Attention* was published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564455b7-5043-4d13-b8be-46b141ec3cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12462-2d80-4ca6-9909-95c2a840cce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a0f2b25-83f8-4f82-8331-b3f96a3ef0e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bahdanau et. al. (2015) - Global Soft Attention In NMT\n",
    "\n",
    "In September 2014, Bahdanau et. al. [published](https://arxiv.org/abs/1409.0473) *Neural Machine Translation by Jointly Learning to Align and Translate*. \n",
    "\n",
    "In their paper, Bahdanau et. at. describer their model arthictecture as an extension of the encode-decoder architecture.\n",
    "\n",
    "> The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb06af6-67de-4f61-8945-10a6bfaf326e",
   "metadata": {},
   "source": [
    "The authors go on to describe the differences between hard and soft alignment.\n",
    "\n",
    "> Consider the source phrase [the man] which was translated into [l’ homme]. Any hard\n",
    "alignment will map [the] to [l’] and [man] to [homme]. This is not helpful for translation, as one\n",
    "must consider the word following [the] to determine whether it should be translated into [le], [la],\n",
    "[les] or [l’]. Our soft-alignment solves this issue naturally by letting the model look at both [the] and\n",
    "[man], and in this example, we see that the model was able to correctly translate [the] into [l’].\n",
    "\n",
    "They comment that a natural output of the soft attention is that differences between input and output sequence length are naturally handled by the attention mechanism and open the door to veriable length sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120cfc2f-a4b4-45c4-b99e-92bca80ae5d3",
   "metadata": {},
   "source": [
    "Additionally the authors advocated that ehtier soft attention mechanism outperforms the prior hard attention implimentsions:\n",
    "\n",
    "<center><img src=\"images/monotonic_soft_attention.png\" style=\"width:75%\"></center>\n",
    "\n",
    "\n",
    "> We can see from the alignments in Fig. 3 that the alignment of words between English and French\n",
    "is largely monotonic. We see strong weights along the diagonal of each matrix. However, we also\n",
    "observe a number of non-trivial, non-monotonic alignments. Adjectives and nouns are typically\n",
    "ordered differently between French and English, and we see an example in Fig. 3 (a). From this\n",
    "figure, we see that the model correctly translates a phrase [European Economic Area] into [zone\n",
    "economique europ ´ een]. The RNNsearch was able to correctly align [zone] with [Area], jumping ´\n",
    "over the two words ([European] and [Economic]), and then looked one word back at a time to\n",
    "complete the whole phrase [zone economique europ ´ eenne]. ´\n",
    ">\n",
    "> The strength of the soft-alignment, opposed to a hard-alignment, is evident, for instance, from\n",
    "Fig. 3 (d). Consider the source phrase [the man] which was translated into [l’ homme]. Any hard\n",
    "alignment will map [the] to [l’] and [man] to [homme]. This is not helpful for translation, as one\n",
    "must consider the word following [the] to determine whether it should be translated into [le], [la],\n",
    "[les] or [l’]. Our soft-alignment solves this issue naturally by letting the model look at both [the] and\n",
    "[man], and in this example, we see that the model was able to correctly translate [the] into [l’]. We\n",
    "observe similar behaviors in all the presented cases in Fig. 3. An additional benefit of the soft alignment is that it naturally deals with source and target phrases of different lengths, without requiring a\n",
    "counter-intuitive way of mapping some words to or from nowhere ([NULL]) (see, e.g., Chapters 4\n",
    "and 5 of Koehn, 2010)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4c366-9acb-4236-982a-15da94e6f13a",
   "metadata": {},
   "source": [
    "Note: The attention mechanism proposed in this paper will later be referred to as a type of global attention mechanism by Luong et. al. (2015). Luong notes that while more complicated than the global attention mechanism he proposes, in the field of NMT, \n",
    "Bahdanau was first to propose global attention.\n",
    "\n",
    ">To the best of our knowledge, there has not been any other work exploring the use of attention-based architectures for NMT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44bf33a-7aec-4e27-b62d-53d94dbf913b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Luong, et al., 2015)\n",
    "> Luong, et al., 2015 proposed the “global” and “local” attention. The global attention is similar to the soft attention, while the local one is an interesting blend between hard and soft, an improvement over the hard attention to make it differentiable: the model first predicts a single aligned position for the current target word and a window centered around the source position is then used to compute a context vector.\n",
    ">\n",
    "> [source](https://lilianweng.github.io/posts/2018-06-24-attention/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd10721-9b01-45e2-8bed-f05524387e1b",
   "metadata": {},
   "source": [
    "## Xu et. al. (2015) - Applying Soft/Hard Attention To Image Processsing\n",
    "\n",
    "In Feb 2015, Xu et. al. [published](https://arxiv.org/abs/1502.03044) *Show, Attend and Tell: Neural Image Caption Generation with Visual Attention* which introduces an attention based model that automatically learns to describe the content of images and is inspired by recent work in machine translation and object detection. \n",
    "\n",
    "In the paper they describe two attention mechanisms which they apply to caption generation.\n",
    "\n",
    "> We introduce two attention-based image caption generators under a common framework (Sec. 3.1): 1) a “soft” deterministic attention mechanism trainable by standard back-propagation methods and 2) a “hard” stochastic attention mechanism trainable by maximizing an approximate variational lower bound or equivalently by REINFORCE (Williams, 1992)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68555af-e459-48ac-a179-dd4a23066429",
   "metadata": {},
   "source": [
    "## Luong et. al. (2015) - Simplified Approach To Local and Global Attention\n",
    "In August 2015, Luang et all [published](https://arxiv.org/abs/1508.04025) *Effective Approaches to Attention-based Neural Machine Translation* which introduces two architectures for neural machine translation (NMT); those being global and local attention.\n",
    "\n",
    "> This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches over the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems which already incorporate known techniques such as dropout. Our ensemble model using different attention architectures has established a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker.\n",
    ">\n",
    "> In this work, we design, with simplicity and effectiveness in mind, two novel types of attentionbased models: a global approach in which all source words are attended and a local one whereby only a subset of source words are considered at a\n",
    "time. The former approach resembles the model of (Bahdanau et al., 2015) but is simpler architecturally. The latter can be viewed as an interesting blend between the hard and soft attention models proposed in (Xu et al., 2015): it is computationally less expensive than the global model or the soft attention; at the same time, unlike the hard attention, the local attention is differentiable almost everywhere, making it easier to implement and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca303da-8404-4c95-8e8d-092418a89021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "618d632c-61df-4587-9cac-885570b8d24f",
   "metadata": {},
   "source": [
    "# How Attention Works (Conceptually)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7956db5f-e47e-4c0d-8153-d71406c90da8",
   "metadata": {},
   "source": [
    "With attention, the basic idea is that some words matter more when determining the meaning of a word within a particular context. Saying it differently, when paying attention to a particular word, in a given context, some words are more relevant to the given word's meaning than others.\n",
    "\n",
    "In an overly simplified way, we can think of attention as a weighting mechanism that attaches a weight of importance to the words in a particular context relative to a given word we are paying attention to. The words that are more important or relevant have a higher weight than those. Thus, each word is going to map to an \"attention\" vector which holds the attention weights for al the other words in the given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27042ba9-f03b-424c-b03c-1f5818e55016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20631d42-c2c1-4e35-afd0-2f442b0ee835",
   "metadata": {},
   "source": [
    "https://txt.cohere.com/what-is-attention-in-language-models/\n",
    "\n",
    "https://stats.stackexchange.com/questions/599085/training-transformers-self-attention-weights-vs-embedding-layer\n",
    "\n",
    "https://txt.cohere.com/what-is-attention-in-language-models/#:~:text=Attention%20is%20a%20very%20clever,embeddings%20into%20contextualized%20word%20embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a795d-8803-4f65-8794-20c5d337b118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12aa271f-2b9e-47fc-b4e4-4991d6aa23d2",
   "metadata": {},
   "source": [
    "Conceptually, the attention mechanism will explain the relevance or interdependence between a given input token and the other tokens in the input sequence. The intention is that this understanding of relevance between tokens provides the fondational context required to understand the true meaning of a word.\n",
    "\n",
    "https://blog.floydhub.com/attention-mechanism/\n",
    "\n",
    "Though there are several implimentations for attention, the consistent approach is that the relevance of the tokens in the input sequence relative to the token in question is explained via a numeric score ranging between 0 and 1. If the related token has a high attention score, it means the token is very relevant to the task at hand. If the related token has a low attention score, it means the token is less relevant to the task at hand. Another important mathematical property is that the sum of the attention scores is one. Thus the attention score quantifies the amount of \"attention\" we should pay to a particular token while performing a given task (e.g. translation or question and answer).\n",
    "\n",
    "**Note**: The tokens will never have an attention score of zero. This is one of the main disadvantages of the current class of attention approaches. Because every attention score is non zero, it means every token is involved in calculation for the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ebb074-2a7f-4fda-b9b7-584da0237fb8",
   "metadata": {},
   "source": [
    "In their [paper](https://arxiv.org/pdf/1409.0473.pdf), (bahdanau et al., 2014) show how the attention scores allow the model to dynamically determine the soft-alignment of the input and output sequences. Specifically, they show several instances where the attention model is able to change the order of words from their exact literal translation to a gramatically correct translation.\n",
    "\n",
    "<center><img src=\"./images/attention_swapping_word_order.png\" style=\"width:50%\"></center>\n",
    "\n",
    "> Figure 3: Four sample alignments found by RNNsearch-50. The x-axis and y-axis of each plot\n",
    "correspond to the words in the source sentence (English) and the generated translation (French),\n",
    "respectively. Each pixel shows the weight $\\alpha_{ij}$ of the annotation of the j-th source word for the i-th\n",
    "target word (see Eq. (6)), in grayscale (0: black, 1: white). (a) an arbitrary sentence. (b–d) three\n",
    "randomly selected samples among the sentences without any unknown words and of length between\n",
    "10 and 20 words from the test set.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a15f0-c6d4-4787-83a6-9bf4cfee6d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f652bce-76d7-4339-b079-2f971e7cc1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb3fb84a-3160-4dd2-bc8f-aea102263136",
   "metadata": {},
   "source": [
    "## Types Of Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3797d73-f59a-44b3-84c6-e713c8012d31",
   "metadata": {},
   "source": [
    "### Implicit vs Explicit\n",
    "\n",
    "I believe these terms, in the context of data science, are analogs of their neuro-biological counterparts dealing with actual physical human attention mechanisms (for example [this article](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01861/full). From what I understand, one way of thinking about attention is to classify the attention mechanism as either implicit or explicit.\n",
    "\n",
    "Explicit attention mechanisms are voluntarily focused on goal relevant stimuli from the environment. For example, if we are looking for pictures of vehicles trying to classify them as car or truck, we will be focusing on the groups of pixels in the image most related to the classification problem; more likely, we will be focusing on the gradient of the loss function. Thinking about translation on the other hand, explicit attention would focus on the words most relvant to the proper translation.\n",
    "\n",
    "Implicit attention mechanisms are involunarily focused on stimuli who's inherant properties inadvertantly manipulate the attention mechanism. In the human analogy, the images may invoke an emotional response that causes us to focus on features of the stimuli which are irrelevant to the stated goal of classification. In the literal case of deep neural networks, it's possible that the physical structure of the network impact the attention mechanism without a direct causal relationship being defined a priori with respect to the stated goal. Thinking about translation, it may be that a particular passage or set of words comes into focus because of some conincidental relationship with the model's current state or architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c625b-060d-4e3e-8182-f66350a5787b",
   "metadata": {},
   "source": [
    "Putting it simply, With explicit attention, the physical system is deigned to adjust the attention mechanism based on the model performance during training. With implicit attention, the attention mechanism is not explicitly alterered as part of the training process; instead any changes to the attention mechanism are an unintentional byproduct.\n",
    "\n",
    "An article worth reading [link](https://www.linkedin.com/pulse/attention-mechanism-part-1-english-version-hay-hoffman/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1e9fc-d2d2-43ad-8cbe-c52300b8b404",
   "metadata": {},
   "source": [
    "### Hard Vs. Soft\n",
    "\n",
    "Generally speaking, at the core of every attention mechanism is a function which assigns attention scores. These functions, and thus the attention mechanisms, are classified as being either soft or hard. Soft attention functions ar characterized by their continuous, smooth, differentiable nature. Hard attention functions are discrete, non-smooth, and non-differentiable.\n",
    "\n",
    "https://theaisummer.com/attention/#types-of-attention-hard-vs-soft\n",
    "\n",
    "The characteristic of being differentiable is important with respect to neural network archiectecure because back propogation does not work if a function is non-differentiable.\n",
    "\n",
    "https://stats.stackexchange.com/questions/386535/why-cant-we-use-back-propagation-in-hard-attention-but-we-can-use-it-in-relu#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d781d-62a6-4ca0-aaee-1e8e4dbe86fc",
   "metadata": {},
   "source": [
    "### Local vs. Global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcba10-96a7-4bd3-a0d7-0b872c705e72",
   "metadata": {},
   "source": [
    "Global attention describes attention mechanisms that consider all input stimuli (e.g. pixels or words) while local attention considers a curated set of words. This curation could be affected asa result of hard/soft characteristics or implicit/explicit design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61286976-61ea-4e1b-97b4-96a3258a4a39",
   "metadata": {},
   "source": [
    "> Luong, et al., 2015 proposed the “global” and “local” attention. The global attention is similar to the soft attention, while the local one is an interesting blend between hard and soft, an improvement over the hard attention to make it differentiable: the model first predicts a single aligned position for the current target word and a window centered around the source position is then used to compute a context vector.\n",
    ">\n",
    "> [source](https://lilianweng.github.io/posts/2018-06-24-attention/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70db33-dec9-43b0-97cd-284a40f1f82b",
   "metadata": {},
   "source": [
    "# How Attention Works (Mathematically)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bbd56c-897b-444d-b0dd-760ac179c8da",
   "metadata": {},
   "source": [
    "The attention mechanism is designed to work with embeddings not raw inputs. As such we must first calculate the word embeddings for the given input. \n",
    "\n",
    "<center><img src=\"./images/transformer_word_embeddings_example2.png\" style=\"width:75%\"></center>\n",
    "\n",
    "<div style=\"text-align:right\"><a href=\"https://jalammar.github.io/illustrated-transformer\">[img source]</a><div>\n",
    "\n",
    "Below we can see an example of a matrix which contains the embedding vectors for each word in the given input sequence \"Thinking Machines\":\n",
    "\n",
    "**Note**: The deimensionality of this matrix are (token count x embedding length).\n",
    "\n",
    "    \n",
    "<center><img src=\"./images/transformer_word_embeddings_example.png\" style=\"width:30%\"></center>\n",
    "\n",
    "    \n",
    "<div style=\"text-align:right\"><a href=\"https://jalammar.github.io/illustrated-transformer\">[img source]</a><div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571cb6c-ee3f-4ba3-94a0-cf69d8296786",
   "metadata": {},
   "source": [
    "Next is to calculate three intermediary matrices $Q$, $K$, and $V$ which are referred to as they query, key, and value vectors respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a5779-dd2e-4fe5-8b91-87ff2991f7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e967388-0689-4a58-8577-a66c54f37614",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5a07e-bafe-4df4-bca9-4cb692118b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2836c4f9-6090-406e-bbcb-e0a2e1327856",
   "metadata": {},
   "source": [
    "These matrices are produced by applying linear transformations ($W_K$,$W_Q$, and $W_V$) to the input embeddings $X$:\n",
    "\n",
    "$$ X W_Q = Q $$\n",
    "$$ X W_K = K $$\n",
    "$$ X W_V = V $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89470021-bf58-4ccb-87e1-46ff5c73016c",
   "metadata": {},
   "source": [
    "This is discussed [here](https://jalammar.github.io/illustrated-transformer/) and [here](https://stackoverflow.com/questions/68266490/dimension-of-query-and-key-tensor-in-multiheadattention), the dimensionality of the linear transformation matrices and thus the resulting query, key, and value matrices is flexible (i.e. The number of columns can change). Some architectures elect specific dimensions so that the calculations take on certain characteristics or properties (like ease of use or speed).\n",
    "\n",
    "That being said, concuptually, I think it makes sense to think of them as having the same dimensionality of $X$ (token count x embedding length). Thus every embedding $x_i$ has a coresponding query $q_i$, key $k_i$, and value $v_i$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ac775-47c5-45fc-a113-af002f964216",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/transformer_query_key_and_value_example2.png\" style=\"width:60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82f70a-75c0-4d09-9a11-5588ffd39730",
   "metadata": {},
   "source": [
    "We can then plug these matrices into the definition of attention:\n",
    "\n",
    "$$ Attention(Q, K, V) =  softmax \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3defe0-7d39-4048-ac8d-385463d1ea44",
   "metadata": {},
   "source": [
    "Visually, we can see the dimensionality:\n",
    "\n",
    "<center><img src=\"./images/transformer_attention_example.png\" style=\"width:50%\"></center>\n",
    "\n",
    "Focusing on the numerator we have:\n",
    "\n",
    "<center><img src=\"./images/transformer_attention_example2.png\" style=\"width:50%\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88418a7-8af7-464f-910c-0be64aa315f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ac182ac-6486-436d-b9e3-d231401979c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1c163b-59d6-482d-9ab1-910b42b3c8ef",
   "metadata": {},
   "source": [
    "By multiplying the query by the key\n",
    "\n",
    "Because this is a square matrix, each element in the matrix represents the intersection of the constituent parts. In our case, it's the intersection of the query and the key.\n",
    "\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560d7d4-4480-4acc-acef-e6e0e9a9f536",
   "metadata": {},
   "source": [
    "The attention score is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c09f6a-8416-4a99-aaf3-e38360fd5d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bad18aff-5bb3-4a48-853e-bc2f11ece765",
   "metadata": {},
   "source": [
    "Which then gives us\n",
    "\n",
    "<center><img src=\"./images/transformer_attention_example3.png\" style=\"width:50%\"></center>\n",
    "\n",
    "<center><img src=\"./images/transformer_attention_example4.png\" style=\"width:20%\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c225b5-15fc-4e08-8d64-e4ad85d60e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7c889-744c-4b78-8b2d-f5f5328f0dbe",
   "metadata": {},
   "source": [
    "**Note**: The softmax function which unsures all the values in the matrix sum to one. This is an important mathematical property which allows us to consider the attention matrix as a multidimensional probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abee353-1f6d-4a70-8601-e5f333ee8b9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "712cf01d-b660-4f5b-9d04-bf2d1cd5a148",
   "metadata": {},
   "source": [
    "In addition to the paper, this [article](https://medium.com/analytics-vidhya/understanding-attention-in-transformers-models-57bada0cce3e was helpful in understanding. I borrowed a few diagrams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178e484-5388-468b-a5c2-511ebdc05801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d68acb-78e2-491c-8bf4-a26f9fd918cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "930df757-aa98-4e88-b308-e661cbb1c530",
   "metadata": {},
   "source": [
    "# Queries, Keys, and Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7896b-fd9f-49ee-99e9-f26410de46a7",
   "metadata": {},
   "source": [
    "Neural networks can be designed in a way that allows them to accept either fixed or variable input sequence lenghts. However, the ability to impliment the latter was not available right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e1a15-0790-48eb-92bf-684d5405bab5",
   "metadata": {},
   "source": [
    "## (Kalchbrenner et al., 2014)\n",
    "In April of 2014, a paper titled *\"A Convolutional Neural Network for Modelling Sentences\n",
    "\"* was [published](https://arxiv.org/abs/1404.2188).\n",
    "\n",
    "\n",
    "Variable size is addressed by sequentially processing one token at a time, or by specially designed convolution kernels \n",
    "\n",
    "This approach can lead to significant problems when the input is truly of varying size with varying information content, such as in Section 10.7 in the transformation of text (Sutskever et al., 2014). In particular, for long sequences it becomes quite difficult to keep track of everything that has already been generated or even viewed by the network. Even explicit tracking heuristics such as proposed by Yang et al. (2016) only offer limited benefit.\n",
    "\n",
    "https://d2l.ai/chapter_attention-mechanisms-and-transformers/queries-keys-values.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d5a99-28a2-4b86-8305-fbe317c06fce",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dafe99-87f5-40cd-9e83-fe607961fdca",
   "metadata": {},
   "source": [
    "# Problem: Fixed length Buffer\n",
    "\n",
    "> An encoder neural network reads and encodes a source sentence into a fixed-length vector. A decoder then outputs a translation from the encoded vector. The whole encoder–decoder system, which consists of the encoder and the decoder for a language pair, is jointly trained to maximize the probability of a correct translation given a source sentence. A potential issue with this encoder–decoder approach is that a neural network needs to be able to compress all the necessary information of a source sentence into a fixed-length vector. This may make it difficult for the neural network to cope with long sentences, especially those that are longer than the sentences in the training corpus.\n",
    ">\n",
    "> (Bahdanau et al., 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4edfcb5-bda1-435a-b9f2-a1dfe9d8c940",
   "metadata": {},
   "source": [
    "## Cho et al. (2014b)\n",
    "Cho et al. (2014b) showed that indeed the performance of\n",
    "a basic encoder–decoder deteriorates rapidly as the length of an input sentence increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c175a46-af99-4ae8-a3ea-856e596da0e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (Bahdanau et al., 2014)\n",
    "In September 2014, a paper titled *\"Neural machine translation by jointly learning to align and translate\"* was [published](https://arxiv.org/abs/1409.0473)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ecaf70-dc0e-46df-b27e-87024485f4a4",
   "metadata": {},
   "source": [
    "Bahdanau et al. acknowlege the issues of the fixed length vector:\n",
    "\n",
    "> The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. \n",
    "\n",
    "Additionally they propose a novel enhancement to the encoder-decoder architecture which is built around an attention mechanism.\n",
    "\n",
    "> In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly.\n",
    ">\n",
    "> By letting the decoder have an attention mechanism, we relieve the encoder from the burden of having to encode all information in the source sentence into a fixedlength vector. With this new approach the information can be spread throughout ..., which can be selectively retrieved by the decoder accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a26b8-0e4d-4572-a0e5-a1d080f1b2fd",
   "metadata": {},
   "source": [
    "They emphasize that this mechanism bypasses the bottleneck of a fixed length vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab7e0c-6ef3-4ed3-879d-c8a5b831fd17",
   "metadata": {},
   "source": [
    "> The most important distinguishing feature of this approach from the basic encoder–decoder is that it does not attempt to encode a whole input sentence into a single fixed-length vector. Instead, it encodes the input sentence into a sequence of (context) vectors and chooses a subset of these vectors adaptively (based on the alignment scores) while decoding the translation. This frees a neural translation model from having to squash all the information of a source sentence, regardless of its length, into a fixed-length vector. We show this allows a model to cope better with long sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bf31c-5879-4f93-a84b-fc4ac154c19e",
   "metadata": {},
   "source": [
    "At the center of their proposed architecture are annotations.  For each token in the input sequence, the encoder (a bi-driectional RNN) will compute an annotation. Each annotation is represented by the concatenation of the coresponding forward and backward hidden states of the encoder's RNNs.\n",
    "\n",
    "> In this way, the annotation $h_j$ contains the summaries of both the preceding words and the following words. Due to the tendency of RNNs to better represent recent inputs, the annotation $h_j$ will be focused on the words around $x_j$ . This sequence of annotations is used by the decoder and the alignment model later to compute the context vector.\n",
    "\n",
    "The context vector is computed as the weighted sum of the annotations (represented by $\\bigoplus$). In this case, the weights $\\alpha$ are calculted as the softmax of the alingment value of the annotations. \n",
    "\n",
    "**Note**: Use of the softmax function continues forward into newer attention mechanisms.\n",
    "\n",
    "\n",
    "This is then used as an input to the decoders hidden state $s_t$ to predict the target value $y_t.\n",
    "$.\n",
    "> The model then predicts a target word based on the context vectors associated with these source positions and all the previous generated target words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d940bd1e-2a69-4ab1-b107-d8942d29eebf",
   "metadata": {},
   "source": [
    "<center><img src='./images/attention_architecture_example.png' style='width:25%'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f6d31-32c1-44f0-b10a-802bd72af012",
   "metadata": {},
   "source": [
    "The model is trained by optimizing an alignment score; which quantifies the distance from the correct outputs given the inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc2467-dc2b-4150-a5a7-eb436d15643d",
   "metadata": {},
   "source": [
    "The authors show how the attention scores allow the model to dynamically determine the soft-alignment of the input and output sequences. Specifically, they show several instances where the attention model is able to change the order of words from their exact literal translation to a gramatically correct translation.\n",
    "\n",
    "<center><img src=\"./images/attention_swapping_word_order.png\" style=\"width:50%\"></center>\n",
    "\n",
    "> Figure 3: Four sample alignments found by RNNsearch-50. The x-axis and y-axis of each plot\n",
    "correspond to the words in the source sentence (English) and the generated translation (French),\n",
    "respectively. Each pixel shows the weight $\\alpha_{ij}$ of the annotation of the j-th source word for the i-th\n",
    "target word (see Eq. (6)), in grayscale (0: black, 1: white). (a) an arbitrary sentence. (b–d) three\n",
    "randomly selected samples among the sentences without any unknown words and of length between\n",
    "10 and 20 words from the test set.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581efdde-d10e-46ff-b2f3-582cddc74867",
   "metadata": {},
   "source": [
    "## Problem: RNN consider entire input seuence (reference window)\n",
    "https://theaisummer.com/attention/#the-limitations-of-rnns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be62fdf-3f91-42d4-99cd-8137a52af13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb38117b-a596-4428-bf5d-ee8dc2a23cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce58f1-8091-4f95-9aba-22a693e3d8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c619b6b-09d8-474c-b19d-f2831c0c393e",
   "metadata": {},
   "source": [
    "Although they used different terminology to (Vaswani et al. 2017) the basic premise of the attention mechanism is conceptually the same. \n",
    "\n",
    "Conceptually, we can consider a trained or calibrated attention mechanism as a database. As a user, we can query the database to see if any information exists based on the search criteria. In the context of attention, the query is asking the database to return records or values which match a particular key. In the context of machine translation or question/answer, our query is constructed to perform a lookup of the most likely next word (value) given the current token in question (key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ca928-9b8d-4f2c-9360-9ec63debce0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b260fa0b-7ddf-45d2-80da-196f539de3ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8805659-6509-4531-bc37-dfef7374c9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
