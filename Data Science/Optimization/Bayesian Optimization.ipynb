{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6982aa7-6687-4da4-bf91-f489b6f34f1a",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6c973-fcbd-4098-adc7-93cf1b11420a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1944ec8f-7318-40cb-8839-e0890e6fda43",
   "metadata": {},
   "source": [
    "# Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def3365-fbb3-4bb2-b6de-0bdc2ea42e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4dca27e-f30a-4bad-b826-ef936176d2e0",
   "metadata": {},
   "source": [
    "## Bayes Theorem\n",
    "\n",
    "Bayes theorem sets up a mathematical equality which allows us to express the relationship between two jointly-distributed variables using conditional and marginal probabilities.\n",
    "\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
    "\n",
    "It's important to know that using the definition of conditional probability, the theorem can also be stated as:\n",
    "\n",
    "$$ P(A|B) = \\frac{P(B \\cap A)}{P(B)} $$\n",
    "\n",
    "\n",
    "The following terminology has been applied to the terms above:\n",
    "\n",
    "- $P(A|B)$: Posterior probability\n",
    "- $P(A)$: Prior probability\n",
    "- $P(B|A)$: Likelihood\n",
    "- $P(B)$: Evidence\n",
    "\n",
    "This allows Bayes Theorem to be restated as:\n",
    "\n",
    "$$ Posterior = \\frac{Likelihood * Prior}{Evidence} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c36e5a-0436-4ad7-b49f-701ca3e3e69d",
   "metadata": {},
   "source": [
    "### Example: Smoke and Fire\n",
    "Let A be the the event that a fire exists. Let B be the event that smoke exists.\n",
    "\n",
    "We multiply the probability that fire creates smoke by the probability of fire. This gives us a measurement for how likely that a fire is currently producing smoke. We divide this by the probability that smoke currently exists. \n",
    "\n",
    "This scaling effectively brings things back into the terms of smoke, and as the equality states, gives us the probability that fire exists given smoke currently exists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b35c2-3e14-4850-9a79-ab7e79b7bfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78bc21-4da7-40b3-ab97-dfc1b2e37aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0d5b6-0383-473d-a22f-c4b6b201079c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73cfff68-96ca-434e-a72e-48e7adb7a581",
   "metadata": {},
   "source": [
    "## Bayesian Statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef4146-0f88-4078-8f64-1783c1c1b58e",
   "metadata": {},
   "source": [
    "### The Prior and Posterior Distributions\n",
    "A prior distribution of a parameter is the probability distribution that represents your uncertainty about the parameter before the current data are examined. Multiplying the prior distribution and the likelihood function together leads to the posterior distribution of the parameter. You use the posterior distribution to carry out all inferences. You cannot carry out any Bayesian inference or perform any modeling without using a prior distribution.\n",
    "https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introbayes_sect004.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18aa24f-9049-44ba-8d0c-81fb7adc88aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "461b6b67-9646-403b-ada0-204fe93a64aa",
   "metadata": {},
   "source": [
    "The prior captures our ignorance regarding the true generating function (objective function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead5972-589c-41b1-b164-9f1d635d4915",
   "metadata": {},
   "source": [
    "Constraints on the prior -> smooth distribution... like terms are near eachother\n",
    "https://ekamperi.github.io/mathematics/2021/03/30/gaussian-process-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0da7c-a726-4ea1-9f5d-69e01cce766b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125493b-9760-4cfc-976e-f5fb982b032c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "993ad676-3307-4a82-aadc-0fd977a65068",
   "metadata": {},
   "source": [
    "Show plots with uncertainty bands\n",
    "https://ekamperi.github.io/mathematics/2021/03/30/gaussian-process-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a28a56-58ff-432f-a13b-f5ec57176e2f",
   "metadata": {},
   "source": [
    "## Whats the connection with quantifying uncertainty... likelihood and hypothesis testing??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b0cde-6524-409c-a627-38578d674576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f47654-dec7-4942-a9f6-da7a505dd176",
   "metadata": {},
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6112ccd-5c0c-44ea-a0ad-7c1fd84e0dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050c124-61ad-4ceb-ab9e-fda6e12317de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05d84d69-cd46-46b6-b90a-7eaf3bf1daa2",
   "metadata": {},
   "source": [
    "# Definition\n",
    "\n",
    "Bayesian Optimization uses a surrogate model \n",
    "\n",
    "A [surrogate model](https://en.wikipedia.org/wiki/Surrogate_model) is used to estimate a function/process of interest. The surrogate model is used when the actual outcomes cannot be directly observed.\n",
    "\n",
    "A gaussian process is often elected as the surrogate process because it provides a measure of uncertainty for the estimations that the model provides. This uncertainty information is used to strike a balance between exploration and exploitation as the search space is searched for the optimal parameter set. Ie. We want to explore new areas of the search space we have not yet inspected while exploiting (continuing to search) the areas we are more certain we will observe good values.\n",
    "\n",
    "https://brendanhasz.github.io/2019/03/28/hyperparameter-optimization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b337e5b-9f99-4a31-80e5-44d9960147d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "802e4c36-1bf1-4c8c-9e9e-54f3c12e941e",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "- **objective function** - the thing (function) being optimized\n",
    "- **search space** - the possible inputs forthe objective function\n",
    "- **surrogate model** - the model representing the objective function (see use cases)\n",
    "- **aquisition function** - the method for selecting the next segment of the domain to explore (BO is an iterative process).\n",
    "- **exploitation** - trying solutions are similar to other things that have already been proven to be good solutions\n",
    "- **exploration** - trying solutions that are in unknown areas of the search space\n",
    "\n",
    "good article: https://ekamperi.github.io/machine%20learning/2021/06/11/acquisition-functions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a41a4c-c8cb-477e-8472-e498d2a635e1",
   "metadata": {},
   "source": [
    "## The Basic Algorithm\n",
    "\n",
    "Bayesian Optimization is an iterative process which is typically terminated by some threshold and/or exhaustion conditions.\n",
    "\n",
    "Remake this image to talk about choosing a surrogate model and considering termination conditions\n",
    "\n",
    "<center><img src='images/bayesian_optimization_algorithm_diagram.png' width='400px' height='400px'></center>\n",
    "\n",
    "picture here: https://ekamperi.github.io/machine%20learning/2021/06/11/acquisition-functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fa884-6520-442a-80d5-f1507a3b8eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719eb8e-f942-4c40-82f8-9dc7d4a4aa42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03a125bb-0cf6-4487-bf89-64afe1ca41e3",
   "metadata": {},
   "source": [
    "Bayesian optimization gets its name because it used bayesian statistics and bayes theorem. The term is generally attributed to Jonas Mockus and is coined in his work from a series of publications on global optimization in the 1970s and 1980s.\n",
    "\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
    "\n",
    "Rearranging this equation slightly we can see that we are calculating the conditional probability as the product of two other terms:\n",
    "\n",
    "$$ P(A|B) = P(B|A) * \\frac{P(A)}{P(B)} $$\n",
    "\n",
    "We can choose to simplify the equation by considering one of the terms as an unneccessary scaling term. Removing it we have:\n",
    "\n",
    "$$ P(A|B) = P(B|A) * P(A) $$\n",
    "\n",
    "It is common to refer to these terms as the posterior probability, likelihood, and prior probability respectively.\n",
    "\n",
    "Definition of priors: https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_introbayes_sect004.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa63b18-31d1-46c4-aa35-d8693f8a9ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0eb87-4d4e-4e4f-9c19-5c6474340910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab4927-1324-4c71-bc9e-4c574aad744b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e239f147-3672-4563-872e-84fab8de4e7a",
   "metadata": {},
   "source": [
    "## Aquisition functions\n",
    "\n",
    "- Upper Confidence Bound (UCB)\n",
    "- Probability of Improvement (PI)\n",
    "- Expected Improvement (EI)\n",
    "\n",
    "https://ekamperi.github.io/machine%20learning/2021/06/11/acquisition-functions.html\n",
    "\n",
    "More methods and great visual for comparison\n",
    "\n",
    "https://distill.pub/2020/bayesian-optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43e372-e943-405f-a0ef-a012171dd5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69e35e-4495-406a-b93f-277e1e04a261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f91c079-ebf1-4873-a900-c76f4145eeb2",
   "metadata": {},
   "source": [
    "## Standard vs Exotic Bayesian Optimization Problems\n",
    "\n",
    "Standard Bayesian optimization relies upon each {\\displaystyle x\\in A}x\\in A being easy to evaluate, and problems that deviate from this assumption are known as exotic Bayesian optimization problems. Optimization problems can become exotic if it is known that there is noise, the evaluations are being done in parallel, the quality of evaluations relies upon a tradeoff between difficulty and accuracy, the presence of random environmental conditions, or if the evaluation involves derivatives.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bayesian_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46bd36-6278-4cbb-8a43-0464393533e8",
   "metadata": {},
   "source": [
    "# Example aquisition functions\n",
    "- probability of improvement, \n",
    "- expected improvement, \n",
    "- Bayesian expected losses, \n",
    "- upper confidence bounds (UCB), \n",
    "- Thompson sampling and hybrids of these\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bayesian_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b18fc-0688-41d3-83c6-39cdf57ba686",
   "metadata": {},
   "source": [
    "\n",
    "# Compare brute force vs bayesisan ... cool visuals\n",
    "https://ekamperi.github.io/machine%20learning/2021/05/08/bayesian-optimization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f4f9c-e232-46ec-ad0a-ecd3b32a44f0",
   "metadata": {},
   "source": [
    "Active learning, visuals of the prior being updated\n",
    "https://distill.pub/2020/bayesian-optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb1d11-7321-4d87-add8-ee38b8640019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96e40308-0ac9-43d2-b1bc-2564281f2373",
   "metadata": {},
   "source": [
    "## constraints\n",
    "https://distill.pub/2020/bayesian-optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3e07b-3c08-4be6-955c-f63fe2a8cdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066ca3a-3479-492f-9496-b8dec77fc9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5834936d-e8a9-46ed-8280-23eaf0606a63",
   "metadata": {},
   "source": [
    "# Use Cases\n",
    "- dont have an analytic expression \n",
    "- functions without 1st or 2nd order statistics (bc. cannot use other methods)\n",
    "- black box functions (objective function is unknown)\n",
    "- functions difficult to observe\n",
    "- functions are expensive to evaulate (lab experiments)\n",
    "- Lipschitz-continuos ?? https://www.cs.uic.edu/~hjin/files/bayesian_opt.pdf\n",
    "- no guarantee of convexity -> rules out methods from convexity field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc687baa-14ea-4795-b13a-4f2e04043091",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b524d7-7e81-4889-b44a-c25b0d7c6ef7",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba415d3a-8247-4d2f-8ed5-475693936826",
   "metadata": {},
   "source": [
    "### Choose a surrogate model\n",
    "The gaussian process is a classic choice, but others exist\n",
    "\n",
    "### Define \"the prior\" (distribution)\n",
    "\n",
    "### Obtain the posterior (distribution)\n",
    "Given the set of observations (function evaluations), use Bayes rule to obtain the posterior.\n",
    "\n",
    "### Determine the next search parameters using aquisition funciton\n",
    "Use an acquisition function \\alpha(x)Î±(x), which is a function of the posterior, to decide the next sample point $x_t = \\text{argmax}_x \\alpha(x)$\n",
    "\n",
    "### Check Terminiation Conditions\n",
    "\n",
    "### Go To Step 2\n",
    "Add newly sampled data to the set of observations and goto step #2 till convergence or budget elapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd95a5-3794-4f63-b874-4b5649526c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390f502-3904-4d7a-ab2b-1b306995f7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102620a-4be9-4112-9e81-577b9c71b2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
