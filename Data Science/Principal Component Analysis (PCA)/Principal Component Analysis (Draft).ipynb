{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook we explore the concept of Principal Component Analysis. This is a popular feature engineering technique used specifically for dimentionality reduction. In short, PCA will try to measure the importance of a feature using a measurement similar to correlation. \n",
    "\n",
    "## Prerequisite Reading\n",
    "If you are unfamiliar with correlation it is suggested you read the [notebook on correlation](Correlation.ipynb). As correlation is affected by linear scale, we will see that normalization is a prerequisite transformation for our data. If you are not famliar with normalization it is suggested you reat the [notebook on normalization](../Exploratory%20Data%20Analysis%20%28EDA%29%2F/Normalization.ipynb)\n",
    "\n",
    "This notebook is broken down into the following sections:\n",
    "1. Loading our data\n",
    "2. Normalizing our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load our libraires\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>QuizAvg</th>\n",
       "      <th>TestAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>181</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>169</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>176</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>181</td>\n",
       "      <td>66</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>169</td>\n",
       "      <td>89</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>150</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>181</td>\n",
       "      <td>98</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31</td>\n",
       "      <td>163</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29</td>\n",
       "      <td>147</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>160</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ACT  FinalExam  QuizAvg  TestAvg\n",
       "0    33        181       95       89\n",
       "1    31        169       81       89\n",
       "2    21        176       65       68\n",
       "3    25        181       66       90\n",
       "4    29        169       89       81\n",
       "5    24        103       61       57\n",
       "6    25        150       81       76\n",
       "7    29        147       86       76\n",
       "8    36        181       98      102\n",
       "9    26        163       72       70\n",
       "10   31        163       95       81\n",
       "11   29        147       65       67\n",
       "12   23        160       62       68\n",
       "13   26        100       63       56"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our sample data\n",
    "import os\n",
    "import pyprojroot\n",
    "project_root_dir = pyprojroot.here()\n",
    "input_file_path = os.path.join(project_root_dir, \"Example Data Sets\", \"Test Scores.csv\")\n",
    "delimiter = \",\"\n",
    "df = pandas.read_csv(input_file_path, delimiter=delimiter)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Normalize Our Data\n",
    "In order to use PCA we need to take care to appropriately normalize our data. In a nutshell, the PCA algorithm relies on linear distance of the deviations of our variables; variables with different scales will disproportionately report deviations and thus will introduce bias into the analysis (penalizing variables with smaller scale). Normalization removes this problem by adjusting variables to a common (or similar enough) scale. If you are not famliar with normalization it is suggested you reat the [notebook on normalization](../Exploratory%20Data%20Analysis%20%28EDA%29%2F/Normalization.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Choose a normalization method\n",
    "There are many ways to normalize or standardiaze our data. We will not talk about all the approaches here... but there are a few and they all have different affects and implications. We will choose standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Normalize using a Standard Score\n",
    "We will use the **standard score** (z-score) because it is simple and well documented.\n",
    "\n",
    "The standard score is the signed fractional number of standard deviations by which the value of an observation or data point is above or below the mean value of what is being observed or measured. Observed values above the mean have positive standard scores, while values below the mean have negative standard scores.\n",
    "\n",
    "$$ z = \\frac{(x-\\mu)}{\\sigma} $$\n",
    "\n",
    "The higher or lower the score, the farther from the mean, and thus the more exceptional a given score is when compared to the sample. This is how we will compare our scores!!\n",
    "\n",
    "If we look at a sample with a normally distributed random variable, we will see the implications of the various scores:\n",
    "\n",
    "![image](Normalization_method_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the standard score of each element in our data frame (on a per-column basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>QuizAvg</th>\n",
       "      <th>TestAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.270931</td>\n",
       "      <td>0.940813</td>\n",
       "      <td>1.304131</td>\n",
       "      <td>0.952737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790038</td>\n",
       "      <td>0.481346</td>\n",
       "      <td>0.285766</td>\n",
       "      <td>0.952737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.614426</td>\n",
       "      <td>0.749368</td>\n",
       "      <td>-0.878080</td>\n",
       "      <td>-0.638767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.652640</td>\n",
       "      <td>0.940813</td>\n",
       "      <td>-0.805340</td>\n",
       "      <td>1.028523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309145</td>\n",
       "      <td>0.481346</td>\n",
       "      <td>0.867689</td>\n",
       "      <td>0.346450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.893087</td>\n",
       "      <td>-2.045721</td>\n",
       "      <td>-1.169041</td>\n",
       "      <td>-1.472411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.652640</td>\n",
       "      <td>-0.246143</td>\n",
       "      <td>0.285766</td>\n",
       "      <td>-0.032480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.309145</td>\n",
       "      <td>-0.361010</td>\n",
       "      <td>0.649467</td>\n",
       "      <td>-0.032480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.992270</td>\n",
       "      <td>0.940813</td>\n",
       "      <td>1.522352</td>\n",
       "      <td>1.937953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.412194</td>\n",
       "      <td>0.251613</td>\n",
       "      <td>-0.368898</td>\n",
       "      <td>-0.487195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.790038</td>\n",
       "      <td>0.251613</td>\n",
       "      <td>1.304131</td>\n",
       "      <td>0.346450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.309145</td>\n",
       "      <td>-0.361010</td>\n",
       "      <td>-0.878080</td>\n",
       "      <td>-0.714553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.133533</td>\n",
       "      <td>0.136746</td>\n",
       "      <td>-1.096301</td>\n",
       "      <td>-0.638767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.412194</td>\n",
       "      <td>-2.160588</td>\n",
       "      <td>-1.023561</td>\n",
       "      <td>-1.548197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACT  FinalExam   QuizAvg   TestAvg\n",
       "0   1.270931   0.940813  1.304131  0.952737\n",
       "1   0.790038   0.481346  0.285766  0.952737\n",
       "2  -1.614426   0.749368 -0.878080 -0.638767\n",
       "3  -0.652640   0.940813 -0.805340  1.028523\n",
       "4   0.309145   0.481346  0.867689  0.346450\n",
       "5  -0.893087  -2.045721 -1.169041 -1.472411\n",
       "6  -0.652640  -0.246143  0.285766 -0.032480\n",
       "7   0.309145  -0.361010  0.649467 -0.032480\n",
       "8   1.992270   0.940813  1.522352  1.937953\n",
       "9  -0.412194   0.251613 -0.368898 -0.487195\n",
       "10  0.790038   0.251613  1.304131  0.346450\n",
       "11  0.309145  -0.361010 -0.878080 -0.714553\n",
       "12 -1.133533   0.136746 -1.096301 -0.638767\n",
       "13 -0.412194  -2.160588 -1.023561 -1.548197"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df = ((df - df.mean())/df.std())\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Calculate Correlation Matrix\n",
    "As we will see, PCA is reliant on the pearson correlation coefficient. We can calculate the correlation between pairs of variables. When dealing with more than one pair, a correlation matrix is a convenient way of tracking the information.\n",
    "\n",
    "The correlation matrix, a type of adjacency matrix, allows us to show the correlation between all variables in a sample set using a compact format. Each row and column pertain to a particular variable, the cells indicate the correlation between the two points.\n",
    "\n",
    "We can easily calculate correlation using numpy or pandas. We will look at both methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Calculate Correlation Using Numpy\n",
    "Numpy provides a method for calculating covariance and returing a correlation matrix represented by a numpy array. It's not as nice to look at, but sometimes numpy objects are needed. The rows/columns match those of our data frame. We see a diagonal set of 1's indicating that variable A is adjacent to itself in that cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33618637, 0.82780343, 0.7102748 ],\n",
       "       [0.33618637, 1.        , 0.49994932, 0.79584684],\n",
       "       [0.82780343, 0.49994932, 1.        , 0.7486962 ],\n",
       "       [0.7102748 , 0.79584684, 0.7486962 , 1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the transpose of our matrix (not important to understand why we are doing this)\n",
    "normalized_transposed_df = normalized_df.T\n",
    "\n",
    "# Compute the correlation matrix (a numpy ndarray)\n",
    "correlation_numpy_array = numpy.corrcoef(normalized_transposed_df)\n",
    "correlation_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACT', 'FinalExam', 'QuizAvg', 'TestAvg']\n"
     ]
    }
   ],
   "source": [
    "# Show the rows and columns in order\n",
    "print(list(normalized_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Calculate Correlation Using Pandas\n",
    "Pandas is a little more user friendly because it requires less knowledge of matrix algebra (the transpose) and it tells us the row and column names upfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT</th>\n",
       "      <th>FinalExam</th>\n",
       "      <th>QuizAvg</th>\n",
       "      <th>TestAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336186</td>\n",
       "      <td>0.827803</td>\n",
       "      <td>0.710275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalExam</th>\n",
       "      <td>0.336186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>0.795847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuizAvg</th>\n",
       "      <td>0.827803</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestAvg</th>\n",
       "      <td>0.710275</td>\n",
       "      <td>0.795847</td>\n",
       "      <td>0.748696</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ACT  FinalExam   QuizAvg   TestAvg\n",
       "ACT        1.000000   0.336186  0.827803  0.710275\n",
       "FinalExam  0.336186   1.000000  0.499949  0.795847\n",
       "QuizAvg    0.827803   0.499949  1.000000  0.748696\n",
       "TestAvg    0.710275   0.795847  0.748696  1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numpy array into a pandas data frame\n",
    "correlation_df = normalized_df.corr()\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that QuizAvg and ACT have the highest correlation meaning that they are likely to be redundant features. There is only a small benefit to including both because one of them give us most of the information about the deviations of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Decompose Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is the heart of PCA. In short, the eigenvalues/eigenvector decomposition provides us a a way of eliminating features which provide duplicate data.\n",
    "\n",
    "Mathematically eigenvalues and eivenvectors allows us to selectively reduce the number of dimensions in our problem while minimizing (and thus quantifying) information loss. The information being considered in the case of PCA is that of the correlation matrix. Thus any redundancy is that of correlation. By reducing the dimensionality we are reducing the overall covariance explained by our feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Using Numpy To Calculate eigenvalues\n",
    "\n",
    "We can use a builtin numpy function to do the decomposition:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the decomposition\n",
    "#\n",
    "#    Note: The term right vector just refers to the orientation of rows vs columns\n",
    "#          This is part of the math that we just do not need to worry about\n",
    "#\n",
    "\n",
    "eigenvalues_numpy_array, right_eigenvectors_numpy_array = numpy.linalg.eig(correlation_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eigenvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>2.978867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalExam</th>\n",
       "      <td>0.762946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuizAvg</th>\n",
       "      <td>0.083230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestAvg</th>\n",
       "      <td>0.174956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eigenvalue\n",
       "ACT          2.978867\n",
       "FinalExam    0.762946\n",
       "QuizAvg      0.083230\n",
       "TestAvg      0.174956"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at our lamndas (eigenvalues)\n",
    "eigenvalues_df = pandas.DataFrame(eigenvalues_numpy_array, index=df.columns, columns=[\"eigenvalue\"])\n",
    "eigenvalues_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Calculate Proportion Of Variance Explained\n",
    "If we look at the eigenvalues as being a measure of variance explained by a feature, we can cauluate the proportion of information explained by dividing the eigenvalue by the total sum of eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eigenvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>0.744717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalExam</th>\n",
       "      <td>0.190737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestAvg</th>\n",
       "      <td>0.043739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuizAvg</th>\n",
       "      <td>0.020807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eigenvalue\n",
       "ACT          0.744717\n",
       "FinalExam    0.190737\n",
       "TestAvg      0.043739\n",
       "QuizAvg      0.020807"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_variance = eigenvalues_df[\"eigenvalue\"].sum()\n",
    "proportion_variance_explained_df = eigenvalues_df / total_variance\n",
    "proportion_variance_explained_df = proportion_variance_explained_df.sort_values(by=[\"eigenvalue\"], ascending=False)\n",
    "proportion_variance_explained_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the proportions sum to 1. Note: Rounding errors are due to numpy's numerical implimentation of floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_variance_explained_df[\"eigenvalue\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Select the Principal Components\n",
    "## 5.1. Frame the problem as an optimization problem\n",
    "As with most problems, selecting the principal components is an optimization problem. If you are not familiar with optimization, see the [coresponding notebook](../Optimization/Optimization.ipynb).\n",
    "\n",
    "We want to maximize the amount of variance explained or to minimize the information lost by removing a feature.\n",
    "\n",
    "Looking at the proportion of information explained we see the following plot which can be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "fig, ax = pyplot.subplots()\n",
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i, proportion in enumerate(proportion_variance_explained_df[\"eigenvalue\"]):\n",
    "    x.append(i)\n",
    "    y.append(proportion)\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Select An Optimization Technique\n",
    "As mentioned earlier, the [optimization notebook](../Optimization/Optimization.ipynb) discusses various methods for optimizing. In our case we need to select a cutoff point for an asymtotic function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we will choose to drop the last parameter with the smallest eigenvalue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
